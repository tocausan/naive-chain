/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, {
/******/ 				configurable: false,
/******/ 				enumerable: true,
/******/ 				get: getter
/******/ 			});
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ({

/***/ "./app.ts":
/*!****************!*\
  !*** ./app.ts ***!
  \****************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(__dirname) {\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar express = __webpack_require__(/*! express */ \"express\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar bodyParser = __webpack_require__(/*! body-parser */ \"body-parser\");\nvar cookieParser = __webpack_require__(/*! cookie-parser */ \"cookie-parser\");\nvar index_ts_1 = __webpack_require__(/*! ./routes/index.ts */ \"./routes/index.ts\");\nvar logger = __webpack_require__(/*! logger */ \"logger\");\nexports.App = express()\n    .set('views', path.join(__dirname, 'views'))\n    .set('view engine', 'jade')\n    .use(logger('dev'))\n    .use(bodyParser.json())\n    .use(bodyParser.urlencoded({ extended: false }))\n    .use(cookieParser())\n    .use(express.static(path.join(__dirname, 'public')))\n    .use('/', index_ts_1.Routes);\n\n/* WEBPACK VAR INJECTION */}.call(this, \"/\"))\n\n//# sourceURL=webpack:///./app.ts?");

/***/ }),

/***/ "./bin/www.ts":
/*!********************!*\
  !*** ./bin/www.ts ***!
  \********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar debug = __webpack_require__(/*! debug */ \"debug\");\nvar http = __webpack_require__(/*! http */ \"http\");\nvar config_1 = __webpack_require__(/*! ../config */ \"./config.ts\");\nvar app_1 = __webpack_require__(/*! ../app */ \"./app.ts\");\nvar port = normalizePort(process.env.PORT || config_1.Config.app.port);\napp_1.App.set('port', port);\nvar server = http.createServer(app_1.App);\nserver.listen(port);\nserver.on('error', onError);\nserver.on('listening', onListening);\nfunction normalizePort(val) {\n    var port = parseInt(val, 10);\n    if (isNaN(port))\n        return val;\n    if (port >= 0)\n        return port;\n    return false;\n}\nfunction onError(error) {\n    if (error.syscall !== 'listen')\n        throw error;\n    var bind = typeof port === 'string'\n        ? 'Pipe ' + port\n        : 'Port ' + port;\n    switch (error.code) {\n        case 'EACCES':\n            console.error(bind + ' requires elevated privileges');\n            process.exit(1);\n            break;\n        case 'EADDRINUSE':\n            console.error(bind + ' is already in use');\n            process.exit(1);\n            break;\n        default:\n            throw error;\n    }\n}\nfunction onListening() {\n    var addr = server.address(), bind = typeof addr === 'string'\n        ? 'pipe ' + addr\n        : 'port ' + addr.port;\n    debug('Listening on ' + bind);\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../node_modules/process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./bin/www.ts?");

/***/ }),

/***/ "./config.ts":
/*!*******************!*\
  !*** ./config.ts ***!
  \*******************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Config = {\n    database: {\n        path: 'mongodb://localhost:27017/naive-chain',\n        collections: {\n            blocks: 'blocks',\n            devices: 'devices'\n        }\n    },\n    encryption: {\n        binary: 'base64',\n        algorithm: 'aes192',\n        hash: 'sha512',\n        iterations: 16\n    },\n    app: {\n        port: '3000',\n        version: 1,\n        path: '/api/1'\n    },\n};\n\n\n//# sourceURL=webpack:///./config.ts?");

/***/ }),

/***/ "./data-access/database.ts":
/*!*********************************!*\
  !*** ./data-access/database.ts ***!
  \*********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar config_1 = __webpack_require__(/*! ../config */ \"./config.ts\");\nvar mongoDb = __webpack_require__(/*! mongoDb */ \"./node_modules/mongoDb/index.js\");\nexports.DatabaseDataAccess = {\n    isConnected: function () {\n        return new Promise(function (resolve, reject) {\n            mongoDb.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(new Error('database not connected'));\n                resolve(true);\n            });\n        });\n    },\n    findAll: function (collection) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).find().toArray(function (error, result) {\n                    if (error)\n                        reject(error);\n                    resolve(result);\n                    db.close();\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    },\n    findOne: function (collection, filter) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).findOne(filter).then(function (result) {\n                    resolve(result);\n                    db.close();\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    },\n    findLastOne: function (collection) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).find().limit(1).sort({ $natural: -1 }).toArray().then(function (result) {\n                    resolve(result[0]);\n                    db.close();\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    },\n    findOneUpdate: function (collection, filter, update) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).findOneAndUpdate(filter, { $set: update }).then(function (result) {\n                    resolve(result);\n                    db.close();\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    },\n    findOneDelete: function (collection, filter) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).findOneAndDelete(filter).then(function (result) {\n                    resolve(result);\n                    db.close();\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    },\n    insertOne: function (collection, data) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).insertOne(data).then(function (result) {\n                    resolve(result);\n                    db.close();\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    },\n    insertOneIfNotExist: function (collection, filter, data) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).findOne(filter).then(function (findResult) {\n                    if (!findResult) {\n                        db.collection(collection).insertOne(data).then(function (insertResult) {\n                            resolve(data);\n                        }, function (e) {\n                            reject(e);\n                        });\n                    }\n                    else {\n                        reject('already exist');\n                    }\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    },\n    insertMany: function (collection, data) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                db.collection(collection).insertMany(data).then(function (result) {\n                    resolve(result);\n                    db.close();\n                }, function (e) {\n                    reject(e);\n                });\n            });\n        });\n    }\n};\n\n\n//# sourceURL=webpack:///./data-access/database.ts?");

/***/ }),

/***/ "./data-access/index.ts":
/*!******************************!*\
  !*** ./data-access/index.ts ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__export(__webpack_require__(/*! ./database */ \"./data-access/database.ts\"));\n\n\n//# sourceURL=webpack:///./data-access/index.ts?");

/***/ }),

/***/ "./models/Block.ts":
/*!*************************!*\
  !*** ./models/Block.ts ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar _ = __webpack_require__(/*! lodash */ \"lodash\");\nvar moment = __webpack_require__(/*! moment */ \"moment\");\nvar services_1 = __webpack_require__(/*! ../services */ \"./services/index.ts\");\nvar Block = (function () {\n    function Block(data) {\n        this.index = !_.isNil(data) && !_.isNil(data.index) ? data.index : 0;\n        this.timestamp = !_.isNil(data) && !_.isNil(data.timestamp) ? data.timestamp : moment.utc().unix();\n        this.data = !_.isNil(data) && !_.isNil(data.data) ? data.data : {};\n        this.target = !_.isNil(data) && !_.isNil(data.target) ? data.target : this.setTarget();\n        this.nonce = !_.isNil(data) && !_.isNil(data.nonce) ? data.nonce : 0;\n        this.prevHash = !_.isNil(data) && !_.isNil(data.prevHash) ? data.prevHash : '0000000000';\n        this.currHash = !_.isNil(data) && !_.isNil(data.currHash) ? data.currHash : this.encryptCurrHash();\n    }\n    ;\n    Block.prototype.setTarget = function () {\n        return Math.ceil(this.index);\n    };\n    Block.prototype.encryptCurrHash = function () {\n        var contentToHash = [\n            this.index,\n            this.timestamp,\n            this.data,\n            this.prevHash,\n            this.nonce,\n            this.target\n        ], hash = services_1.EncryptionServices.hash(JSON.stringify(contentToHash));\n        return hash;\n    };\n    ;\n    Block.createNonce = function () {\n        return services_1.BlockServices.getAllBlocks()\n            .then(function (blocks) {\n            var nonceList = blocks.map(function (b) { return b.nonce; });\n            var nonce;\n            do {\n                nonce = Math.round(Math.random() * 100000000000000000000000000000000);\n                console.log(nonce);\n            } while (nonceList.indexOf(nonce) > -1);\n            return nonce;\n        });\n    };\n    Block.isValid = function (block, previousBlock) {\n        return block.prevHash === previousBlock.currHash;\n    };\n    ;\n    return Block;\n}());\nexports.Block = Block;\n;\n\n\n//# sourceURL=webpack:///./models/Block.ts?");

/***/ }),

/***/ "./models/DbClient.ts":
/*!****************************!*\
  !*** ./models/DbClient.ts ***!
  \****************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar config_1 = __webpack_require__(/*! ../config */ \"./config.ts\");\nvar mongoDb = __webpack_require__(/*! mongoDb */ \"./node_modules/mongoDb/index.js\");\nvar DbClient = (function () {\n    function DbClient() {\n    }\n    DbClient.prototype.connect = function (data) {\n        return new Promise(function (resolve, reject) {\n            mongoDb.MongoClient.connect(config_1.Config.database.path, function (err, db) {\n                if (err)\n                    reject(err);\n                console.log(db);\n                resolve(db);\n            });\n        });\n    };\n    return DbClient;\n}());\nexports.DbClient = DbClient;\n\n\n//# sourceURL=webpack:///./models/DbClient.ts?");

/***/ }),

/***/ "./models/Debug.ts":
/*!*************************!*\
  !*** ./models/Debug.ts ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar chalk = __webpack_require__(/*! chalk */ \"chalk\");\nvar Debug = (function () {\n    function Debug() {\n    }\n    Debug.checkJson = function (data) {\n        try {\n            return JSON.stringify(JSON.parse(data));\n        }\n        catch (e) {\n            console.log('invalid json');\n            console.log(e);\n        }\n    };\n    Debug.info = function (data) {\n        var message = this.checkJson(data);\n        console.log(chalk.greenBright(chalk.underline.dim('info'), message));\n    };\n    ;\n    Debug.data = function (data) {\n        var message = this.checkJson(data);\n        console.log(chalk.blueBright(chalk.underline.dim('data'), message));\n    };\n    ;\n    Debug.warn = function (data) {\n        var message = this.checkJson(data);\n        console.log(chalk.yellowBright(chalk.underline.dim('warn'), message));\n    };\n    ;\n    Debug.error = function (data) {\n        var message = this.checkJson(data);\n        console.log(chalk.redBright(chalk.underline.dim('error'), message));\n    };\n    ;\n    return Debug;\n}());\nexports.Debug = Debug;\n;\n\n\n//# sourceURL=webpack:///./models/Debug.ts?");

/***/ }),

/***/ "./models/Device.ts":
/*!**************************!*\
  !*** ./models/Device.ts ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar _ = __webpack_require__(/*! lodash */ \"lodash\");\nvar moment = __webpack_require__(/*! moment */ \"moment\");\nvar services_1 = __webpack_require__(/*! ../services */ \"./services/index.ts\");\nvar Device = (function () {\n    function Device(data) {\n        this.name = !_.isNil(data) && !_.isNil(data.name) ? data.name : null;\n        this.host = !_.isNil(data) && !_.isNil(data.host) ? data.host : null;\n        this.publicKey = !_.isNil(data) && !_.isNil(data.publicKey) ? data.key.publicKey : null;\n        this.privateKey = !_.isNil(data) && !_.isNil(data.privateKey) ? data.key.privateKey : null;\n        this.connection = !_.isNil(data) && !_.isNil(data.connection) ? data.connection : moment.utc().format();\n    }\n    ;\n    Device.prototype.initKeys = function () {\n        this.publicKey = services_1.EncryptionServices.hash(services_1.EncryptionServices.randomSecret(20));\n        this.privateKey = services_1.EncryptionServices.hash(services_1.EncryptionServices.randomSecret(20));\n        return this;\n    };\n    ;\n    return Device;\n}());\nexports.Device = Device;\n\n\n//# sourceURL=webpack:///./models/Device.ts?");

/***/ }),

/***/ "./models/Error.ts":
/*!*************************!*\
  !*** ./models/Error.ts ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ErrorApi = (function (_super) {\n    __extends(ErrorApi, _super);\n    function ErrorApi() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    return ErrorApi;\n}(Error));\nexports.ErrorApi = ErrorApi;\n\n\n//# sourceURL=webpack:///./models/Error.ts?");

/***/ }),

/***/ "./models/index.ts":
/*!*************************!*\
  !*** ./models/index.ts ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__export(__webpack_require__(/*! ./DbClient */ \"./models/DbClient.ts\"));\n__export(__webpack_require__(/*! ./Debug */ \"./models/Debug.ts\"));\n__export(__webpack_require__(/*! ./Block */ \"./models/Block.ts\"));\n__export(__webpack_require__(/*! ./Device */ \"./models/Device.ts\"));\n\n\n//# sourceURL=webpack:///./models/index.ts?");

/***/ }),

/***/ "./node_modules/buffer/index.js":
/*!**************************************!*\
  !*** ./node_modules/buffer/index.js ***!
  \**************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global) {/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n\n\nvar base64 = __webpack_require__(/*! base64-js */ \"base64-js\")\nvar ieee754 = __webpack_require__(/*! ieee754 */ \"ieee754\")\nvar isArray = __webpack_require__(/*! isarray */ \"isarray\")\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Use Object implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * Due to various browser bugs, sometimes the Object implementation will be used even\n * when the browser supports typed arrays.\n *\n * Note:\n *\n *   - Firefox 4-29 lacks support for adding new properties to `Uint8Array` instances,\n *     See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438.\n *\n *   - Chrome 9-10 is missing the `TypedArray.prototype.subarray` function.\n *\n *   - IE10 has a broken `TypedArray.prototype.subarray` function which returns arrays of\n *     incorrect length in some situations.\n\n * We detect these buggy browsers and set `Buffer.TYPED_ARRAY_SUPPORT` to `false` so they\n * get the Object implementation, which is slower but behaves correctly.\n */\nBuffer.TYPED_ARRAY_SUPPORT = global.TYPED_ARRAY_SUPPORT !== undefined\n  ? global.TYPED_ARRAY_SUPPORT\n  : typedArraySupport()\n\n/*\n * Export kMaxLength after typed array support is determined.\n */\nexports.kMaxLength = kMaxLength()\n\nfunction typedArraySupport () {\n  try {\n    var arr = new Uint8Array(1)\n    arr.__proto__ = {__proto__: Uint8Array.prototype, foo: function () { return 42 }}\n    return arr.foo() === 42 && // typed array instances can be augmented\n        typeof arr.subarray === 'function' && // chrome 9-10 lack `subarray`\n        arr.subarray(1, 1).byteLength === 0 // ie10 has broken `subarray`\n  } catch (e) {\n    return false\n  }\n}\n\nfunction kMaxLength () {\n  return Buffer.TYPED_ARRAY_SUPPORT\n    ? 0x7fffffff\n    : 0x3fffffff\n}\n\nfunction createBuffer (that, length) {\n  if (kMaxLength() < length) {\n    throw new RangeError('Invalid typed array length')\n  }\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = new Uint8Array(length)\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    if (that === null) {\n      that = new Buffer(length)\n    }\n    that.length = length\n  }\n\n  return that\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  if (!Buffer.TYPED_ARRAY_SUPPORT && !(this instanceof Buffer)) {\n    return new Buffer(arg, encodingOrOffset, length)\n  }\n\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new Error(\n        'If encoding is specified then the first argument must be a string'\n      )\n    }\n    return allocUnsafe(this, arg)\n  }\n  return from(this, arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\n// TODO: Legacy, not needed anymore. Remove in next major version.\nBuffer._augment = function (arr) {\n  arr.__proto__ = Buffer.prototype\n  return arr\n}\n\nfunction from (that, value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    return fromArrayBuffer(that, value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(that, value, encodingOrOffset)\n  }\n\n  return fromObject(that, value)\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(null, value, encodingOrOffset, length)\n}\n\nif (Buffer.TYPED_ARRAY_SUPPORT) {\n  Buffer.prototype.__proto__ = Uint8Array.prototype\n  Buffer.__proto__ = Uint8Array\n  if (typeof Symbol !== 'undefined' && Symbol.species &&\n      Buffer[Symbol.species] === Buffer) {\n    // Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97\n    Object.defineProperty(Buffer, Symbol.species, {\n      value: null,\n      configurable: true\n    })\n  }\n}\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  } else if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n}\n\nfunction alloc (that, size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(that, size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpretted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(that, size).fill(fill, encoding)\n      : createBuffer(that, size).fill(fill)\n  }\n  return createBuffer(that, size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(null, size, fill, encoding)\n}\n\nfunction allocUnsafe (that, size) {\n  assertSize(size)\n  that = createBuffer(that, size < 0 ? 0 : checked(size) | 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) {\n    for (var i = 0; i < size; ++i) {\n      that[i] = 0\n    }\n  }\n  return that\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(null, size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(null, size)\n}\n\nfunction fromString (that, string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  var length = byteLength(string, encoding) | 0\n  that = createBuffer(that, length)\n\n  var actual = that.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    that = that.slice(0, actual)\n  }\n\n  return that\n}\n\nfunction fromArrayLike (that, array) {\n  var length = array.length < 0 ? 0 : checked(array.length) | 0\n  that = createBuffer(that, length)\n  for (var i = 0; i < length; i += 1) {\n    that[i] = array[i] & 255\n  }\n  return that\n}\n\nfunction fromArrayBuffer (that, array, byteOffset, length) {\n  array.byteLength // this throws if `array` is not a valid ArrayBuffer\n\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\\'offset\\' is out of bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\\'length\\' is out of bounds')\n  }\n\n  if (byteOffset === undefined && length === undefined) {\n    array = new Uint8Array(array)\n  } else if (length === undefined) {\n    array = new Uint8Array(array, byteOffset)\n  } else {\n    array = new Uint8Array(array, byteOffset, length)\n  }\n\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = array\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    that = fromArrayLike(that, array)\n  }\n  return that\n}\n\nfunction fromObject (that, obj) {\n  if (Buffer.isBuffer(obj)) {\n    var len = checked(obj.length) | 0\n    that = createBuffer(that, len)\n\n    if (that.length === 0) {\n      return that\n    }\n\n    obj.copy(that, 0, 0, len)\n    return that\n  }\n\n  if (obj) {\n    if ((typeof ArrayBuffer !== 'undefined' &&\n        obj.buffer instanceof ArrayBuffer) || 'length' in obj) {\n      if (typeof obj.length !== 'number' || isnan(obj.length)) {\n        return createBuffer(that, 0)\n      }\n      return fromArrayLike(that, obj)\n    }\n\n    if (obj.type === 'Buffer' && isArray(obj.data)) {\n      return fromArrayLike(that, obj.data)\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.')\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < kMaxLength()` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= kMaxLength()) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + kMaxLength().toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return !!(b != null && b._isBuffer)\n}\n\nBuffer.compare = function compare (a, b) {\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError('Arguments must be Buffers')\n  }\n\n  if (a === b) return 0\n\n  var x = a.length\n  var y = b.length\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  var i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  var buffer = Buffer.allocUnsafe(length)\n  var pos = 0\n  for (i = 0; i < list.length; ++i) {\n    var buf = list[i]\n    if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    }\n    buf.copy(buffer, pos)\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (typeof ArrayBuffer !== 'undefined' && typeof ArrayBuffer.isView === 'function' &&\n      (ArrayBuffer.isView(string) || string instanceof ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    string = '' + string\n  }\n\n  var len = string.length\n  if (len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n      case undefined:\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) return utf8ToBytes(string).length // assume utf8\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  var loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// The property is used by `Buffer.isBuffer` and `is-buffer` (in Safari 5-7) to detect\n// Buffer instances.\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  var i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  var len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (var i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  var len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (var i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  var len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (var i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  var length = this.length | 0\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  var str = ''\n  var max = exports.INSPECT_MAX_BYTES\n  if (this.length > 0) {\n    str = this.toString('hex', 0, max).match(/.{2}/g).join(' ')\n    if (this.length > max) str += ' ... '\n  }\n  return '<Buffer ' + str + '>'\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError('Argument must be a Buffer')\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  var x = thisEnd - thisStart\n  var y = end - start\n  var len = Math.min(x, y)\n\n  var thisCopy = this.slice(thisStart, thisEnd)\n  var targetCopy = target.slice(start, end)\n\n  for (var i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset  // Coerce to Number.\n  if (isNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (Buffer.TYPED_ARRAY_SUPPORT &&\n        typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  var indexSize = 1\n  var arrLength = arr.length\n  var valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  var i\n  if (dir) {\n    var foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      var found = true\n      for (var j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  var remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  // must be an even number of digits\n  var strLen = string.length\n  if (strLen % 2 !== 0) throw new TypeError('Invalid hex string')\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  for (var i = 0; i < length; ++i) {\n    var parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (isNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction latin1Write (buf, string, offset, length) {\n  return asciiWrite(buf, string, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset | 0\n    if (isFinite(length)) {\n      length = length | 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  // legacy write(string, encoding, offset, length) - remove in v0.13\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  var remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n        return asciiWrite(this, string, offset, length)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Write(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  var res = []\n\n  var i = start\n  while (i < end) {\n    var firstByte = buf[i]\n    var codePoint = null\n    var bytesPerSequence = (firstByte > 0xEF) ? 4\n      : (firstByte > 0xDF) ? 3\n      : (firstByte > 0xBF) ? 2\n      : 1\n\n    if (i + bytesPerSequence <= end) {\n      var secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nvar MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  var len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  var res = ''\n  var i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  var len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  var out = ''\n  for (var i = start; i < end; ++i) {\n    out += toHex(buf[i])\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  var bytes = buf.slice(start, end)\n  var res = ''\n  for (var i = 0; i < bytes.length; i += 2) {\n    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256)\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  var len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  var newBuf\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    newBuf = this.subarray(start, end)\n    newBuf.__proto__ = Buffer.prototype\n  } else {\n    var sliceLen = end - start\n    newBuf = new Buffer(sliceLen, undefined)\n    for (var i = 0; i < sliceLen; ++i) {\n      newBuf[i] = this[i + start]\n    }\n  }\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  var val = this[offset + --byteLength]\n  var mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var i = byteLength\n  var mul = 1\n  var val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var mul = 1\n  var i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nfunction objectWriteUInt16 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 2); i < j; ++i) {\n    buf[offset + i] = (value & (0xff << (8 * (littleEndian ? i : 1 - i)))) >>>\n      (littleEndian ? i : 1 - i) * 8\n  }\n}\n\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nfunction objectWriteUInt32 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffffffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 4); i < j; ++i) {\n    buf[offset + i] = (value >>> (littleEndian ? i : 3 - i) * 8) & 0xff\n  }\n}\n\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset + 3] = (value >>> 24)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 1] = (value >>> 8)\n    this[offset] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = 0\n  var mul = 1\n  var sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  var sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 3] = (value >>> 24)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('sourceStart out of bounds')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  var len = end - start\n  var i\n\n  if (this === target && start < targetStart && targetStart < end) {\n    // descending copy from end\n    for (i = len - 1; i >= 0; --i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else if (len < 1000 || !Buffer.TYPED_ARRAY_SUPPORT) {\n    // ascending copy from start\n    for (i = 0; i < len; ++i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, start + len),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (val.length === 1) {\n      var code = val.charCodeAt(0)\n      if (code < 256) {\n        val = code\n      }\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  var i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    var bytes = Buffer.isBuffer(val)\n      ? val\n      : utf8ToBytes(new Buffer(val, encoding).toString())\n    var len = bytes.length\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// HELPER FUNCTIONS\n// ================\n\nvar INVALID_BASE64_RE = /[^+\\/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = stringtrim(str).replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction stringtrim (str) {\n  if (str.trim) return str.trim()\n  return str.replace(/^\\s+|\\s+$/g, '')\n}\n\nfunction toHex (n) {\n  if (n < 16) return '0' + n.toString(16)\n  return n.toString(16)\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  var codePoint\n  var length = string.length\n  var leadSurrogate = null\n  var bytes = []\n\n  for (var i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  var c, hi, lo\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  for (var i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\nfunction isnan (val) {\n  return val !== val // eslint-disable-line no-self-compare\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/buffer/index.js?");

/***/ }),

/***/ "./node_modules/mongoDb/index.js":
/*!***************************************!*\
  !*** ./node_modules/mongoDb/index.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// Core module\nvar core = __webpack_require__(/*! mongodb-core */ \"mongodb-core\"),\n  Instrumentation = __webpack_require__(/*! ./lib/apm */ \"./node_modules/mongoDb/lib/apm.js\");\n\n// Set up the connect function\nvar connect = __webpack_require__(/*! ./lib/mongo_client */ \"./node_modules/mongoDb/lib/mongo_client.js\").connect;\n\n// Expose error class\nconnect.MongoError = core.MongoError;\n\n// Actual driver classes exported\nconnect.Admin = __webpack_require__(/*! ./lib/admin */ \"./node_modules/mongoDb/lib/admin.js\");\nconnect.MongoClient = __webpack_require__(/*! ./lib/mongo_client */ \"./node_modules/mongoDb/lib/mongo_client.js\");\nconnect.Db = __webpack_require__(/*! ./lib/db */ \"./node_modules/mongoDb/lib/db.js\");\nconnect.Collection = __webpack_require__(/*! ./lib/collection */ \"./node_modules/mongoDb/lib/collection.js\");\nconnect.Server = __webpack_require__(/*! ./lib/topologies/server */ \"./node_modules/mongoDb/lib/topologies/server.js\");\nconnect.ReplSet = __webpack_require__(/*! ./lib/topologies/replset */ \"./node_modules/mongoDb/lib/topologies/replset.js\");\nconnect.Mongos = __webpack_require__(/*! ./lib/topologies/mongos */ \"./node_modules/mongoDb/lib/topologies/mongos.js\");\nconnect.ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference;\nconnect.GridStore = __webpack_require__(/*! ./lib/gridfs/grid_store */ \"./node_modules/mongoDb/lib/gridfs/grid_store.js\");\nconnect.Chunk = __webpack_require__(/*! ./lib/gridfs/chunk */ \"./node_modules/mongoDb/lib/gridfs/chunk.js\");\nconnect.Logger = core.Logger;\nconnect.Cursor = __webpack_require__(/*! ./lib/cursor */ \"./node_modules/mongoDb/lib/cursor.js\");\nconnect.GridFSBucket = __webpack_require__(/*! ./lib/gridfs-stream */ \"./node_modules/mongoDb/lib/gridfs-stream/index.js\");\n// Exported to be used in tests not to be used anywhere else\nconnect.CoreServer = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Server;\nconnect.CoreConnection = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Connection;\n\n// BSON types exported\nconnect.Binary = core.BSON.Binary;\nconnect.Code = core.BSON.Code;\nconnect.Map = core.BSON.Map;\nconnect.DBRef = core.BSON.DBRef;\nconnect.Double = core.BSON.Double;\nconnect.Int32 = core.BSON.Int32;\nconnect.Long = core.BSON.Long;\nconnect.MinKey = core.BSON.MinKey;\nconnect.MaxKey = core.BSON.MaxKey;\nconnect.ObjectID = core.BSON.ObjectID;\nconnect.ObjectId = core.BSON.ObjectID;\nconnect.Symbol = core.BSON.Symbol;\nconnect.Timestamp = core.BSON.Timestamp;\nconnect.BSONRegExp = core.BSON.BSONRegExp;\nconnect.Decimal128 = core.BSON.Decimal128;\n\n// Add connect method\nconnect.connect = connect;\n\n// Set up the instrumentation method\nconnect.instrument = function(options, callback) {\n  if (typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n\n  return new Instrumentation(core, options, callback);\n};\n\n// Set our exports to be the connect function\nmodule.exports = connect;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/index.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/admin.js":
/*!*******************************************!*\
  !*** ./node_modules/mongoDb/lib/admin.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar toError = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").toError,\n  Define = __webpack_require__(/*! ./metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  shallowClone = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").shallowClone,\n  executeOperation = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation;\n\n/**\n * @fileOverview The **Admin** class is an internal class that allows convenient access to\n * the admin functionality and commands for MongoDB.\n *\n * **ADMIN Cannot directly be instantiated**\n * @example\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n *\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   // Use the admin database for the operation\n *   const adminDb = client.db(dbName).admin();\n *\n *   // List all the available databases\n *   adminDb.listDatabases(function(err, dbs) {\n *     test.equal(null, err);\n *     test.ok(dbs.databases.length > 0);\n *     client.close();\n *   });\n * });\n */\n\n/**\n * Create a new Admin instance (INTERNAL TYPE, do not instantiate directly)\n * @class\n * @return {Admin} a collection instance.\n */\nvar Admin = function(db, topology, promiseLibrary) {\n  if (!(this instanceof Admin)) return new Admin(db, topology);\n\n  // Internal state\n  this.s = {\n    db: db,\n    topology: topology,\n    promiseLibrary: promiseLibrary\n  };\n};\n\nvar define = (Admin.define = new Define('Admin', Admin, false));\n\n/**\n * The callback format for results\n * @callback Admin~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {object} result The result object if the command was executed successfully.\n */\n\n/**\n * Execute a command\n * @method\n * @param {object} command The command hash\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {number} [options.maxTimeMS=null] Number of milliseconds to wait before aborting the query.\n * @param {Admin~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.command = function(command, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() : {};\n\n  return executeOperation(this.s.db.s.topology, this.s.db.executeDbAdminCommand.bind(this.s.db), [\n    command,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('command', { callback: true, promise: true });\n\n/**\n * Retrieve the server information for the current\n * instance of the db client\n *\n * @param {Object} [options] optional parameters for this operation\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.buildInfo = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  const cmd = { buildinfo: 1 };\n  return executeOperation(this.s.db.s.topology, this.s.db.executeDbAdminCommand.bind(this.s.db), [\n    cmd,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('buildInfo', { callback: true, promise: true });\n\n/**\n * Retrieve the server information for the current\n * instance of the db client\n *\n * @param {Object} [options] optional parameters for this operation\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.serverInfo = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  const cmd = { buildinfo: 1 };\n  return executeOperation(this.s.db.s.topology, this.s.db.executeDbAdminCommand.bind(this.s.db), [\n    cmd,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('serverInfo', { callback: true, promise: true });\n\n/**\n * Retrieve this db's server status.\n *\n * @param {Object} [options] optional parameters for this operation\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.serverStatus = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.db.s.topology, serverStatus, [this, options, callback]);\n};\n\nvar serverStatus = function(self, options, callback) {\n  self.s.db.executeDbAdminCommand({ serverStatus: 1 }, options, function(err, doc) {\n    if (err == null && doc.ok === 1) {\n      callback(null, doc);\n    } else {\n      if (err) return callback(err, false);\n      return callback(toError(doc), false);\n    }\n  });\n};\n\ndefine.classMethod('serverStatus', { callback: true, promise: true });\n\n/**\n * Ping the MongoDB server and retrieve results\n *\n * @param {Object} [options] optional parameters for this operation\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.ping = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  const cmd = { ping: 1 };\n  return executeOperation(this.s.db.s.topology, this.s.db.executeDbAdminCommand.bind(this.s.db), [\n    cmd,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('ping', { callback: true, promise: true });\n\n// Get write concern\nvar writeConcern = function(options, db) {\n  options = shallowClone(options);\n\n  // If options already contain write concerns return it\n  if (options.w || options.wtimeout || options.j || options.fsync) {\n    return options;\n  }\n\n  // Set db write concern if available\n  if (db.writeConcern) {\n    if (options.w) options.w = db.writeConcern.w;\n    if (options.wtimeout) options.wtimeout = db.writeConcern.wtimeout;\n    if (options.j) options.j = db.writeConcern.j;\n    if (options.fsync) options.fsync = db.writeConcern.fsync;\n  }\n\n  // Return modified options\n  return options;\n};\n\n/**\n * Add a user to the database.\n * @method\n * @param {string} username The username.\n * @param {string} password The password.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.fsync=false] Specify a file sync write concern.\n * @param {object} [options.customData=null] Custom data associated with the user (only Mongodb 2.6 or higher)\n * @param {object[]} [options.roles=null] Roles associated with the created user (only Mongodb 2.6 or higher)\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.addUser = function(username, password, options, callback) {\n  var self = this;\n  var args = Array.prototype.slice.call(arguments, 2);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n\n  options = args.length ? args.shift() : {};\n  options = options || {};\n  // Get the options\n  options = writeConcern(options, self.s.db);\n  // Set the db name to admin\n  options.dbName = 'admin';\n\n  return executeOperation(this.s.db.s.topology, this.s.db.addUser.bind(this.s.db), [\n    username,\n    password,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('addUser', { callback: true, promise: true });\n\n/**\n * Remove a user from a database\n * @method\n * @param {string} username The username.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.fsync=false] Specify a file sync write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.removeUser = function(username, options, callback) {\n  var self = this;\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n\n  options = args.length ? args.shift() : {};\n  options = options || {};\n  // Get the options\n  options = writeConcern(options, self.s.db);\n  // Set the db name\n  options.dbName = 'admin';\n\n  return executeOperation(this.s.db.s.topology, this.s.db.removeUser.bind(this.s.db), [\n    username,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('removeUser', { callback: true, promise: true });\n\n/**\n * Validate an existing collection\n *\n * @param {string} collectionName The name of the collection to validate.\n * @param {object} [options=null] Optional settings.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.validateCollection = function(collectionName, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.db.s.topology, validateCollection, [\n    this,\n    collectionName,\n    options,\n    callback\n  ]);\n};\n\nvar validateCollection = function(self, collectionName, options, callback) {\n  var command = { validate: collectionName };\n  var keys = Object.keys(options);\n\n  // Decorate command with extra options\n  for (var i = 0; i < keys.length; i++) {\n    if (options.hasOwnProperty(keys[i]) && keys[i] !== 'session') {\n      command[keys[i]] = options[keys[i]];\n    }\n  }\n\n  self.s.db.command(command, options, function(err, doc) {\n    if (err != null) return callback(err, null);\n\n    if (doc.ok === 0) return callback(new Error('Error with validate command'), null);\n    if (doc.result != null && doc.result.constructor !== String)\n      return callback(new Error('Error with validation data'), null);\n    if (doc.result != null && doc.result.match(/exception|corrupt/) != null)\n      return callback(new Error('Error: invalid collection ' + collectionName), null);\n    if (doc.valid != null && !doc.valid)\n      return callback(new Error('Error: invalid collection ' + collectionName), null);\n\n    return callback(null, doc);\n  });\n};\n\ndefine.classMethod('validateCollection', { callback: true, promise: true });\n\n/**\n * List the available databases\n *\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.nameOnly=false] Whether the command should return only db names, or names and size info.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.listDatabases = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  var cmd = { listDatabases: 1 };\n  if (options.nameOnly) cmd.nameOnly = Number(cmd.nameOnly);\n  return executeOperation(this.s.db.s.topology, this.s.db.executeDbAdminCommand.bind(this.s.db), [\n    cmd,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('listDatabases', { callback: true, promise: true });\n\n/**\n * Get ReplicaSet status\n *\n * @param {Object} [options] optional parameters for this operation\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Admin~resultCallback} [callback] The command result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nAdmin.prototype.replSetGetStatus = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.db.s.topology, replSetGetStatus, [this, options, callback]);\n};\n\nvar replSetGetStatus = function(self, options, callback) {\n  self.s.db.executeDbAdminCommand({ replSetGetStatus: 1 }, options, function(err, doc) {\n    if (err == null && doc.ok === 1) return callback(null, doc);\n    if (err) return callback(err, false);\n    callback(toError(doc), false);\n  });\n};\n\ndefine.classMethod('replSetGetStatus', { callback: true, promise: true });\n\nmodule.exports = Admin;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/admin.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/aggregation_cursor.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoDb/lib/aggregation_cursor.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  Readable = __webpack_require__(/*! stream */ \"stream\").Readable,\n  Define = __webpack_require__(/*! ./metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  CoreCursor = __webpack_require__(/*! ./cursor */ \"./node_modules/mongoDb/lib/cursor.js\");\n\n/**\n * @fileOverview The **AggregationCursor** class is an internal class that embodies an aggregation cursor on MongoDB\n * allowing for iteration over the results returned from the underlying query. It supports\n * one by one document iteration, conversion to an array or can be iterated as a Node 4.X\n * or higher stream\n *\n * **AGGREGATIONCURSOR Cannot directly be instantiated**\n * @example\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   // Create a collection we want to drop later\n *   const col = client.db(dbName).collection('createIndexExample1');\n *   // Insert a bunch of documents\n *   col.insert([{a:1, b:1}\n *     , {a:2, b:2}, {a:3, b:3}\n *     , {a:4, b:4}], {w:1}, function(err, result) {\n *     test.equal(null, err);\n *     // Show that duplicate records got dropped\n *     col.aggregation({}, {cursor: {}}).toArray(function(err, items) {\n *       test.equal(null, err);\n *       test.equal(4, items.length);\n *       client.close();\n *     });\n *   });\n * });\n */\n\n/**\n * Namespace provided by the browser.\n * @external Readable\n */\n\n/**\n * Creates a new Aggregation Cursor instance (INTERNAL TYPE, do not instantiate directly)\n * @class AggregationCursor\n * @extends external:Readable\n * @fires AggregationCursor#data\n * @fires AggregationCursor#end\n * @fires AggregationCursor#close\n * @fires AggregationCursor#readable\n * @return {AggregationCursor} an AggregationCursor instance.\n */\nvar AggregationCursor = function(bson, ns, cmd, options, topology, topologyOptions) {\n  CoreCursor.apply(this, Array.prototype.slice.call(arguments, 0));\n  var state = AggregationCursor.INIT;\n  var streamOptions = {};\n\n  // MaxTimeMS\n  var maxTimeMS = null;\n\n  // Get the promiseLibrary\n  var promiseLibrary = options.promiseLibrary || Promise;\n\n  // Set up\n  Readable.call(this, { objectMode: true });\n\n  // Internal state\n  this.s = {\n    // MaxTimeMS\n    maxTimeMS: maxTimeMS,\n    // State\n    state: state,\n    // Stream options\n    streamOptions: streamOptions,\n    // BSON\n    bson: bson,\n    // Namespace\n    ns: ns,\n    // Command\n    cmd: cmd,\n    // Options\n    options: options,\n    // Topology\n    topology: topology,\n    // Topology Options\n    topologyOptions: topologyOptions,\n    // Promise library\n    promiseLibrary: promiseLibrary\n  };\n};\n\n/**\n * AggregationCursor stream data event, fired for each document in the cursor.\n *\n * @event AggregationCursor#data\n * @type {object}\n */\n\n/**\n * AggregationCursor stream end event\n *\n * @event AggregationCursor#end\n * @type {null}\n */\n\n/**\n * AggregationCursor stream close event\n *\n * @event AggregationCursor#close\n * @type {null}\n */\n\n/**\n * AggregationCursor stream readable event\n *\n * @event AggregationCursor#readable\n * @type {null}\n */\n\n// Inherit from Readable\ninherits(AggregationCursor, Readable);\n\n// Extend the Cursor\nfor (var name in CoreCursor.prototype) {\n  AggregationCursor.prototype[name] = CoreCursor.prototype[name];\n}\n\nvar define = (AggregationCursor.define = new Define('AggregationCursor', AggregationCursor, true));\n\n/**\n * Set the batch size for the cursor.\n * @method\n * @param {number} value The batchSize for the cursor.\n * @throws {MongoError}\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.batchSize = function(value) {\n  if (this.s.state === AggregationCursor.CLOSED || this.isDead())\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  if (typeof value !== 'number')\n    throw MongoError.create({ message: 'batchSize requires an integer', drvier: true });\n  if (this.s.cmd.cursor) this.s.cmd.cursor.batchSize = value;\n  this.setCursorBatchSize(value);\n  return this;\n};\n\ndefine.classMethod('batchSize', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a geoNear stage to the aggregation pipeline\n * @method\n * @param {object} document The geoNear stage document.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.geoNear = function(document) {\n  this.s.cmd.pipeline.push({ $geoNear: document });\n  return this;\n};\n\ndefine.classMethod('geoNear', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a group stage to the aggregation pipeline\n * @method\n * @param {object} document The group stage document.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.group = function(document) {\n  this.s.cmd.pipeline.push({ $group: document });\n  return this;\n};\n\ndefine.classMethod('group', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a limit stage to the aggregation pipeline\n * @method\n * @param {number} value The state limit value.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.limit = function(value) {\n  this.s.cmd.pipeline.push({ $limit: value });\n  return this;\n};\n\ndefine.classMethod('limit', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a match stage to the aggregation pipeline\n * @method\n * @param {object} document The match stage document.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.match = function(document) {\n  this.s.cmd.pipeline.push({ $match: document });\n  return this;\n};\n\ndefine.classMethod('match', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a maxTimeMS stage to the aggregation pipeline\n * @method\n * @param {number} value The state maxTimeMS value.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.maxTimeMS = function(value) {\n  if (this.s.topology.lastIsMaster().minWireVersion > 2) {\n    this.s.cmd.maxTimeMS = value;\n  }\n  return this;\n};\n\ndefine.classMethod('maxTimeMS', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a out stage to the aggregation pipeline\n * @method\n * @param {number} destination The destination name.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.out = function(destination) {\n  this.s.cmd.pipeline.push({ $out: destination });\n  return this;\n};\n\ndefine.classMethod('out', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a project stage to the aggregation pipeline\n * @method\n * @param {object} document The project stage document.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.project = function(document) {\n  this.s.cmd.pipeline.push({ $project: document });\n  return this;\n};\n\ndefine.classMethod('project', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a lookup stage to the aggregation pipeline\n * @method\n * @param {object} document The lookup stage document.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.lookup = function(document) {\n  this.s.cmd.pipeline.push({ $lookup: document });\n  return this;\n};\n\ndefine.classMethod('lookup', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a redact stage to the aggregation pipeline\n * @method\n * @param {object} document The redact stage document.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.redact = function(document) {\n  this.s.cmd.pipeline.push({ $redact: document });\n  return this;\n};\n\ndefine.classMethod('redact', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a skip stage to the aggregation pipeline\n * @method\n * @param {number} value The state skip value.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.skip = function(value) {\n  this.s.cmd.pipeline.push({ $skip: value });\n  return this;\n};\n\ndefine.classMethod('skip', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a sort stage to the aggregation pipeline\n * @method\n * @param {object} document The sort stage document.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.sort = function(document) {\n  this.s.cmd.pipeline.push({ $sort: document });\n  return this;\n};\n\ndefine.classMethod('sort', { callback: false, promise: false, returns: [AggregationCursor] });\n\n/**\n * Add a unwind stage to the aggregation pipeline\n * @method\n * @param {number} field The unwind field name.\n * @return {AggregationCursor}\n */\nAggregationCursor.prototype.unwind = function(field) {\n  this.s.cmd.pipeline.push({ $unwind: field });\n  return this;\n};\n\ndefine.classMethod('unwind', { callback: false, promise: false, returns: [AggregationCursor] });\n\nAggregationCursor.prototype.get = AggregationCursor.prototype.toArray;\n\n// Inherited methods\ndefine.classMethod('toArray', { callback: true, promise: true });\ndefine.classMethod('each', { callback: true, promise: false });\ndefine.classMethod('forEach', { callback: true, promise: false });\ndefine.classMethod('hasNext', { callback: true, promise: true });\ndefine.classMethod('next', { callback: true, promise: true });\ndefine.classMethod('close', { callback: true, promise: true });\ndefine.classMethod('isClosed', { callback: false, promise: false, returns: [Boolean] });\ndefine.classMethod('rewind', { callback: false, promise: false });\ndefine.classMethod('bufferedCount', { callback: false, promise: false, returns: [Number] });\ndefine.classMethod('readBufferedDocuments', { callback: false, promise: false, returns: [Array] });\n\n/**\n * Get the next available document from the cursor, returns null if no more documents are available.\n * @function AggregationCursor.prototype.next\n * @param {AggregationCursor~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * Check if there is any document still available in the cursor\n * @function AggregationCursor.prototype.hasNext\n * @param {AggregationCursor~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * The callback format for results\n * @callback AggregationCursor~toArrayResultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {object[]} documents All the documents the satisfy the cursor.\n */\n\n/**\n * Returns an array of documents. The caller is responsible for making sure that there\n * is enough memory to store the results. Note that the array only contain partial\n * results when this cursor had been previouly accessed. In that case,\n * cursor.rewind() can be used to reset the cursor.\n * @method AggregationCursor.prototype.toArray\n * @param {AggregationCursor~toArrayResultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * The callback format for results\n * @callback AggregationCursor~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {(object|null)} result The result object if the command was executed successfully.\n */\n\n/**\n * Iterates over all the documents for this cursor. As with **{cursor.toArray}**,\n * not all of the elements will be iterated if this cursor had been previouly accessed.\n * In that case, **{cursor.rewind}** can be used to reset the cursor. However, unlike\n * **{cursor.toArray}**, the cursor will only hold a maximum of batch size elements\n * at any given time if batch size is specified. Otherwise, the caller is responsible\n * for making sure that the entire result can fit the memory.\n * @method AggregationCursor.prototype.each\n * @param {AggregationCursor~resultCallback} callback The result callback.\n * @throws {MongoError}\n * @return {null}\n */\n\n/**\n * Close the cursor, sending a AggregationCursor command and emitting close.\n * @method AggregationCursor.prototype.close\n * @param {AggregationCursor~resultCallback} [callback] The result callback.\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * Is the cursor closed\n * @method AggregationCursor.prototype.isClosed\n * @return {boolean}\n */\n\n/**\n * Execute the explain for the cursor\n * @method AggregationCursor.prototype.explain\n * @param {AggregationCursor~resultCallback} [callback] The result callback.\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * Clone the cursor\n * @function AggregationCursor.prototype.clone\n * @return {AggregationCursor}\n */\n\n/**\n * Resets the cursor\n * @function AggregationCursor.prototype.rewind\n * @return {AggregationCursor}\n */\n\n/**\n * The callback format for the forEach iterator method\n * @callback AggregationCursor~iteratorCallback\n * @param {Object} doc An emitted document for the iterator\n */\n\n/**\n * The callback error format for the forEach iterator method\n * @callback AggregationCursor~endCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n */\n\n/*\n * Iterates over all the documents for this cursor using the iterator, callback pattern.\n * @method AggregationCursor.prototype.forEach\n * @param {AggregationCursor~iteratorCallback} iterator The iteration callback.\n * @param {AggregationCursor~endCallback} callback The end callback.\n * @throws {MongoError}\n * @return {null}\n */\n\nAggregationCursor.INIT = 0;\nAggregationCursor.OPEN = 1;\nAggregationCursor.CLOSED = 2;\n\nmodule.exports = AggregationCursor;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/aggregation_cursor.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/apm.js":
/*!*****************************************!*\
  !*** ./node_modules/mongoDb/lib/apm.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter,\n  inherits = __webpack_require__(/*! util */ \"util\").inherits;\n\n// Get prototypes\nvar AggregationCursor = __webpack_require__(/*! ./aggregation_cursor */ \"./node_modules/mongoDb/lib/aggregation_cursor.js\"),\n  CommandCursor = __webpack_require__(/*! ./command_cursor */ \"./node_modules/mongoDb/lib/command_cursor.js\"),\n  OrderedBulkOperation = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongoDb/lib/bulk/ordered.js\").OrderedBulkOperation,\n  UnorderedBulkOperation = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongoDb/lib/bulk/unordered.js\").UnorderedBulkOperation,\n  GridStore = __webpack_require__(/*! ./gridfs/grid_store */ \"./node_modules/mongoDb/lib/gridfs/grid_store.js\"),\n  Cursor = __webpack_require__(/*! ./cursor */ \"./node_modules/mongoDb/lib/cursor.js\"),\n  Collection = __webpack_require__(/*! ./collection */ \"./node_modules/mongoDb/lib/collection.js\"),\n  Db = __webpack_require__(/*! ./db */ \"./node_modules/mongoDb/lib/db.js\");\n\nvar basicOperationIdGenerator = {\n  operationId: 1,\n\n  next: function() {\n    return this.operationId++;\n  }\n};\n\nvar basicTimestampGenerator = {\n  current: function() {\n    return new Date().getTime();\n  },\n\n  duration: function(start, end) {\n    return end - start;\n  }\n};\n\nvar senstiveCommands = [\n  'authenticate',\n  'saslStart',\n  'saslContinue',\n  'getnonce',\n  'createUser',\n  'updateUser',\n  'copydbgetnonce',\n  'copydbsaslstart',\n  'copydb'\n];\n\nvar Instrumentation = function(core, options, callback) {\n  options = options || {};\n\n  // Optional id generators\n  var operationIdGenerator = options.operationIdGenerator || basicOperationIdGenerator;\n  // Optional timestamp generator\n  var timestampGenerator = options.timestampGenerator || basicTimestampGenerator;\n  // Extend with event emitter functionality\n  EventEmitter.call(this);\n\n  // Contains all the instrumentation overloads\n  this.overloads = [];\n\n  // ---------------------------------------------------------\n  //\n  // Instrument prototype\n  //\n  // ---------------------------------------------------------\n\n  var instrumentPrototype = function(callback) {\n    var instrumentations = [];\n\n    // Classes to support\n    var classes = [\n      GridStore,\n      OrderedBulkOperation,\n      UnorderedBulkOperation,\n      CommandCursor,\n      AggregationCursor,\n      Cursor,\n      Collection,\n      Db\n    ];\n\n    // Add instrumentations to the available list\n    for (var i = 0; i < classes.length; i++) {\n      if (classes[i].define) {\n        instrumentations.push(classes[i].define.generate());\n      }\n    }\n\n    // Return the list of instrumentation points\n    callback(null, instrumentations);\n  };\n\n  // Did the user want to instrument the prototype\n  if (typeof callback === 'function') {\n    instrumentPrototype(callback);\n  }\n\n  // ---------------------------------------------------------\n  //\n  // Server\n  //\n  // ---------------------------------------------------------\n\n  // Reference\n  var self = this;\n  // Names of methods we need to wrap\n  var methods = ['command', 'insert', 'update', 'remove'];\n  // Prototype\n  var proto = core.Server.prototype;\n  // Core server method we are going to wrap\n  methods.forEach(function(x) {\n    var func = proto[x];\n\n    // Add to overloaded methods\n    self.overloads.push({ proto: proto, name: x, func: func });\n\n    // The actual prototype\n    proto[x] = function() {\n      var requestId = core.Query.nextRequestId();\n      // Get the aruments\n      var args = Array.prototype.slice.call(arguments, 0);\n      var ns = args[0];\n      var commandObj = args[1];\n      var options = args[2] || {};\n      var keys = Object.keys(commandObj);\n      var commandName = keys[0];\n      var db = ns.split('.')[0];\n\n      // Get the collection\n      var col = ns.split('.');\n      col.shift();\n      col = col.join('.');\n\n      // Do we have a legacy insert/update/remove command\n      if (x === 'insert') {\n        //} && !this.lastIsMaster().maxWireVersion) {\n        commandName = 'insert';\n\n        // Re-write the command\n        commandObj = {\n          insert: col,\n          documents: commandObj\n        };\n\n        if (options.writeConcern && Object.keys(options.writeConcern).length > 0) {\n          commandObj.writeConcern = options.writeConcern;\n        }\n\n        commandObj.ordered = options.ordered !== undefined ? options.ordered : true;\n      } else if (x === 'update') {\n        // && !this.lastIsMaster().maxWireVersion) {\n        commandName = 'update';\n\n        // Re-write the command\n        commandObj = {\n          update: col,\n          updates: commandObj\n        };\n\n        if (options.writeConcern && Object.keys(options.writeConcern).length > 0) {\n          commandObj.writeConcern = options.writeConcern;\n        }\n\n        commandObj.ordered = options.ordered !== undefined ? options.ordered : true;\n      } else if (x === 'remove') {\n        //&& !this.lastIsMaster().maxWireVersion) {\n        commandName = 'delete';\n\n        // Re-write the command\n        commandObj = {\n          delete: col,\n          deletes: commandObj\n        };\n\n        if (options.writeConcern && Object.keys(options.writeConcern).length > 0) {\n          commandObj.writeConcern = options.writeConcern;\n        }\n\n        commandObj.ordered = options.ordered !== undefined ? options.ordered : true;\n      }\n\n      // Get the callback\n      var callback = args.pop();\n      // Set current callback operation id from the current context or create\n      // a new one\n      var ourOpId = callback.operationId || operationIdGenerator.next();\n\n      // Get a connection reference for this server instance\n      var connection = this.s.pool.get();\n\n      // Emit the start event for the command\n      var command = {\n        // Returns the command.\n        command: commandObj,\n        // Returns the database name.\n        databaseName: db,\n        // Returns the command name.\n        commandName: commandName,\n        // Returns the driver generated request id.\n        requestId: requestId,\n        // Returns the driver generated operation id.\n        // This is used to link events together such as bulk write operations. OPTIONAL.\n        operationId: ourOpId,\n        // Returns the connection id for the command. For languages that do not have this,\n        // this MUST return the driver equivalent which MUST include the server address and port.\n        // The name of this field is flexible to match the object that is returned from the driver.\n        connectionId: connection\n      };\n\n      // Filter out any sensitive commands\n      if (senstiveCommands.indexOf(commandName.toLowerCase()) !== -1) {\n        command.commandObj = {};\n        command.commandObj[commandName] = true;\n      }\n\n      // Emit the started event\n      self.emit('started', command);\n\n      // Start time\n      var startTime = timestampGenerator.current();\n\n      // Push our handler callback\n      args.push(function(err, r) {\n        var endTime = timestampGenerator.current();\n        var command = {\n          duration: timestampGenerator.duration(startTime, endTime),\n          commandName: commandName,\n          requestId: requestId,\n          operationId: ourOpId,\n          connectionId: connection\n        };\n\n        // If we have an error\n        if (err || (r && r.result && r.result.ok === 0)) {\n          command.failure = err || r.result.writeErrors || r.result;\n\n          // Filter out any sensitive commands\n          if (senstiveCommands.indexOf(commandName.toLowerCase()) !== -1) {\n            command.failure = {};\n          }\n\n          self.emit('failed', command);\n        } else if (commandObj && commandObj.writeConcern && commandObj.writeConcern.w === 0) {\n          // If we have write concern 0\n          command.reply = { ok: 1 };\n          self.emit('succeeded', command);\n        } else {\n          command.reply = r && r.result ? r.result : r;\n\n          // Filter out any sensitive commands\n          if (senstiveCommands.indexOf(commandName.toLowerCase()) !== -1) {\n            command.reply = {};\n          }\n\n          self.emit('succeeded', command);\n        }\n\n        // Return to caller\n        callback(err, r);\n      });\n\n      // Apply the call\n      func.apply(this, args);\n    };\n  });\n\n  // ---------------------------------------------------------\n  //\n  // Bulk Operations\n  //\n  // ---------------------------------------------------------\n\n  // Inject ourselves into the Bulk methods\n  methods = ['execute'];\n  var prototypes = [\n    __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongoDb/lib/bulk/ordered.js\").Bulk.prototype,\n    __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongoDb/lib/bulk/unordered.js\").Bulk.prototype\n  ];\n\n  prototypes.forEach(function(proto) {\n    // Core server method we are going to wrap\n    methods.forEach(function(x) {\n      var func = proto[x];\n\n      // Add to overloaded methods\n      self.overloads.push({ proto: proto, name: x, func: func });\n\n      // The actual prototype\n      proto[x] = function() {\n        // Get the aruments\n        var args = Array.prototype.slice.call(arguments, 0);\n        // Set an operation Id on the bulk object\n        this.operationId = operationIdGenerator.next();\n\n        // Get the callback\n        var callback = args.pop();\n        // If we have a callback use this\n        if (typeof callback === 'function') {\n          args.push(function(err, r) {\n            // Return to caller\n            callback(err, r);\n          });\n\n          // Apply the call\n          func.apply(this, args);\n        } else {\n          return func.apply(this, args);\n        }\n      };\n    });\n  });\n\n  // ---------------------------------------------------------\n  //\n  // Cursor\n  //\n  // ---------------------------------------------------------\n\n  // Inject ourselves into the Cursor methods\n  methods = ['_find', '_getmore', '_killcursor'];\n  prototypes = [\n    __webpack_require__(/*! ./cursor */ \"./node_modules/mongoDb/lib/cursor.js\").prototype,\n    __webpack_require__(/*! ./command_cursor */ \"./node_modules/mongoDb/lib/command_cursor.js\").prototype,\n    __webpack_require__(/*! ./aggregation_cursor */ \"./node_modules/mongoDb/lib/aggregation_cursor.js\").prototype\n  ];\n\n  // Command name translation\n  var commandTranslation = {\n    _find: 'find',\n    _getmore: 'getMore',\n    _killcursor: 'killCursors',\n    _explain: 'explain'\n  };\n\n  prototypes.forEach(function(proto) {\n    // Core server method we are going to wrap\n    methods.forEach(function(x) {\n      var func = proto[x];\n\n      // Add to overloaded methods\n      self.overloads.push({ proto: proto, name: x, func: func });\n\n      // The actual prototype\n      proto[x] = function() {\n        var cursor = this;\n        var requestId = core.Query.nextRequestId();\n        var ourOpId = operationIdGenerator.next();\n        var parts = this.ns.split('.');\n        var db = parts[0];\n\n        // Get the collection\n        parts.shift();\n        var collection = parts.join('.');\n\n        // Set the command\n        var command = this.query;\n        var cmd = this.s.cmd;\n\n        // If we have a find method, set the operationId on the cursor\n        if (x === '_find') {\n          cursor.operationId = ourOpId;\n        }\n\n        // Do we have a find command rewrite it\n        if (x === '_getmore') {\n          command = {\n            getMore: this.cursorState.cursorId,\n            collection: collection,\n            batchSize: cmd.batchSize\n          };\n\n          if (cmd.maxTimeMS) command.maxTimeMS = cmd.maxTimeMS;\n        } else if (x === '_killcursor') {\n          command = {\n            killCursors: collection,\n            cursors: [this.cursorState.cursorId]\n          };\n        } else if (cmd.find) {\n          command = {\n            find: collection,\n            filter: cmd.query\n          };\n\n          if (cmd.sort) command.sort = cmd.sort;\n          if (cmd.fields) command.projection = cmd.fields;\n          if (cmd.limit && cmd.limit < 0) {\n            command.limit = Math.abs(cmd.limit);\n            command.singleBatch = true;\n          } else if (cmd.limit) {\n            command.limit = Math.abs(cmd.limit);\n          }\n\n          // Options\n          if (cmd.skip) command.skip = cmd.skip;\n          if (cmd.hint) command.hint = cmd.hint;\n          if (cmd.batchSize) command.batchSize = cmd.batchSize;\n          if (typeof cmd.returnKey === 'boolean') command.returnKey = cmd.returnKey;\n          if (cmd.comment) command.comment = cmd.comment;\n          if (cmd.min) command.min = cmd.min;\n          if (cmd.max) command.max = cmd.max;\n          if (cmd.maxScan) command.maxScan = cmd.maxScan;\n          if (cmd.maxTimeMS) command.maxTimeMS = cmd.maxTimeMS;\n\n          // Flags\n          if (typeof cmd.awaitData === 'boolean') command.awaitData = cmd.awaitData;\n          if (typeof cmd.snapshot === 'boolean') command.snapshot = cmd.snapshot;\n          if (typeof cmd.tailable === 'boolean') command.tailable = cmd.tailable;\n          if (typeof cmd.oplogReplay === 'boolean') command.oplogReplay = cmd.oplogReplay;\n          if (typeof cmd.noCursorTimeout === 'boolean')\n            command.noCursorTimeout = cmd.noCursorTimeout;\n          if (typeof cmd.partial === 'boolean') command.partial = cmd.partial;\n          if (typeof cmd.showDiskLoc === 'boolean') command.showRecordId = cmd.showDiskLoc;\n\n          // Read Concern\n          if (cmd.readConcern) command.readConcern = cmd.readConcern;\n\n          // Override method\n          if (cmd.explain) command.explain = cmd.explain;\n          if (cmd.exhaust) command.exhaust = cmd.exhaust;\n\n          // If we have a explain flag\n          if (cmd.explain) {\n            // Create fake explain command\n            command = {\n              explain: command,\n              verbosity: 'allPlansExecution'\n            };\n\n            // Set readConcern on the command if available\n            if (cmd.readConcern) command.readConcern = cmd.readConcern;\n\n            // Set up the _explain name for the command\n            x = '_explain';\n          }\n        } else {\n          command = cmd;\n        }\n\n        // Set up the connection\n        var connectionId = null;\n\n        // Set local connection\n        if (this.connection) connectionId = this.connection;\n        if (!connectionId && this.topology && this.topology.getConnection)\n          connectionId = this.topology.getConnection();\n\n        // Get the command Name\n        var commandName = x === '_find' ? Object.keys(command)[0] : commandTranslation[x];\n\n        // Emit the start event for the command\n        command = {\n          // Returns the command.\n          command: command,\n          // Returns the database name.\n          databaseName: db,\n          // Returns the command name.\n          commandName: commandName,\n          // Returns the driver generated request id.\n          requestId: requestId,\n          // Returns the driver generated operation id.\n          // This is used to link events together such as bulk write operations. OPTIONAL.\n          operationId: this.operationId,\n          // Returns the connection id for the command. For languages that do not have this,\n          // this MUST return the driver equivalent which MUST include the server address and port.\n          // The name of this field is flexible to match the object that is returned from the driver.\n          connectionId: connectionId\n        };\n\n        // Get the aruments\n        var args = Array.prototype.slice.call(arguments, 0);\n\n        // Get the callback\n        var callback = args.pop();\n\n        // We do not have a callback but a Promise\n        if (typeof callback === 'function' || command.commandName === 'killCursors') {\n          var startTime = timestampGenerator.current();\n          // Emit the started event\n          self.emit('started', command);\n\n          // Emit succeeded event with killcursor if we have a legacy protocol\n          if (\n            command.commandName === 'killCursors' &&\n            this.topology.lastIsMaster() &&\n            this.topology.lastIsMaster().maxWireVersion < 4\n          ) {\n            // Emit the succeeded command\n            command = {\n              duration: timestampGenerator.duration(startTime, timestampGenerator.current()),\n              commandName: commandName,\n              requestId: requestId,\n              operationId: cursor.operationId,\n              connectionId: cursor.topology.getConnection(),\n              reply: [{ ok: 1 }]\n            };\n\n            // Apply callback to the list of args\n            args.push(callback);\n            // Apply the call\n            func.apply(this, args);\n            // Emit the command\n            return self.emit('succeeded', command);\n          }\n\n          // Add our callback handler\n          args.push(function(err, r) {\n            if (err) {\n              // Command\n              var command = {\n                duration: timestampGenerator.duration(startTime, timestampGenerator.current()),\n                commandName: commandName,\n                requestId: requestId,\n                operationId: ourOpId,\n                connectionId: cursor.topology.getConnection(),\n                failure: err\n              };\n\n              // Emit the command\n              self.emit('failed', command);\n            } else {\n              if (r && r.documents) {\n                r = r.documents[0];\n              }\n\n              if (commandName.toLowerCase() === 'getmore' && (r == null || r.cursor == null)) {\n                r = {\n                  cursor: {\n                    id: cursor.cursorState.cursorId,\n                    ns: cursor.ns,\n                    nextBatch: cursor.cursorState.documents\n                  },\n                  ok: 1\n                };\n              } else if (\n                (commandName.toLowerCase() === 'find' ||\n                  commandName.toLowerCase() === 'aggregate' ||\n                  commandName.toLowerCase() === 'listcollections') &&\n                (r == null || r.cursor == null)\n              ) {\n                r = {\n                  cursor: {\n                    id: cursor.cursorState.cursorId,\n                    ns: cursor.ns,\n                    firstBatch: cursor.cursorState.documents\n                  },\n                  ok: 1\n                };\n              } else if (commandName.toLowerCase() === 'killcursors' && r == null) {\n                r = {\n                  cursorsUnknown: [cursor.cursorState.lastCursorId],\n                  ok: 1\n                };\n              }\n\n              // cursor id is zero, we can issue success command\n              command = {\n                duration: timestampGenerator.duration(startTime, timestampGenerator.current()),\n                commandName: commandName,\n                requestId: requestId,\n                operationId: cursor.operationId,\n                connectionId: cursor.topology.getConnection(),\n                reply: r && r.result ? r.result : r\n              };\n\n              // Emit the command\n              self.emit('succeeded', command);\n            }\n\n            // Return\n            if (!callback) return;\n\n            // Return to caller\n            callback(err, r);\n          });\n\n          // Apply the call\n          func.apply(this, args);\n        } else {\n          // Assume promise, push back the missing value\n          args.push(callback);\n          // Get the promise\n          var promise = func.apply(this, args);\n          // Return a new promise\n          return new cursor.s.promiseLibrary(function(resolve, reject) {\n            var startTime = timestampGenerator.current();\n            // Emit the started event\n            self.emit('started', command);\n            // Execute the function\n            promise\n              .then(function() {\n                // cursor id is zero, we can issue success command\n                var command = {\n                  duration: timestampGenerator.duration(startTime, timestampGenerator.current()),\n                  commandName: commandName,\n                  requestId: requestId,\n                  operationId: cursor.operationId,\n                  connectionId: cursor.topology.getConnection(),\n                  reply: cursor.cursorState.documents\n                };\n\n                // Emit the command\n                self.emit('succeeded', command);\n              })\n              .catch(function(err) {\n                // Command\n                var command = {\n                  duration: timestampGenerator.duration(startTime, timestampGenerator.current()),\n                  commandName: commandName,\n                  requestId: requestId,\n                  operationId: ourOpId,\n                  connectionId: cursor.topology.getConnection(),\n                  failure: err\n                };\n\n                // Emit the command\n                self.emit('failed', command);\n                // reject the promise\n                reject(err);\n              });\n          });\n        }\n      };\n    });\n  });\n};\n\ninherits(Instrumentation, EventEmitter);\n\nInstrumentation.prototype.uninstrument = function() {\n  for (var i = 0; i < this.overloads.length; i++) {\n    var obj = this.overloads[i];\n    obj.proto[obj.name] = obj.func;\n  }\n\n  // Remove all listeners\n  this.removeAllListeners('started');\n  this.removeAllListeners('succeeded');\n  this.removeAllListeners('failed');\n};\n\nmodule.exports = Instrumentation;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/apm.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/authenticate.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoDb/lib/authenticate.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nvar shallowClone = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").shallowClone,\n  handleCallback = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").handleCallback,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  f = __webpack_require__(/*! util */ \"util\").format;\n\nvar authenticate = function(client, username, password, options, callback) {\n  // Did the user destroy the topology\n  if (client.topology && client.topology.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n\n  // the default db to authenticate against is 'self'\n  // if authententicate is called from a retry context, it may be another one, like admin\n  var authdb = options.dbName;\n  authdb = options.authdb ? options.authdb : authdb;\n  authdb = options.authSource ? options.authSource : authdb;\n\n  // Callback\n  var _callback = function(err, result) {\n    if (client.listeners('authenticated').length > 0) {\n      client.emit('authenticated', err, result);\n    }\n\n    // Return to caller\n    handleCallback(callback, err, result);\n  };\n\n  // authMechanism\n  var authMechanism = options.authMechanism || '';\n  authMechanism = authMechanism.toUpperCase();\n\n  // If classic auth delegate to auth command\n  if (authMechanism === 'MONGODB-CR') {\n    client.topology.auth('mongocr', authdb, username, password, function(err) {\n      if (err) return handleCallback(callback, err, false);\n      _callback(null, true);\n    });\n  } else if (authMechanism === 'PLAIN') {\n    client.topology.auth('plain', authdb, username, password, function(err) {\n      if (err) return handleCallback(callback, err, false);\n      _callback(null, true);\n    });\n  } else if (authMechanism === 'MONGODB-X509') {\n    client.topology.auth('x509', authdb, username, password, function(err) {\n      if (err) return handleCallback(callback, err, false);\n      _callback(null, true);\n    });\n  } else if (authMechanism === 'SCRAM-SHA-1') {\n    client.topology.auth('scram-sha-1', authdb, username, password, function(err) {\n      if (err) return handleCallback(callback, err, false);\n      _callback(null, true);\n    });\n  } else if (authMechanism === 'GSSAPI') {\n    if (process.platform === 'win32') {\n      client.topology.auth('sspi', authdb, username, password, options, function(err) {\n        if (err) return handleCallback(callback, err, false);\n        _callback(null, true);\n      });\n    } else {\n      client.topology.auth('gssapi', authdb, username, password, options, function(err) {\n        if (err) return handleCallback(callback, err, false);\n        _callback(null, true);\n      });\n    }\n  } else if (authMechanism === 'DEFAULT') {\n    client.topology.auth('default', authdb, username, password, function(err) {\n      if (err) return handleCallback(callback, err, false);\n      _callback(null, true);\n    });\n  } else {\n    handleCallback(\n      callback,\n      MongoError.create({\n        message: f('authentication mechanism %s not supported', options.authMechanism),\n        driver: true\n      })\n    );\n  }\n};\n\nmodule.exports = function(self, username, password, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Shallow copy the options\n  options = shallowClone(options);\n\n  // Set default mechanism\n  if (!options.authMechanism) {\n    options.authMechanism = 'DEFAULT';\n  } else if (\n    options.authMechanism !== 'GSSAPI' &&\n    options.authMechanism !== 'DEFAULT' &&\n    options.authMechanism !== 'MONGODB-CR' &&\n    options.authMechanism !== 'MONGODB-X509' &&\n    options.authMechanism !== 'SCRAM-SHA-1' &&\n    options.authMechanism !== 'PLAIN'\n  ) {\n    return handleCallback(\n      callback,\n      MongoError.create({\n        message:\n          'only DEFAULT, GSSAPI, PLAIN, MONGODB-X509, SCRAM-SHA-1 or MONGODB-CR is supported by authMechanism',\n        driver: true\n      })\n    );\n  }\n\n  // If we have a callback fallback\n  if (typeof callback === 'function')\n    return authenticate(self, username, password, options, function(err, r) {\n      // Support failed auth method\n      if (err && err.message && err.message.indexOf('saslStart') !== -1) err.code = 59;\n      // Reject error\n      if (err) return callback(err, r);\n      callback(null, r);\n    });\n\n  // Return a promise\n  return new self.s.promiseLibrary(function(resolve, reject) {\n    authenticate(self, username, password, options, function(err, r) {\n      // Support failed auth method\n      if (err && err.message && err.message.indexOf('saslStart') !== -1) err.code = 59;\n      // Reject error\n      if (err) return reject(err);\n      resolve(r);\n    });\n  });\n};\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/authenticate.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/bulk/common.js":
/*!*************************************************!*\
  !*** ./node_modules/mongoDb/lib/bulk/common.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar Long = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.Long,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  util = __webpack_require__(/*! util */ \"util\");\n\n// Error codes\nvar UNKNOWN_ERROR = 8;\nvar INVALID_BSON_ERROR = 22;\nvar WRITE_CONCERN_ERROR = 64;\nvar MULTIPLE_ERROR = 65;\n\n// Insert types\nvar INSERT = 1;\nvar UPDATE = 2;\nvar REMOVE = 3;\n\n// Get write concern\nvar writeConcern = function(target, col, options) {\n  var writeConcern = {};\n\n  // Collection level write concern\n  if (col.writeConcern && col.writeConcern.w != null) writeConcern.w = col.writeConcern.w;\n  if (col.writeConcern && col.writeConcern.j != null) writeConcern.j = col.writeConcern.j;\n  if (col.writeConcern && col.writeConcern.fsync != null)\n    writeConcern.fsync = col.writeConcern.fsync;\n  if (col.writeConcern && col.writeConcern.wtimeout != null)\n    writeConcern.wtimeout = col.writeConcern.wtimeout;\n\n  // Options level write concern\n  if (options && options.w != null) writeConcern.w = options.w;\n  if (options && options.wtimeout != null) writeConcern.wtimeout = options.wtimeout;\n  if (options && options.j != null) writeConcern.j = options.j;\n  if (options && options.fsync != null) writeConcern.fsync = options.fsync;\n\n  // Return write concern\n  return writeConcern;\n};\n\n/**\n * Helper function to define properties\n * @ignore\n */\nvar defineReadOnlyProperty = function(self, name, value) {\n  Object.defineProperty(self, name, {\n    enumerable: true,\n    get: function() {\n      return value;\n    }\n  });\n};\n\n/**\n * Keeps the state of a unordered batch so we can rewrite the results\n * correctly after command execution\n * @ignore\n */\nvar Batch = function(batchType, originalZeroIndex) {\n  this.originalZeroIndex = originalZeroIndex;\n  this.currentIndex = 0;\n  this.originalIndexes = [];\n  this.batchType = batchType;\n  this.operations = [];\n  this.size = 0;\n  this.sizeBytes = 0;\n};\n\n/**\n * Wraps a legacy operation so we can correctly rewrite it's error\n * @ignore\n */\nvar LegacyOp = function(batchType, operation, index) {\n  this.batchType = batchType;\n  this.index = index;\n  this.operation = operation;\n};\n\n/**\n * Create a new BulkWriteResult instance (INTERNAL TYPE, do not instantiate directly)\n *\n * @class\n * @property {boolean} ok Did bulk operation correctly execute\n * @property {number} nInserted number of inserted documents\n * @property {number} nUpdated number of documents updated logically\n * @property {number} nUpserted Number of upserted documents\n * @property {number} nModified Number of documents updated physically on disk\n * @property {number} nRemoved Number of removed documents\n * @return {BulkWriteResult} a BulkWriteResult instance\n */\nvar BulkWriteResult = function(bulkResult) {\n  defineReadOnlyProperty(this, 'ok', bulkResult.ok);\n  defineReadOnlyProperty(this, 'nInserted', bulkResult.nInserted);\n  defineReadOnlyProperty(this, 'nUpserted', bulkResult.nUpserted);\n  defineReadOnlyProperty(this, 'nMatched', bulkResult.nMatched);\n  defineReadOnlyProperty(this, 'nModified', bulkResult.nModified);\n  defineReadOnlyProperty(this, 'nRemoved', bulkResult.nRemoved);\n\n  /**\n   * Return an array of inserted ids\n   *\n   * @return {object[]}\n   */\n  this.getInsertedIds = function() {\n    return bulkResult.insertedIds;\n  };\n\n  /**\n   * Return an array of upserted ids\n   *\n   * @return {object[]}\n   */\n  this.getUpsertedIds = function() {\n    return bulkResult.upserted;\n  };\n\n  /**\n   * Return the upserted id at position x\n   *\n   * @param {number} index the number of the upserted id to return, returns undefined if no result for passed in index\n   * @return {object}\n   */\n  this.getUpsertedIdAt = function(index) {\n    return bulkResult.upserted[index];\n  };\n\n  /**\n   * Return raw internal result\n   *\n   * @return {object}\n   */\n  this.getRawResponse = function() {\n    return bulkResult;\n  };\n\n  /**\n   * Returns true if the bulk operation contains a write error\n   *\n   * @return {boolean}\n   */\n  this.hasWriteErrors = function() {\n    return bulkResult.writeErrors.length > 0;\n  };\n\n  /**\n   * Returns the number of write errors off the bulk operation\n   *\n   * @return {number}\n   */\n  this.getWriteErrorCount = function() {\n    return bulkResult.writeErrors.length;\n  };\n\n  /**\n   * Returns a specific write error object\n   *\n   * @param {number} index of the write error to return, returns null if there is no result for passed in index\n   * @return {WriteError}\n   */\n  this.getWriteErrorAt = function(index) {\n    if (index < bulkResult.writeErrors.length) {\n      return bulkResult.writeErrors[index];\n    }\n    return null;\n  };\n\n  /**\n   * Retrieve all write errors\n   *\n   * @return {object[]}\n   */\n  this.getWriteErrors = function() {\n    return bulkResult.writeErrors;\n  };\n\n  /**\n   * Retrieve lastOp if available\n   *\n   * @return {object}\n   */\n  this.getLastOp = function() {\n    return bulkResult.lastOp;\n  };\n\n  /**\n   * Retrieve the write concern error if any\n   *\n   * @return {WriteConcernError}\n   */\n  this.getWriteConcernError = function() {\n    if (bulkResult.writeConcernErrors.length === 0) {\n      return null;\n    } else if (bulkResult.writeConcernErrors.length === 1) {\n      // Return the error\n      return bulkResult.writeConcernErrors[0];\n    } else {\n      // Combine the errors\n      var errmsg = '';\n      for (var i = 0; i < bulkResult.writeConcernErrors.length; i++) {\n        var err = bulkResult.writeConcernErrors[i];\n        errmsg = errmsg + err.errmsg;\n\n        // TODO: Something better\n        if (i === 0) errmsg = errmsg + ' and ';\n      }\n\n      return new WriteConcernError({ errmsg: errmsg, code: WRITE_CONCERN_ERROR });\n    }\n  };\n\n  this.toJSON = function() {\n    return bulkResult;\n  };\n\n  this.toString = function() {\n    return 'BulkWriteResult(' + this.toJSON(bulkResult) + ')';\n  };\n\n  this.isOk = function() {\n    return bulkResult.ok === 1;\n  };\n};\n\n/**\n * Create a new WriteConcernError instance (INTERNAL TYPE, do not instantiate directly)\n *\n * @class\n * @property {number} code Write concern error code.\n * @property {string} errmsg Write concern error message.\n * @return {WriteConcernError} a WriteConcernError instance\n */\nvar WriteConcernError = function(err) {\n  if (!(this instanceof WriteConcernError)) return new WriteConcernError(err);\n\n  // Define properties\n  defineReadOnlyProperty(this, 'code', err.code);\n  defineReadOnlyProperty(this, 'errmsg', err.errmsg);\n\n  this.toJSON = function() {\n    return { code: err.code, errmsg: err.errmsg };\n  };\n\n  this.toString = function() {\n    return 'WriteConcernError(' + err.errmsg + ')';\n  };\n};\n\n/**\n * Create a new WriteError instance (INTERNAL TYPE, do not instantiate directly)\n *\n * @class\n * @property {number} code Write concern error code.\n * @property {number} index Write concern error original bulk operation index.\n * @property {string} errmsg Write concern error message.\n * @return {WriteConcernError} a WriteConcernError instance\n */\nvar WriteError = function(err) {\n  if (!(this instanceof WriteError)) return new WriteError(err);\n\n  // Define properties\n  defineReadOnlyProperty(this, 'code', err.code);\n  defineReadOnlyProperty(this, 'index', err.index);\n  defineReadOnlyProperty(this, 'errmsg', err.errmsg);\n\n  //\n  // Define access methods\n  this.getOperation = function() {\n    return err.op;\n  };\n\n  this.toJSON = function() {\n    return { code: err.code, index: err.index, errmsg: err.errmsg, op: err.op };\n  };\n\n  this.toString = function() {\n    return 'WriteError(' + JSON.stringify(this.toJSON()) + ')';\n  };\n};\n\n/**\n * Merges results into shared data structure\n * @ignore\n */\nvar mergeBatchResults = function(ordered, batch, bulkResult, err, result) {\n  // If we have an error set the result to be the err object\n  if (err) {\n    result = err;\n  } else if (result && result.result) {\n    result = result.result;\n  } else if (result == null) {\n    return;\n  }\n\n  // Do we have a top level error stop processing and return\n  if (result.ok === 0 && bulkResult.ok === 1) {\n    bulkResult.ok = 0;\n\n    var writeError = {\n      index: 0,\n      code: result.code || 0,\n      errmsg: result.message,\n      op: batch.operations[0]\n    };\n\n    bulkResult.writeErrors.push(new WriteError(writeError));\n    return;\n  } else if (result.ok === 0 && bulkResult.ok === 0) {\n    return;\n  }\n\n  // Deal with opTime if available\n  if (result.opTime || result.lastOp) {\n    var opTime = result.lastOp || result.opTime;\n    var lastOpTS = null;\n    var lastOpT = null;\n\n    // We have a time stamp\n    if (opTime && opTime._bsontype === 'Timestamp') {\n      if (bulkResult.lastOp == null) {\n        bulkResult.lastOp = opTime;\n      } else if (opTime.greaterThan(bulkResult.lastOp)) {\n        bulkResult.lastOp = opTime;\n      }\n    } else {\n      // Existing TS\n      if (bulkResult.lastOp) {\n        lastOpTS =\n          typeof bulkResult.lastOp.ts === 'number'\n            ? Long.fromNumber(bulkResult.lastOp.ts)\n            : bulkResult.lastOp.ts;\n        lastOpT =\n          typeof bulkResult.lastOp.t === 'number'\n            ? Long.fromNumber(bulkResult.lastOp.t)\n            : bulkResult.lastOp.t;\n      }\n\n      // Current OpTime TS\n      var opTimeTS = typeof opTime.ts === 'number' ? Long.fromNumber(opTime.ts) : opTime.ts;\n      var opTimeT = typeof opTime.t === 'number' ? Long.fromNumber(opTime.t) : opTime.t;\n\n      // Compare the opTime's\n      if (bulkResult.lastOp == null) {\n        bulkResult.lastOp = opTime;\n      } else if (opTimeTS.greaterThan(lastOpTS)) {\n        bulkResult.lastOp = opTime;\n      } else if (opTimeTS.equals(lastOpTS)) {\n        if (opTimeT.greaterThan(lastOpT)) {\n          bulkResult.lastOp = opTime;\n        }\n      }\n    }\n  }\n\n  // If we have an insert Batch type\n  if (batch.batchType === INSERT && result.n) {\n    bulkResult.nInserted = bulkResult.nInserted + result.n;\n  }\n\n  // If we have an insert Batch type\n  if (batch.batchType === REMOVE && result.n) {\n    bulkResult.nRemoved = bulkResult.nRemoved + result.n;\n  }\n\n  var nUpserted = 0;\n\n  // We have an array of upserted values, we need to rewrite the indexes\n  if (Array.isArray(result.upserted)) {\n    nUpserted = result.upserted.length;\n\n    for (var i = 0; i < result.upserted.length; i++) {\n      bulkResult.upserted.push({\n        index: result.upserted[i].index + batch.originalZeroIndex,\n        _id: result.upserted[i]._id\n      });\n    }\n  } else if (result.upserted) {\n    nUpserted = 1;\n\n    bulkResult.upserted.push({\n      index: batch.originalZeroIndex,\n      _id: result.upserted\n    });\n  }\n\n  // If we have an update Batch type\n  if (batch.batchType === UPDATE && result.n) {\n    var nModified = result.nModified;\n    bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;\n    bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);\n\n    if (typeof nModified === 'number') {\n      bulkResult.nModified = bulkResult.nModified + nModified;\n    } else {\n      bulkResult.nModified = null;\n    }\n  }\n\n  if (Array.isArray(result.writeErrors)) {\n    for (i = 0; i < result.writeErrors.length; i++) {\n      writeError = {\n        index: batch.originalZeroIndex + result.writeErrors[i].index,\n        code: result.writeErrors[i].code,\n        errmsg: result.writeErrors[i].errmsg,\n        op: batch.operations[result.writeErrors[i].index]\n      };\n\n      bulkResult.writeErrors.push(new WriteError(writeError));\n    }\n  }\n\n  if (result.writeConcernError) {\n    bulkResult.writeConcernErrors.push(new WriteConcernError(result.writeConcernError));\n  }\n};\n\n//\n// Clone the options\nvar cloneOptions = function(options) {\n  var clone = {};\n  var keys = Object.keys(options);\n  for (var i = 0; i < keys.length; i++) {\n    clone[keys[i]] = options[keys[i]];\n  }\n\n  return clone;\n};\n\n/**\n * Creates a new BulkWriteError\n *\n * @class\n * @param {Error|string|object} message The error message\n * @param {BulkWriteResult} result The result of the bulk write operation\n * @return {BulkWriteError} A BulkWriteError instance\n * @extends {MongoError}\n */\nconst BulkWriteError = function(error, result) {\n  var message = error.err || error.errmsg || error.errMessage || error;\n  MongoError.call(this, message);\n\n  var keys = typeof error === 'object' ? Object.keys(error) : [];\n  for (var i = 0; i < keys.length; i++) {\n    this[keys[i]] = error[keys[i]];\n  }\n\n  this.name = 'BulkWriteError';\n  this.result = result;\n};\nutil.inherits(BulkWriteError, MongoError);\n\n// Exports symbols\nexports.BulkWriteError = BulkWriteError;\nexports.BulkWriteResult = BulkWriteResult;\nexports.WriteError = WriteError;\nexports.Batch = Batch;\nexports.LegacyOp = LegacyOp;\nexports.mergeBatchResults = mergeBatchResults;\nexports.cloneOptions = cloneOptions;\nexports.writeConcern = writeConcern;\nexports.INVALID_BSON_ERROR = INVALID_BSON_ERROR;\nexports.WRITE_CONCERN_ERROR = WRITE_CONCERN_ERROR;\nexports.MULTIPLE_ERROR = MULTIPLE_ERROR;\nexports.UNKNOWN_ERROR = UNKNOWN_ERROR;\nexports.INSERT = INSERT;\nexports.UPDATE = UPDATE;\nexports.REMOVE = REMOVE;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/bulk/common.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/bulk/ordered.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoDb/lib/bulk/ordered.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/mongoDb/lib/bulk/common.js\"),\n  utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\"),\n  toError = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").toError,\n  handleCallback = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").handleCallback,\n  shallowClone = utils.shallowClone,\n  BulkWriteResult = common.BulkWriteResult,\n  ObjectID = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.ObjectID,\n  Define = __webpack_require__(/*! ../metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  BSON = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON,\n  Batch = common.Batch,\n  mergeBatchResults = common.mergeBatchResults,\n  executeOperation = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation,\n  BulkWriteError = __webpack_require__(/*! ./common */ \"./node_modules/mongoDb/lib/bulk/common.js\").BulkWriteError;\n\nvar bson = new BSON([\n  BSON.Binary,\n  BSON.Code,\n  BSON.DBRef,\n  BSON.Decimal128,\n  BSON.Double,\n  BSON.Int32,\n  BSON.Long,\n  BSON.Map,\n  BSON.MaxKey,\n  BSON.MinKey,\n  BSON.ObjectId,\n  BSON.BSONRegExp,\n  BSON.Symbol,\n  BSON.Timestamp\n]);\n\n/**\n * Create a FindOperatorsOrdered instance (INTERNAL TYPE, do not instantiate directly)\n * @class\n * @return {FindOperatorsOrdered} a FindOperatorsOrdered instance.\n */\nvar FindOperatorsOrdered = function(self) {\n  this.s = self.s;\n};\n\n/**\n * Add a single update document to the bulk operation\n *\n * @method\n * @param {object} doc update operations\n * @throws {MongoError}\n * @return {OrderedBulkOperation}\n */\nFindOperatorsOrdered.prototype.update = function(updateDocument) {\n  // Perform upsert\n  var upsert = typeof this.s.currentOp.upsert === 'boolean' ? this.s.currentOp.upsert : false;\n\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    u: updateDocument,\n    multi: true,\n    upsert: upsert\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the update document to the list\n  return addToOperationsList(this, common.UPDATE, document);\n};\n\n/**\n * Add a single update one document to the bulk operation\n *\n * @method\n * @param {object} doc update operations\n * @throws {MongoError}\n * @return {OrderedBulkOperation}\n */\nFindOperatorsOrdered.prototype.updateOne = function(updateDocument) {\n  // Perform upsert\n  var upsert = typeof this.s.currentOp.upsert === 'boolean' ? this.s.currentOp.upsert : false;\n\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    u: updateDocument,\n    multi: false,\n    upsert: upsert\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the update document to the list\n  return addToOperationsList(this, common.UPDATE, document);\n};\n\n/**\n * Add a replace one operation to the bulk operation\n *\n * @method\n * @param {object} doc the new document to replace the existing one with\n * @throws {MongoError}\n * @return {OrderedBulkOperation}\n */\nFindOperatorsOrdered.prototype.replaceOne = function(updateDocument) {\n  this.updateOne(updateDocument);\n};\n\n/**\n * Upsert modifier for update bulk operation\n *\n * @method\n * @throws {MongoError}\n * @return {FindOperatorsOrdered}\n */\nFindOperatorsOrdered.prototype.upsert = function() {\n  this.s.currentOp.upsert = true;\n  return this;\n};\n\n/**\n * Add a remove one operation to the bulk operation\n *\n * @method\n * @throws {MongoError}\n * @return {OrderedBulkOperation}\n */\nFindOperatorsOrdered.prototype.deleteOne = function() {\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    limit: 1\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the remove document to the list\n  return addToOperationsList(this, common.REMOVE, document);\n};\n\n// Backward compatibility\nFindOperatorsOrdered.prototype.removeOne = FindOperatorsOrdered.prototype.deleteOne;\n\n/**\n * Add a remove operation to the bulk operation\n *\n * @method\n * @throws {MongoError}\n * @return {OrderedBulkOperation}\n */\nFindOperatorsOrdered.prototype.delete = function() {\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    limit: 0\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the remove document to the list\n  return addToOperationsList(this, common.REMOVE, document);\n};\n\n// Backward compatibility\nFindOperatorsOrdered.prototype.remove = FindOperatorsOrdered.prototype.delete;\n\n// Add to internal list of documents\nvar addToOperationsList = function(_self, docType, document) {\n  // Get the bsonSize\n  var bsonSize = bson.calculateObjectSize(document, {\n    checkKeys: false\n  });\n\n  // Throw error if the doc is bigger than the max BSON size\n  if (bsonSize >= _self.s.maxBatchSizeBytes) {\n    throw toError('document is larger than the maximum size ' + _self.s.maxBatchSizeBytes);\n  }\n\n  // Create a new batch object if we don't have a current one\n  if (_self.s.currentBatch == null) _self.s.currentBatch = new Batch(docType, _self.s.currentIndex);\n\n  // Check if we need to create a new batch\n  if (\n    _self.s.currentBatchSize + 1 >= _self.s.maxWriteBatchSize ||\n    _self.s.currentBatchSizeBytes + _self.s.currentBatchSizeBytes >= _self.s.maxBatchSizeBytes ||\n    _self.s.currentBatch.batchType !== docType\n  ) {\n    // Save the batch to the execution stack\n    _self.s.batches.push(_self.s.currentBatch);\n\n    // Create a new batch\n    _self.s.currentBatch = new Batch(docType, _self.s.currentIndex);\n\n    // Reset the current size trackers\n    _self.s.currentBatchSize = 0;\n    _self.s.currentBatchSizeBytes = 0;\n  } else {\n    // Update current batch size\n    _self.s.currentBatchSize = _self.s.currentBatchSize + 1;\n    _self.s.currentBatchSizeBytes = _self.s.currentBatchSizeBytes + bsonSize;\n  }\n\n  if (docType === common.INSERT) {\n    _self.s.bulkResult.insertedIds.push({ index: _self.s.currentIndex, _id: document._id });\n  }\n\n  // We have an array of documents\n  if (Array.isArray(document)) {\n    throw toError('operation passed in cannot be an Array');\n  } else {\n    _self.s.currentBatch.originalIndexes.push(_self.s.currentIndex);\n    _self.s.currentBatch.operations.push(document);\n    _self.s.currentBatchSizeBytes = _self.s.currentBatchSizeBytes + bsonSize;\n    _self.s.currentIndex = _self.s.currentIndex + 1;\n  }\n\n  // Return self\n  return _self;\n};\n\n/**\n * Create a new OrderedBulkOperation instance (INTERNAL TYPE, do not instantiate directly)\n * @class\n * @property {number} length Get the number of operations in the bulk.\n * @return {OrderedBulkOperation} a OrderedBulkOperation instance.\n */\nfunction OrderedBulkOperation(topology, collection, options) {\n  options = options == null ? {} : options;\n  // TODO Bring from driver information in isMaster\n  var executed = false;\n\n  // Current item\n  var currentOp = null;\n\n  // Handle to the bson serializer, used to calculate running sizes\n  var bson = topology.bson;\n\n  // Namespace for the operation\n  var namespace = collection.collectionName;\n\n  // Set max byte size\n  var maxBatchSizeBytes =\n    topology.isMasterDoc && topology.isMasterDoc.maxBsonObjectSize\n      ? topology.isMasterDoc.maxBsonObjectSize\n      : 1024 * 1025 * 16;\n  var maxWriteBatchSize =\n    topology.isMasterDoc && topology.isMasterDoc.maxWriteBatchSize\n      ? topology.isMasterDoc.maxWriteBatchSize\n      : 1000;\n\n  // Get the write concern\n  var writeConcern = common.writeConcern(shallowClone(options), collection, options);\n\n  // Get the promiseLibrary\n  var promiseLibrary = options.promiseLibrary || Promise;\n\n  // Final results\n  var bulkResult = {\n    ok: 1,\n    writeErrors: [],\n    writeConcernErrors: [],\n    insertedIds: [],\n    nInserted: 0,\n    nUpserted: 0,\n    nMatched: 0,\n    nModified: 0,\n    nRemoved: 0,\n    upserted: []\n  };\n\n  // Internal state\n  this.s = {\n    // Final result\n    bulkResult: bulkResult,\n    // Current batch state\n    currentBatch: null,\n    currentIndex: 0,\n    currentBatchSize: 0,\n    currentBatchSizeBytes: 0,\n    batches: [],\n    // Write concern\n    writeConcern: writeConcern,\n    // Max batch size options\n    maxBatchSizeBytes: maxBatchSizeBytes,\n    maxWriteBatchSize: maxWriteBatchSize,\n    // Namespace\n    namespace: namespace,\n    // BSON\n    bson: bson,\n    // Topology\n    topology: topology,\n    // Options\n    options: options,\n    // Current operation\n    currentOp: currentOp,\n    // Executed\n    executed: executed,\n    // Collection\n    collection: collection,\n    // Promise Library\n    promiseLibrary: promiseLibrary,\n    // Fundamental error\n    err: null,\n    // Bypass validation\n    bypassDocumentValidation:\n      typeof options.bypassDocumentValidation === 'boolean'\n        ? options.bypassDocumentValidation\n        : false,\n    // check keys\n    checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : true\n  };\n}\n\nvar define = (OrderedBulkOperation.define = new Define(\n  'OrderedBulkOperation',\n  OrderedBulkOperation,\n  false\n));\n\nOrderedBulkOperation.prototype.raw = function(op) {\n  var key = Object.keys(op)[0];\n\n  // Set up the force server object id\n  var forceServerObjectId =\n    typeof this.s.options.forceServerObjectId === 'boolean'\n      ? this.s.options.forceServerObjectId\n      : this.s.collection.s.db.options.forceServerObjectId;\n\n  // Update operations\n  if (\n    (op.updateOne && op.updateOne.q) ||\n    (op.updateMany && op.updateMany.q) ||\n    (op.replaceOne && op.replaceOne.q)\n  ) {\n    op[key].multi = op.updateOne || op.replaceOne ? false : true;\n    return addToOperationsList(this, common.UPDATE, op[key]);\n  }\n\n  // Crud spec update format\n  if (op.updateOne || op.updateMany || op.replaceOne) {\n    var multi = op.updateOne || op.replaceOne ? false : true;\n    var operation = { q: op[key].filter, u: op[key].update || op[key].replacement, multi: multi };\n    operation.upsert = op[key].upsert ? true : false;\n    if (op.collation) operation.collation = op.collation;\n    if (op[key].arrayFilters) operation.arrayFilters = op[key].arrayFilters;\n    return addToOperationsList(this, common.UPDATE, operation);\n  }\n\n  // Remove operations\n  if (\n    op.removeOne ||\n    op.removeMany ||\n    (op.deleteOne && op.deleteOne.q) ||\n    (op.deleteMany && op.deleteMany.q)\n  ) {\n    op[key].limit = op.removeOne ? 1 : 0;\n    return addToOperationsList(this, common.REMOVE, op[key]);\n  }\n\n  // Crud spec delete operations, less efficient\n  if (op.deleteOne || op.deleteMany) {\n    var limit = op.deleteOne ? 1 : 0;\n    operation = { q: op[key].filter, limit: limit };\n    if (op.collation) operation.collation = op.collation;\n    return addToOperationsList(this, common.REMOVE, operation);\n  }\n\n  // Insert operations\n  if (op.insertOne && op.insertOne.document == null) {\n    if (forceServerObjectId !== true && op.insertOne._id == null) op.insertOne._id = new ObjectID();\n    return addToOperationsList(this, common.INSERT, op.insertOne);\n  } else if (op.insertOne && op.insertOne.document) {\n    if (forceServerObjectId !== true && op.insertOne.document._id == null)\n      op.insertOne.document._id = new ObjectID();\n    return addToOperationsList(this, common.INSERT, op.insertOne.document);\n  }\n\n  if (op.insertMany) {\n    for (var i = 0; i < op.insertMany.length; i++) {\n      if (forceServerObjectId !== true && op.insertMany[i]._id == null)\n        op.insertMany[i]._id = new ObjectID();\n      addToOperationsList(this, common.INSERT, op.insertMany[i]);\n    }\n\n    return;\n  }\n\n  // No valid type of operation\n  throw toError(\n    'bulkWrite only supports insertOne, insertMany, updateOne, updateMany, removeOne, removeMany, deleteOne, deleteMany'\n  );\n};\n\n/**\n * Add a single insert document to the bulk operation\n *\n * @param {object} doc the document to insert\n * @throws {MongoError}\n * @return {OrderedBulkOperation}\n */\nOrderedBulkOperation.prototype.insert = function(document) {\n  if (this.s.collection.s.db.options.forceServerObjectId !== true && document._id == null)\n    document._id = new ObjectID();\n  return addToOperationsList(this, common.INSERT, document);\n};\n\n/**\n * Initiate a find operation for an update/updateOne/remove/removeOne/replaceOne\n *\n * @method\n * @param {object} selector The selector for the bulk operation.\n * @throws {MongoError}\n * @return {FindOperatorsOrdered}\n */\nOrderedBulkOperation.prototype.find = function(selector) {\n  if (!selector) {\n    throw toError('Bulk find operation must specify a selector');\n  }\n\n  // Save a current selector\n  this.s.currentOp = {\n    selector: selector\n  };\n\n  return new FindOperatorsOrdered(this);\n};\n\nObject.defineProperty(OrderedBulkOperation.prototype, 'length', {\n  enumerable: true,\n  get: function() {\n    return this.s.currentIndex;\n  }\n});\n\n//\n// Execute next write command in a chain\nvar executeCommands = function(self, options, callback) {\n  if (self.s.batches.length === 0) {\n    return handleCallback(callback, null, new BulkWriteResult(self.s.bulkResult));\n  }\n\n  // Ordered execution of the command\n  var batch = self.s.batches.shift();\n\n  var resultHandler = function(err, result) {\n    // Error is a driver related error not a bulk op error, terminate\n    if ((err && err.driver) || (err && err.message)) {\n      return handleCallback(callback, err);\n    }\n\n    // If we have and error\n    if (err) err.ok = 0;\n    // Merge the results together\n    var mergeResult = mergeBatchResults(true, batch, self.s.bulkResult, err, result);\n    const writeResult = new BulkWriteResult(self.s.bulkResult);\n    if (mergeResult != null) {\n      return handleCallback(callback, null, writeResult);\n    }\n\n    // If we are ordered and have errors and they are\n    // not all replication errors terminate the operation\n    if (self.s.bulkResult.writeErrors.length > 0) {\n      if (self.s.bulkResult.writeErrors.length === 1) {\n        return handleCallback(\n          callback,\n          new BulkWriteError(toError(self.s.bulkResult.writeErrors[0]), writeResult),\n          null\n        );\n      }\n\n      return handleCallback(\n        callback,\n        new BulkWriteError(\n          toError({\n            message: 'write operation failed',\n            code: self.s.bulkResult.writeErrors[0].code,\n            writeErrors: self.s.bulkResult.writeErrors\n          }),\n          writeResult\n        ),\n        null\n      );\n    } else if (writeResult.getWriteConcernError()) {\n      return handleCallback(\n        callback,\n        new BulkWriteError(toError(writeResult.getWriteConcernError()), writeResult),\n        null\n      );\n    }\n\n    // Execute the next command in line\n    executeCommands(self, options, callback);\n  };\n\n  var finalOptions = Object.assign({ ordered: true }, options);\n  if (self.s.writeConcern != null) {\n    finalOptions.writeConcern = self.s.writeConcern;\n  }\n\n  // Set an operationIf if provided\n  if (self.operationId) {\n    resultHandler.operationId = self.operationId;\n  }\n\n  // Serialize functions\n  if (self.s.options.serializeFunctions) {\n    finalOptions.serializeFunctions = true;\n  }\n\n  // Ignore undefined\n  if (self.s.options.ignoreUndefined) {\n    finalOptions.ignoreUndefined = true;\n  }\n\n  // Is the bypassDocumentValidation options specific\n  if (self.s.bypassDocumentValidation === true) {\n    finalOptions.bypassDocumentValidation = true;\n  }\n\n  // Is the checkKeys option disabled\n  if (self.s.checkKeys === false) {\n    finalOptions.checkKeys = false;\n  }\n\n  try {\n    if (batch.batchType === common.INSERT) {\n      self.s.topology.insert(\n        self.s.collection.namespace,\n        batch.operations,\n        finalOptions,\n        resultHandler\n      );\n    } else if (batch.batchType === common.UPDATE) {\n      self.s.topology.update(\n        self.s.collection.namespace,\n        batch.operations,\n        finalOptions,\n        resultHandler\n      );\n    } else if (batch.batchType === common.REMOVE) {\n      self.s.topology.remove(\n        self.s.collection.namespace,\n        batch.operations,\n        finalOptions,\n        resultHandler\n      );\n    }\n  } catch (err) {\n    // Force top level error\n    err.ok = 0;\n    // Merge top level error and return\n    handleCallback(callback, null, mergeBatchResults(false, batch, self.s.bulkResult, err, null));\n  }\n};\n\n/**\n * The callback format for results\n * @callback OrderedBulkOperation~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {BulkWriteResult} result The bulk write result.\n */\n\n/**\n * Execute the ordered bulk operation\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.fsync=false] Specify a file sync write concern.\n * @param {OrderedBulkOperation~resultCallback} [callback] The result callback\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nOrderedBulkOperation.prototype.execute = function(_writeConcern, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  if (this.s.executed) {\n    var executedError = toError('batch cannot be re-executed');\n    return typeof callback === 'function'\n      ? callback(executedError, null)\n      : this.s.promiseLibrary.reject(executedError);\n  }\n\n  if (typeof _writeConcern === 'function') {\n    callback = _writeConcern;\n  } else if (_writeConcern && typeof _writeConcern === 'object') {\n    this.s.writeConcern = _writeConcern;\n  }\n\n  // If we have current batch\n  if (this.s.currentBatch) this.s.batches.push(this.s.currentBatch);\n\n  // If we have no operations in the bulk raise an error\n  if (this.s.batches.length === 0) {\n    var emptyBatchError = toError('Invalid Operation, no operations specified');\n    return typeof callback === 'function'\n      ? callback(emptyBatchError, null)\n      : this.s.promiseLibrary.reject(emptyBatchError);\n  }\n\n  return executeOperation(this.s.topology, executeCommands, [this, options, callback]);\n};\n\ndefine.classMethod('execute', { callback: true, promise: false });\n\n/**\n * Returns an unordered batch object\n * @ignore\n */\nvar initializeOrderedBulkOp = function(topology, collection, options) {\n  return new OrderedBulkOperation(topology, collection, options);\n};\n\ninitializeOrderedBulkOp.OrderedBulkOperation = OrderedBulkOperation;\nmodule.exports = initializeOrderedBulkOp;\nmodule.exports.Bulk = OrderedBulkOperation;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/bulk/ordered.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/bulk/unordered.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoDb/lib/bulk/unordered.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar common = __webpack_require__(/*! ./common */ \"./node_modules/mongoDb/lib/bulk/common.js\"),\n  utils = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\"),\n  toError = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").toError,\n  handleCallback = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").handleCallback,\n  shallowClone = utils.shallowClone,\n  BulkWriteResult = common.BulkWriteResult,\n  ObjectID = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.ObjectID,\n  BSON = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON,\n  Define = __webpack_require__(/*! ../metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  Batch = common.Batch,\n  mergeBatchResults = common.mergeBatchResults,\n  executeOperation = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation,\n  BulkWriteError = __webpack_require__(/*! ./common */ \"./node_modules/mongoDb/lib/bulk/common.js\").BulkWriteError;\n\nvar bson = new BSON([\n  BSON.Binary,\n  BSON.Code,\n  BSON.DBRef,\n  BSON.Decimal128,\n  BSON.Double,\n  BSON.Int32,\n  BSON.Long,\n  BSON.Map,\n  BSON.MaxKey,\n  BSON.MinKey,\n  BSON.ObjectId,\n  BSON.BSONRegExp,\n  BSON.Symbol,\n  BSON.Timestamp\n]);\n\n/**\n * Create a FindOperatorsUnordered instance (INTERNAL TYPE, do not instantiate directly)\n * @class\n * @property {number} length Get the number of operations in the bulk.\n * @return {FindOperatorsUnordered} a FindOperatorsUnordered instance.\n */\nvar FindOperatorsUnordered = function(self) {\n  this.s = self.s;\n};\n\n/**\n * Add a single update document to the bulk operation\n *\n * @method\n * @param {object} updateDocument update operations\n * @throws {MongoError}\n * @return {FindOperatorsUnordered}\n */\nFindOperatorsUnordered.prototype.update = function(updateDocument) {\n  // Perform upsert\n  var upsert = typeof this.s.currentOp.upsert === 'boolean' ? this.s.currentOp.upsert : false;\n\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    u: updateDocument,\n    multi: true,\n    upsert: upsert\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the update document to the list\n  return addToOperationsList(this, common.UPDATE, document);\n};\n\n/**\n * Add a single update one document to the bulk operation\n *\n * @method\n * @param {object} updateDocument update operations\n * @throws {MongoError}\n * @return {FindOperatorsUnordered}\n */\nFindOperatorsUnordered.prototype.updateOne = function(updateDocument) {\n  // Perform upsert\n  var upsert = typeof this.s.currentOp.upsert === 'boolean' ? this.s.currentOp.upsert : false;\n\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    u: updateDocument,\n    multi: false,\n    upsert: upsert\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the update document to the list\n  return addToOperationsList(this, common.UPDATE, document);\n};\n\n/**\n * Add a replace one operation to the bulk operation\n *\n * @method\n * @param {object} updateDocument the new document to replace the existing one with\n * @throws {MongoError}\n * @return {FindOperatorsUnordered}\n */\nFindOperatorsUnordered.prototype.replaceOne = function(updateDocument) {\n  this.updateOne(updateDocument);\n};\n\n/**\n * Upsert modifier for update bulk operation\n *\n * @method\n * @throws {MongoError}\n * @return {FindOperatorsUnordered}\n */\nFindOperatorsUnordered.prototype.upsert = function() {\n  this.s.currentOp.upsert = true;\n  return this;\n};\n\n/**\n * Add a remove one operation to the bulk operation\n *\n * @method\n * @throws {MongoError}\n * @return {FindOperatorsUnordered}\n */\nFindOperatorsUnordered.prototype.removeOne = function() {\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    limit: 1\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the remove document to the list\n  return addToOperationsList(this, common.REMOVE, document);\n};\n\n/**\n * Add a remove operation to the bulk operation\n *\n * @method\n * @throws {MongoError}\n * @return {FindOperatorsUnordered}\n */\nFindOperatorsUnordered.prototype.remove = function() {\n  // Establish the update command\n  var document = {\n    q: this.s.currentOp.selector,\n    limit: 0\n  };\n\n  // Clear out current Op\n  this.s.currentOp = null;\n  // Add the remove document to the list\n  return addToOperationsList(this, common.REMOVE, document);\n};\n\n//\n// Add to the operations list\n//\nvar addToOperationsList = function(_self, docType, document) {\n  // Get the bsonSize\n  var bsonSize = bson.calculateObjectSize(document, {\n    checkKeys: false\n  });\n  // Throw error if the doc is bigger than the max BSON size\n  if (bsonSize >= _self.s.maxBatchSizeBytes)\n    throw toError('document is larger than the maximum size ' + _self.s.maxBatchSizeBytes);\n  // Holds the current batch\n  _self.s.currentBatch = null;\n  // Get the right type of batch\n  if (docType === common.INSERT) {\n    _self.s.currentBatch = _self.s.currentInsertBatch;\n  } else if (docType === common.UPDATE) {\n    _self.s.currentBatch = _self.s.currentUpdateBatch;\n  } else if (docType === common.REMOVE) {\n    _self.s.currentBatch = _self.s.currentRemoveBatch;\n  }\n\n  // Create a new batch object if we don't have a current one\n  if (_self.s.currentBatch == null) _self.s.currentBatch = new Batch(docType, _self.s.currentIndex);\n\n  // Check if we need to create a new batch\n  if (\n    _self.s.currentBatch.size + 1 >= _self.s.maxWriteBatchSize ||\n    _self.s.currentBatch.sizeBytes + bsonSize >= _self.s.maxBatchSizeBytes ||\n    _self.s.currentBatch.batchType !== docType\n  ) {\n    // Save the batch to the execution stack\n    _self.s.batches.push(_self.s.currentBatch);\n\n    // Create a new batch\n    _self.s.currentBatch = new Batch(docType, _self.s.currentIndex);\n  }\n\n  // We have an array of documents\n  if (Array.isArray(document)) {\n    throw toError('operation passed in cannot be an Array');\n  } else {\n    _self.s.currentBatch.operations.push(document);\n    _self.s.currentBatch.originalIndexes.push(_self.s.currentIndex);\n    _self.s.currentIndex = _self.s.currentIndex + 1;\n  }\n\n  // Save back the current Batch to the right type\n  if (docType === common.INSERT) {\n    _self.s.currentInsertBatch = _self.s.currentBatch;\n    _self.s.bulkResult.insertedIds.push({\n      index: _self.s.bulkResult.insertedIds.length,\n      _id: document._id\n    });\n  } else if (docType === common.UPDATE) {\n    _self.s.currentUpdateBatch = _self.s.currentBatch;\n  } else if (docType === common.REMOVE) {\n    _self.s.currentRemoveBatch = _self.s.currentBatch;\n  }\n\n  // Update current batch size\n  _self.s.currentBatch.size = _self.s.currentBatch.size + 1;\n  _self.s.currentBatch.sizeBytes = _self.s.currentBatch.sizeBytes + bsonSize;\n\n  // Return self\n  return _self;\n};\n\n/**\n * Create a new UnorderedBulkOperation instance (INTERNAL TYPE, do not instantiate directly)\n * @class\n * @property {number} length Get the number of operations in the bulk.\n * @return {UnorderedBulkOperation} a UnorderedBulkOperation instance.\n */\nvar UnorderedBulkOperation = function(topology, collection, options) {\n  options = options == null ? {} : options;\n\n  // Get the namesspace for the write operations\n  var namespace = collection.collectionName;\n  // Used to mark operation as executed\n  var executed = false;\n\n  // Current item\n  // var currentBatch = null;\n  var currentOp = null;\n\n  // Handle to the bson serializer, used to calculate running sizes\n  var bson = topology.bson;\n\n  // Set max byte size\n  var maxBatchSizeBytes =\n    topology.isMasterDoc && topology.isMasterDoc.maxBsonObjectSize\n      ? topology.isMasterDoc.maxBsonObjectSize\n      : 1024 * 1025 * 16;\n  var maxWriteBatchSize =\n    topology.isMasterDoc && topology.isMasterDoc.maxWriteBatchSize\n      ? topology.isMasterDoc.maxWriteBatchSize\n      : 1000;\n\n  // Get the write concern\n  var writeConcern = common.writeConcern(shallowClone(options), collection, options);\n\n  // Get the promiseLibrary\n  var promiseLibrary = options.promiseLibrary || Promise;\n\n  // Final results\n  var bulkResult = {\n    ok: 1,\n    writeErrors: [],\n    writeConcernErrors: [],\n    insertedIds: [],\n    nInserted: 0,\n    nUpserted: 0,\n    nMatched: 0,\n    nModified: 0,\n    nRemoved: 0,\n    upserted: []\n  };\n\n  // Internal state\n  this.s = {\n    // Final result\n    bulkResult: bulkResult,\n    // Current batch state\n    currentInsertBatch: null,\n    currentUpdateBatch: null,\n    currentRemoveBatch: null,\n    currentBatch: null,\n    currentIndex: 0,\n    batches: [],\n    // Write concern\n    writeConcern: writeConcern,\n    // Max batch size options\n    maxBatchSizeBytes: maxBatchSizeBytes,\n    maxWriteBatchSize: maxWriteBatchSize,\n    // Namespace\n    namespace: namespace,\n    // BSON\n    bson: bson,\n    // Topology\n    topology: topology,\n    // Options\n    options: options,\n    // Current operation\n    currentOp: currentOp,\n    // Executed\n    executed: executed,\n    // Collection\n    collection: collection,\n    // Promise Library\n    promiseLibrary: promiseLibrary,\n    // Bypass validation\n    bypassDocumentValidation:\n      typeof options.bypassDocumentValidation === 'boolean'\n        ? options.bypassDocumentValidation\n        : false,\n    // check keys\n    checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : true\n  };\n};\n\nvar define = (UnorderedBulkOperation.define = new Define(\n  'UnorderedBulkOperation',\n  UnorderedBulkOperation,\n  false\n));\n\n/**\n * Add a single insert document to the bulk operation\n *\n * @param {object} document the document to insert\n * @throws {MongoError}\n * @return {UnorderedBulkOperation}\n */\nUnorderedBulkOperation.prototype.insert = function(document) {\n  if (this.s.collection.s.db.options.forceServerObjectId !== true && document._id == null)\n    document._id = new ObjectID();\n  return addToOperationsList(this, common.INSERT, document);\n};\n\n/**\n * Initiate a find operation for an update/updateOne/remove/removeOne/replaceOne\n *\n * @method\n * @param {object} selector The selector for the bulk operation.\n * @throws {MongoError}\n * @return {FindOperatorsUnordered}\n */\nUnorderedBulkOperation.prototype.find = function(selector) {\n  if (!selector) {\n    throw toError('Bulk find operation must specify a selector');\n  }\n\n  // Save a current selector\n  this.s.currentOp = {\n    selector: selector\n  };\n\n  return new FindOperatorsUnordered(this);\n};\n\nObject.defineProperty(UnorderedBulkOperation.prototype, 'length', {\n  enumerable: true,\n  get: function() {\n    return this.s.currentIndex;\n  }\n});\n\nUnorderedBulkOperation.prototype.raw = function(op) {\n  var key = Object.keys(op)[0];\n\n  // Set up the force server object id\n  var forceServerObjectId =\n    typeof this.s.options.forceServerObjectId === 'boolean'\n      ? this.s.options.forceServerObjectId\n      : this.s.collection.s.db.options.forceServerObjectId;\n\n  // Update operations\n  if (\n    (op.updateOne && op.updateOne.q) ||\n    (op.updateMany && op.updateMany.q) ||\n    (op.replaceOne && op.replaceOne.q)\n  ) {\n    op[key].multi = op.updateOne || op.replaceOne ? false : true;\n    return addToOperationsList(this, common.UPDATE, op[key]);\n  }\n\n  // Crud spec update format\n  if (op.updateOne || op.updateMany || op.replaceOne) {\n    var multi = op.updateOne || op.replaceOne ? false : true;\n    var operation = { q: op[key].filter, u: op[key].update || op[key].replacement, multi: multi };\n    if (op[key].upsert) operation.upsert = true;\n    if (op[key].arrayFilters) operation.arrayFilters = op[key].arrayFilters;\n    return addToOperationsList(this, common.UPDATE, operation);\n  }\n\n  // Remove operations\n  if (\n    op.removeOne ||\n    op.removeMany ||\n    (op.deleteOne && op.deleteOne.q) ||\n    (op.deleteMany && op.deleteMany.q)\n  ) {\n    op[key].limit = op.removeOne ? 1 : 0;\n    return addToOperationsList(this, common.REMOVE, op[key]);\n  }\n\n  // Crud spec delete operations, less efficient\n  if (op.deleteOne || op.deleteMany) {\n    var limit = op.deleteOne ? 1 : 0;\n    operation = { q: op[key].filter, limit: limit };\n    return addToOperationsList(this, common.REMOVE, operation);\n  }\n\n  // Insert operations\n  if (op.insertOne && op.insertOne.document == null) {\n    if (forceServerObjectId !== true && op.insertOne._id == null) op.insertOne._id = new ObjectID();\n    return addToOperationsList(this, common.INSERT, op.insertOne);\n  } else if (op.insertOne && op.insertOne.document) {\n    if (forceServerObjectId !== true && op.insertOne.document._id == null)\n      op.insertOne.document._id = new ObjectID();\n    return addToOperationsList(this, common.INSERT, op.insertOne.document);\n  }\n\n  if (op.insertMany) {\n    for (var i = 0; i < op.insertMany.length; i++) {\n      if (forceServerObjectId !== true && op.insertMany[i]._id == null)\n        op.insertMany[i]._id = new ObjectID();\n      addToOperationsList(this, common.INSERT, op.insertMany[i]);\n    }\n\n    return;\n  }\n\n  // No valid type of operation\n  throw toError(\n    'bulkWrite only supports insertOne, insertMany, updateOne, updateMany, removeOne, removeMany, deleteOne, deleteMany'\n  );\n};\n\n//\n// Execute the command\nvar executeBatch = function(self, batch, options, callback) {\n  var finalOptions = Object.assign({ ordered: false }, options);\n  if (self.s.writeConcern != null) {\n    finalOptions.writeConcern = self.s.writeConcern;\n  }\n\n  var resultHandler = function(err, result) {\n    // Error is a driver related error not a bulk op error, terminate\n    if ((err && err.driver) || (err && err.message)) {\n      return handleCallback(callback, err);\n    }\n\n    // If we have and error\n    if (err) err.ok = 0;\n    handleCallback(callback, null, mergeBatchResults(false, batch, self.s.bulkResult, err, result));\n  };\n\n  // Set an operationIf if provided\n  if (self.operationId) {\n    resultHandler.operationId = self.operationId;\n  }\n\n  // Serialize functions\n  if (self.s.options.serializeFunctions) {\n    finalOptions.serializeFunctions = true;\n  }\n\n  // Ignore undefined\n  if (self.s.options.ignoreUndefined) {\n    finalOptions.ignoreUndefined = true;\n  }\n\n  // Is the bypassDocumentValidation options specific\n  if (self.s.bypassDocumentValidation === true) {\n    finalOptions.bypassDocumentValidation = true;\n  }\n\n  // Is the checkKeys option disabled\n  if (self.s.checkKeys === false) {\n    finalOptions.checkKeys = false;\n  }\n\n  try {\n    if (batch.batchType === common.INSERT) {\n      self.s.topology.insert(\n        self.s.collection.namespace,\n        batch.operations,\n        finalOptions,\n        resultHandler\n      );\n    } else if (batch.batchType === common.UPDATE) {\n      self.s.topology.update(\n        self.s.collection.namespace,\n        batch.operations,\n        finalOptions,\n        resultHandler\n      );\n    } else if (batch.batchType === common.REMOVE) {\n      self.s.topology.remove(\n        self.s.collection.namespace,\n        batch.operations,\n        finalOptions,\n        resultHandler\n      );\n    }\n  } catch (err) {\n    // Force top level error\n    err.ok = 0;\n    // Merge top level error and return\n    handleCallback(callback, null, mergeBatchResults(false, batch, self.s.bulkResult, err, null));\n  }\n};\n\n//\n// Execute all the commands\nvar executeBatches = function(self, options, callback) {\n  var numberOfCommandsToExecute = self.s.batches.length;\n  // Execute over all the batches\n  for (var i = 0; i < self.s.batches.length; i++) {\n    executeBatch(self, self.s.batches[i], options, function(err) {\n      // Count down the number of commands left to execute\n      numberOfCommandsToExecute = numberOfCommandsToExecute - 1;\n\n      // Execute\n      if (numberOfCommandsToExecute === 0) {\n        // Driver level error\n        if (err) return handleCallback(callback, err);\n\n        const writeResult = new BulkWriteResult(self.s.bulkResult);\n        if (self.s.bulkResult.writeErrors.length > 0) {\n          if (self.s.bulkResult.writeErrors.length === 1) {\n            return handleCallback(\n              callback,\n              new BulkWriteError(toError(self.s.bulkResult.writeErrors[0]), writeResult),\n              null\n            );\n          }\n\n          return handleCallback(\n            callback,\n            new BulkWriteError(\n              toError({\n                message: 'write operation failed',\n                code: self.s.bulkResult.writeErrors[0].code,\n                writeErrors: self.s.bulkResult.writeErrors\n              }),\n              writeResult\n            ),\n            null\n          );\n        } else if (writeResult.getWriteConcernError()) {\n          return handleCallback(\n            callback,\n            new BulkWriteError(toError(writeResult.getWriteConcernError()), writeResult),\n            null\n          );\n        }\n\n        return handleCallback(callback, null, writeResult);\n      }\n    });\n  }\n};\n\n/**\n * The callback format for results\n * @callback UnorderedBulkOperation~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {BulkWriteResult} result The bulk write result.\n */\n\n/**\n * Execute the ordered bulk operation\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.fsync=false] Specify a file sync write concern.\n * @param {UnorderedBulkOperation~resultCallback} [callback] The result callback\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nUnorderedBulkOperation.prototype.execute = function(_writeConcern, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  if (this.s.executed) {\n    var executedError = toError('batch cannot be re-executed');\n    return typeof callback === 'function'\n      ? callback(executedError, null)\n      : this.s.promiseLibrary.reject(executedError);\n  }\n\n  if (typeof _writeConcern === 'function') {\n    callback = _writeConcern;\n  } else if (_writeConcern && typeof _writeConcern === 'object') {\n    this.s.writeConcern = _writeConcern;\n  }\n\n  // If we have current batch\n  if (this.s.currentInsertBatch) this.s.batches.push(this.s.currentInsertBatch);\n  if (this.s.currentUpdateBatch) this.s.batches.push(this.s.currentUpdateBatch);\n  if (this.s.currentRemoveBatch) this.s.batches.push(this.s.currentRemoveBatch);\n\n  // If we have no operations in the bulk raise an error\n  if (this.s.batches.length === 0) {\n    var emptyBatchError = toError('Invalid Operation, no operations specified');\n    return typeof callback === 'function'\n      ? callback(emptyBatchError, null)\n      : this.s.promiseLibrary.reject(emptyBatchError);\n  }\n\n  return executeOperation(this.s.topology, executeBatches, [this, options, callback]);\n};\n\ndefine.classMethod('execute', { callback: true, promise: false });\n\n/**\n * Returns an unordered batch object\n * @ignore\n */\nvar initializeUnorderedBulkOp = function(topology, collection, options) {\n  return new UnorderedBulkOperation(topology, collection, options);\n};\n\ninitializeUnorderedBulkOp.UnorderedBulkOperation = UnorderedBulkOperation;\nmodule.exports = initializeUnorderedBulkOp;\nmodule.exports.Bulk = UnorderedBulkOperation;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/bulk/unordered.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/change_stream.js":
/*!***************************************************!*\
  !*** ./node_modules/mongoDb/lib/change_stream.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar EventEmitter = __webpack_require__(/*! events */ \"events\"),\n  inherits = __webpack_require__(/*! util */ \"util\").inherits,\n  MongoNetworkError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoNetworkError;\n\nvar cursorOptionNames = ['maxAwaitTimeMS', 'collation', 'readPreference'];\n\n/**\n * Creates a new Change Stream instance. Normally created using {@link Collection#watch|Collection.watch()}.\n * @class ChangeStream\n * @since 3.0.0\n * @param {(Db|Collection)} changeDomain The collection against which to create the change stream\n * @param {Array} pipeline An array of {@link https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents\n * @param {object} [options=null] Optional settings\n * @param {string} [options.fullDocument='default'] Allowed values: default, updateLookup. When set to updateLookup, the change stream will include both a delta describing the changes to the document, as well as a copy of the entire document that was changed from some time after the change occurred.\n * @param {number} [options.maxAwaitTimeMS] The maximum amount of time for the server to wait on new documents to satisfy a change stream query\n * @param {object} [options.resumeAfter=null] Specifies the logical starting point for the new change stream. This should be the _id field from a previously returned change stream document.\n * @param {number} [options.batchSize=null] The number of documents to return per batch. See {@link https://docs.mongodb.com/manual/reference/command/aggregate|aggregation documentation}.\n * @param {object} [options.collation=null] Specify collation settings for operation. See {@link https://docs.mongodb.com/manual/reference/command/aggregate|aggregation documentation}.\n * @param {ReadPreference} [options.readPreference=null] The read preference. Defaults to the read preference of the database or collection. See {@link https://docs.mongodb.com/manual/reference/read-preference|read preference documentation}.\n * @fires ChangeStream#close\n * @fires ChangeStream#change\n * @fires ChangeStream#end\n * @fires ChangeStream#error\n * @return {ChangeStream} a ChangeStream instance.\n */\nvar ChangeStream = function(collection, pipeline, options) {\n  var Collection = __webpack_require__(/*! ./collection */ \"./node_modules/mongoDb/lib/collection.js\");\n\n  // Ensure the provided collection is actually a collection\n  if (!(collection instanceof Collection)) {\n    throw new Error(\n      'collection provided to ChangeStream constructor is not an instance of Collection'\n    );\n  }\n\n  var self = this;\n  self.pipeline = pipeline || [];\n  self.options = options || {};\n  self.promiseLibrary = collection.s.promiseLibrary;\n\n  // Extract namespace and serverConfig from the collection\n  self.namespace = {\n    collection: collection.collectionName,\n    database: collection.s.db.databaseName\n  };\n\n  self.serverConfig = collection.s.db.serverConfig;\n\n  // Determine correct read preference\n  self.options.readPreference = self.options.readPreference || collection.s.readPreference;\n\n  // Create contained Change Stream cursor\n  self.cursor = createChangeStreamCursor(self);\n\n  // Listen for any `change` listeners being added to ChangeStream\n  self.on('newListener', function(eventName) {\n    if (eventName === 'change' && self.cursor && self.cursor.listenerCount('change') === 0) {\n      self.cursor.on('data', function(change) {\n        processNewChange(self, null, change);\n      });\n    }\n  });\n\n  // Listen for all `change` listeners being removed from ChangeStream\n  self.on('removeListener', function(eventName) {\n    if (eventName === 'change' && self.listenerCount('change') === 0 && self.cursor) {\n      self.cursor.removeAllListeners('data');\n    }\n  });\n};\n\ninherits(ChangeStream, EventEmitter);\n\n// Create a new change stream cursor based on self's configuration\nvar createChangeStreamCursor = function(self) {\n  if (self.resumeToken) {\n    self.options.resumeAfter = self.resumeToken;\n  }\n\n  var changeStreamCursor = buildChangeStreamAggregationCommand(\n    self.serverConfig,\n    self.namespace,\n    self.pipeline,\n    self.resumeToken,\n    self.options\n  );\n\n  /**\n   * Fired for each new matching change in the specified namespace. Attaching a `change` event listener to a Change Stream will switch the stream into flowing mode. Data will then be passed as soon as it is available.\n   *\n   * @event ChangeStream#change\n   * @type {object}\n   */\n  if (self.listenerCount('change') > 0) {\n    changeStreamCursor.on('data', function(change) {\n      processNewChange(self, null, change);\n    });\n  }\n\n  /**\n   * Change stream close event\n   *\n   * @event ChangeStream#close\n   * @type {null}\n   */\n  changeStreamCursor.on('close', function() {\n    self.emit('close');\n  });\n\n  /**\n   * Change stream end event\n   *\n   * @event ChangeStream#end\n   * @type {null}\n   */\n  changeStreamCursor.on('end', function() {\n    self.emit('end');\n  });\n\n  /**\n   * Fired when the stream encounters an error.\n   *\n   * @event ChangeStream#error\n   * @type {Error}\n   */\n  changeStreamCursor.on('error', function(error) {\n    self.emit('error', error);\n  });\n\n  return changeStreamCursor;\n};\n\nvar buildChangeStreamAggregationCommand = function(\n  serverConfig,\n  namespace,\n  pipeline,\n  resumeToken,\n  options\n) {\n  var changeStreamStageOptions = {};\n  if (options.fullDocument) {\n    changeStreamStageOptions.fullDocument = options.fullDocument;\n  }\n\n  if (resumeToken || options.resumeAfter) {\n    changeStreamStageOptions.resumeAfter = resumeToken || options.resumeAfter;\n  }\n\n  // Map cursor options\n  var cursorOptions = {};\n  cursorOptionNames.forEach(function(optionName) {\n    if (options[optionName]) {\n      cursorOptions[optionName] = options[optionName];\n    }\n  });\n\n  var changeStreamPipeline = [{ $changeStream: changeStreamStageOptions }];\n\n  changeStreamPipeline = changeStreamPipeline.concat(pipeline);\n\n  var command = {\n    aggregate: namespace.collection,\n    pipeline: changeStreamPipeline,\n    readConcern: { level: 'majority' },\n    cursor: {\n      batchSize: options.batchSize || 1\n    }\n  };\n\n  // Create and return the cursor\n  return serverConfig.cursor(\n    namespace.database + '.' + namespace.collection,\n    command,\n    cursorOptions\n  );\n};\n\n/**\n * Check if there is any document still available in the Change Stream\n * @function ChangeStream.prototype.hasNext\n * @param {ChangeStream~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nChangeStream.prototype.hasNext = function(callback) {\n  return this.cursor.hasNext(callback);\n};\n\n/**\n * Get the next available document from the Change Stream, returns null if no more documents are available.\n * @function ChangeStream.prototype.next\n * @param {ChangeStream~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nChangeStream.prototype.next = function(callback) {\n  var self = this;\n  if (this.isClosed()) {\n    if (callback) return callback(new Error('Change Stream is not open.'), null);\n    return self.promiseLibrary.reject(new Error('Change Stream is not open.'));\n  }\n  return this.cursor\n    .next()\n    .then(function(change) {\n      return processNewChange(self, null, change, callback);\n    })\n    .catch(function(err) {\n      return processNewChange(self, err, null, callback);\n    });\n};\n\n/**\n * Is the cursor closed\n * @method ChangeStream.prototype.isClosed\n * @return {boolean}\n */\nChangeStream.prototype.isClosed = function() {\n  if (this.cursor) {\n    return this.cursor.isClosed();\n  }\n  return true;\n};\n\n/**\n * Close the Change Stream\n * @method ChangeStream.prototype.close\n * @param {ChangeStream~resultCallback} [callback] The result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nChangeStream.prototype.close = function(callback) {\n  if (!this.cursor) {\n    if (callback) return callback();\n    return this.promiseLibrary.resolve();\n  }\n\n  // Tidy up the existing cursor\n  var cursor = this.cursor;\n  delete this.cursor;\n  return cursor.close(callback);\n};\n\n/**\n * This method pulls all the data out of a readable stream, and writes it to the supplied destination, automatically managing the flow so that the destination is not overwhelmed by a fast readable stream.\n * @method\n * @param {Writable} destination The destination for writing data\n * @param {object} [options] {@link https://nodejs.org/api/stream.html#stream_readable_pipe_destination_options|Pipe options}\n * @return {null}\n */\nChangeStream.prototype.pipe = function(destination, options) {\n  if (!this.pipeDestinations) {\n    this.pipeDestinations = [];\n  }\n  this.pipeDestinations.push(destination);\n  return this.cursor.pipe(destination, options);\n};\n\n/**\n * This method will remove the hooks set up for a previous pipe() call.\n * @param {Writable} [destination] The destination for writing data\n * @return {null}\n */\nChangeStream.prototype.unpipe = function(destination) {\n  if (this.pipeDestinations && this.pipeDestinations.indexOf(destination) > -1) {\n    this.pipeDestinations.splice(this.pipeDestinations.indexOf(destination), 1);\n  }\n  return this.cursor.unpipe(destination);\n};\n\n/**\n * This method will cause a stream in flowing mode to stop emitting data events. Any data that becomes available will remain in the internal buffer.\n * @return {null}\n */\nChangeStream.prototype.pause = function() {\n  return this.cursor.pause();\n};\n\n/**\n * This method will cause the readable stream to resume emitting data events.\n * @return {null}\n */\nChangeStream.prototype.resume = function() {\n  return this.cursor.resume();\n};\n\n/**\n * Return a modified Readable stream including a possible transform method.\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {function} [options.transform=null] A transformation method applied to each document emitted by the stream.\n * @return {Cursor}\n */\nChangeStream.prototype.stream = function(options) {\n  this.streamOptions = options;\n  return this.cursor.stream(options);\n};\n\n// Handle new change events. This method brings together the routes from the callback, event emitter, and promise ways of using ChangeStream.\nvar processNewChange = function(self, err, change, callback) {\n  // Handle errors\n  if (err) {\n    // Handle resumable MongoNetworkErrors\n    if (err instanceof MongoNetworkError && !self.attemptingResume) {\n      self.attemptingResume = true;\n      return self.cursor.close(function(closeErr) {\n        if (closeErr) {\n          if (callback) return callback(err, null);\n          return self.promiseLibrary.reject(err);\n        }\n\n        // Establish a new cursor\n        self.cursor = createChangeStreamCursor(self);\n\n        // Attempt to reconfigure piping\n        if (self.pipeDestinations) {\n          var cursorStream = self.cursor.stream(self.streamOptions);\n          for (var pipeDestination in self.pipeDestinations) {\n            cursorStream.pipe(pipeDestination);\n          }\n        }\n\n        // Attempt the next() operation again\n        if (callback) return self.next(callback);\n        return self.next();\n      });\n    }\n\n    if (typeof callback === 'function') return callback(err, null);\n    if (self.listenerCount('error')) return self.emit('error', err);\n    return self.promiseLibrary.reject(err);\n  }\n  self.attemptingResume = false;\n\n  // Cache the resume token if it is present. If it is not present return an error.\n  if (!change || !change._id) {\n    var noResumeTokenError = new Error(\n      'A change stream document has been received that lacks a resume token (_id).'\n    );\n    if (typeof callback === 'function') return callback(noResumeTokenError, null);\n    if (self.listenerCount('error')) return self.emit('error', noResumeTokenError);\n    return self.promiseLibrary.reject(noResumeTokenError);\n  }\n  self.resumeToken = change._id;\n\n  // Return the change\n  if (typeof callback === 'function') return callback(err, change);\n  if (self.listenerCount('change')) return self.emit('change', change);\n  return self.promiseLibrary.resolve(change);\n};\n\n/**\n * The callback format for results\n * @callback ChangeStream~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {(object|null)} result The result object if the command was executed successfully.\n */\n\nmodule.exports = ChangeStream;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/change_stream.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/collection.js":
/*!************************************************!*\
  !*** ./node_modules/mongoDb/lib/collection.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(Buffer) {\n\nvar checkCollectionName = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").checkCollectionName,\n  ObjectID = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.ObjectID,\n  Long = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.Long,\n  Code = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.Code,\n  f = __webpack_require__(/*! util */ \"util\").format,\n  AggregationCursor = __webpack_require__(/*! ./aggregation_cursor */ \"./node_modules/mongoDb/lib/aggregation_cursor.js\"),\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  shallowClone = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").shallowClone,\n  isObject = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").isObject,\n  toError = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").toError,\n  normalizeHintField = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").normalizeHintField,\n  handleCallback = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").handleCallback,\n  decorateCommand = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").decorateCommand,\n  formattedOrderClause = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").formattedOrderClause,\n  ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference,\n  CommandCursor = __webpack_require__(/*! ./command_cursor */ \"./node_modules/mongoDb/lib/command_cursor.js\"),\n  Define = __webpack_require__(/*! ./metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  Cursor = __webpack_require__(/*! ./cursor */ \"./node_modules/mongoDb/lib/cursor.js\"),\n  unordered = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongoDb/lib/bulk/unordered.js\"),\n  ordered = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongoDb/lib/bulk/ordered.js\"),\n  ChangeStream = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongoDb/lib/change_stream.js\"),\n  executeOperation = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation;\n\n/**\n * @fileOverview The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/update/remove/find and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @example\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   // Create a collection we want to drop later\n *   const col = client.db(dbName).collection('createIndexExample1');\n *   // Show that duplicate records got dropped\n *   col.find({}).toArray(function(err, items) {\n *     test.equal(null, err);\n *     test.equal(4, items.length);\n *     client.close();\n *   });\n * });\n */\n\nvar mergeKeys = ['readPreference', 'ignoreUndefined'];\n\n/**\n * Create a new Collection instance (INTERNAL TYPE, do not instantiate directly)\n * @class\n * @property {string} collectionName Get the collection name.\n * @property {string} namespace Get the full collection namespace.\n * @property {object} writeConcern The current write concern values.\n * @property {object} readConcern The current read concern values.\n * @property {object} hint Get current index hint for collection.\n * @return {Collection} a Collection instance.\n */\nvar Collection = function(db, topology, dbName, name, pkFactory, options) {\n  checkCollectionName(name);\n\n  // Unpack variables\n  var internalHint = null;\n  var slaveOk = options == null || options.slaveOk == null ? db.slaveOk : options.slaveOk;\n  var serializeFunctions =\n    options == null || options.serializeFunctions == null\n      ? db.s.options.serializeFunctions\n      : options.serializeFunctions;\n  var raw = options == null || options.raw == null ? db.s.options.raw : options.raw;\n  var promoteLongs =\n    options == null || options.promoteLongs == null\n      ? db.s.options.promoteLongs\n      : options.promoteLongs;\n  var promoteValues =\n    options == null || options.promoteValues == null\n      ? db.s.options.promoteValues\n      : options.promoteValues;\n  var promoteBuffers =\n    options == null || options.promoteBuffers == null\n      ? db.s.options.promoteBuffers\n      : options.promoteBuffers;\n  var readPreference = null;\n  var collectionHint = null;\n  var namespace = f('%s.%s', dbName, name);\n\n  // Get the promiseLibrary\n  var promiseLibrary = options.promiseLibrary || Promise;\n\n  // Assign the right collection level readPreference\n  if (options && options.readPreference) {\n    readPreference = options.readPreference;\n  } else if (db.options.readPreference) {\n    readPreference = db.options.readPreference;\n  }\n\n  // Set custom primary key factory if provided\n  pkFactory = pkFactory == null ? ObjectID : pkFactory;\n\n  // Internal state\n  this.s = {\n    // Set custom primary key factory if provided\n    pkFactory: pkFactory,\n    // Db\n    db: db,\n    // Topology\n    topology: topology,\n    // dbName\n    dbName: dbName,\n    // Options\n    options: options,\n    // Namespace\n    namespace: namespace,\n    // Read preference\n    readPreference: readPreference,\n    // SlaveOK\n    slaveOk: slaveOk,\n    // Serialize functions\n    serializeFunctions: serializeFunctions,\n    // Raw\n    raw: raw,\n    // promoteLongs\n    promoteLongs: promoteLongs,\n    // promoteValues\n    promoteValues: promoteValues,\n    // promoteBuffers\n    promoteBuffers: promoteBuffers,\n    // internalHint\n    internalHint: internalHint,\n    // collectionHint\n    collectionHint: collectionHint,\n    // Name\n    name: name,\n    // Promise library\n    promiseLibrary: promiseLibrary,\n    // Read Concern\n    readConcern: options.readConcern\n  };\n};\n\nvar define = (Collection.define = new Define('Collection', Collection, false));\n\nObject.defineProperty(Collection.prototype, 'dbName', {\n  enumerable: true,\n  get: function() {\n    return this.s.dbName;\n  }\n});\n\nObject.defineProperty(Collection.prototype, 'collectionName', {\n  enumerable: true,\n  get: function() {\n    return this.s.name;\n  }\n});\n\nObject.defineProperty(Collection.prototype, 'namespace', {\n  enumerable: true,\n  get: function() {\n    return this.s.namespace;\n  }\n});\n\nObject.defineProperty(Collection.prototype, 'readConcern', {\n  enumerable: true,\n  get: function() {\n    return this.s.readConcern || { level: 'local' };\n  }\n});\n\nObject.defineProperty(Collection.prototype, 'writeConcern', {\n  enumerable: true,\n  get: function() {\n    var ops = {};\n    if (this.s.options.w != null) ops.w = this.s.options.w;\n    if (this.s.options.j != null) ops.j = this.s.options.j;\n    if (this.s.options.fsync != null) ops.fsync = this.s.options.fsync;\n    if (this.s.options.wtimeout != null) ops.wtimeout = this.s.options.wtimeout;\n    return ops;\n  }\n});\n\n/**\n * @ignore\n */\nObject.defineProperty(Collection.prototype, 'hint', {\n  enumerable: true,\n  get: function() {\n    return this.s.collectionHint;\n  },\n  set: function(v) {\n    this.s.collectionHint = normalizeHintField(v);\n  }\n});\n\n/**\n * Creates a cursor for a query that can be used to iterate over results from MongoDB\n * @method\n * @param {object} [query={}] The cursor query object.\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.limit=0] Sets the limit of documents returned in the query.\n * @param {(array|object)} [options.sort=null] Set to sort the documents coming back from the query. Array of indexes, [['a', 1]] etc.\n * @param {object} [options.projection=null] The fields to return in the query. Object of fields to include or exclude (not both), {'a':1}\n * @param {object} [options.fields=null] **Deprecated** Use `options.projection` instead\n * @param {number} [options.skip=0] Set to skip N documents ahead in your query (useful for pagination).\n * @param {Object} [options.hint=null] Tell the query to use specific indexes in the query. Object of indexes to use, {'_id':1}\n * @param {boolean} [options.explain=false] Explain the query instead of returning the data.\n * @param {boolean} [options.snapshot=false] Snapshot query.\n * @param {boolean} [options.timeout=false] Specify if the cursor can timeout.\n * @param {boolean} [options.tailable=false] Specify if the cursor is tailable.\n * @param {number} [options.batchSize=0] Set the batchSize for the getMoreCommand when iterating over the query results.\n * @param {boolean} [options.returnKey=false] Only return the index key.\n * @param {number} [options.maxScan=null] Limit the number of items to scan.\n * @param {number} [options.min=null] Set index bounds.\n * @param {number} [options.max=null] Set index bounds.\n * @param {boolean} [options.showDiskLoc=false] Show disk location of results.\n * @param {string} [options.comment=null] You can put a $comment field on a query to make looking in the profiler logs simpler.\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers.\n * @param {boolean} [options.promoteLongs=true] Promotes Long values to number if they fit inside the 53 bits resolution.\n * @param {boolean} [options.promoteValues=true] Promotes BSON values to native types where possible, set to false to only receive wrapper types.\n * @param {boolean} [options.promoteBuffers=false] Promotes Binary BSON values to native Node Buffers.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {boolean} [options.partial=false] Specify if the cursor should return partial results when querying against a sharded system\n * @param {number} [options.maxTimeMS=null] Number of miliseconds to wait before aborting the query.\n * @param {object} [options.collation=null] Specify collation (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @throws {MongoError}\n * @return {Cursor}\n */\nCollection.prototype.find = function(query, options, callback) {\n  let selector = query;\n  // figuring out arguments\n  if (typeof callback !== 'function') {\n    if (typeof options === 'function') {\n      callback = options;\n      options = undefined;\n    } else if (options == null) {\n      callback = typeof selector === 'function' ? selector : undefined;\n      selector = typeof selector === 'object' ? selector : undefined;\n    }\n  }\n\n  // Ensure selector is not null\n  selector = selector == null ? {} : selector;\n  // Validate correctness off the selector\n  var object = selector;\n  if (Buffer.isBuffer(object)) {\n    var object_size = object[0] | (object[1] << 8) | (object[2] << 16) | (object[3] << 24);\n    if (object_size !== object.length) {\n      var error = new Error(\n        'query selector raw message size does not match message header size [' +\n          object.length +\n          '] != [' +\n          object_size +\n          ']'\n      );\n      error.name = 'MongoError';\n      throw error;\n    }\n  }\n\n  // Check special case where we are using an objectId\n  if (selector != null && selector._bsontype === 'ObjectID') {\n    selector = { _id: selector };\n  }\n\n  if (!options) options = {};\n\n  let projection = options.projection || options.fields;\n\n  if (projection && !Buffer.isBuffer(projection) && Array.isArray(projection)) {\n    projection = projection.length\n      ? projection.reduce((result, field) => {\n          result[field] = 1;\n          return result;\n        }, {})\n      : { _id: 1 };\n  }\n\n  var newOptions = {};\n\n  // Make a shallow copy of the collection options\n  for (var key in this.s.options) {\n    if (mergeKeys.indexOf(key) !== -1) {\n      newOptions[key] = this.s.options[key];\n    }\n  }\n\n  // Make a shallow copy of options\n  for (var optKey in options) {\n    newOptions[optKey] = options[optKey];\n  }\n\n  // Unpack options\n  newOptions.skip = options.skip ? options.skip : 0;\n  newOptions.limit = options.limit ? options.limit : 0;\n  newOptions.raw = typeof options.raw === 'boolean' ? options.raw : this.s.raw;\n  newOptions.hint = options.hint != null ? normalizeHintField(options.hint) : this.s.collectionHint;\n  newOptions.timeout = typeof options.timeout === 'undefined' ? undefined : options.timeout;\n  // // If we have overridden slaveOk otherwise use the default db setting\n  newOptions.slaveOk = options.slaveOk != null ? options.slaveOk : this.s.db.slaveOk;\n\n  // Add read preference if needed\n  newOptions = getReadPreference(this, newOptions, this.s.db);\n\n  // Set slave ok to true if read preference different from primary\n  if (\n    newOptions.readPreference != null &&\n    (newOptions.readPreference !== 'primary' || newOptions.readPreference.mode !== 'primary')\n  ) {\n    newOptions.slaveOk = true;\n  }\n\n  // Ensure the query is an object\n  if (selector != null && typeof selector !== 'object') {\n    throw MongoError.create({ message: 'query selector must be an object', driver: true });\n  }\n\n  // Build the find command\n  var findCommand = {\n    find: this.s.namespace,\n    limit: newOptions.limit,\n    skip: newOptions.skip,\n    query: selector\n  };\n\n  // Ensure we use the right await data option\n  if (typeof newOptions.awaitdata === 'boolean') {\n    newOptions.awaitData = newOptions.awaitdata;\n  }\n\n  // Translate to new command option noCursorTimeout\n  if (typeof newOptions.timeout === 'boolean') newOptions.noCursorTimeout = newOptions.timeout;\n\n  // Merge in options to command\n  for (var name in newOptions) {\n    if (newOptions[name] != null && name !== 'session') {\n      findCommand[name] = newOptions[name];\n    }\n  }\n\n  if (projection) findCommand.fields = projection;\n\n  // Add db object to the new options\n  newOptions.db = this.s.db;\n\n  // Add the promise library\n  newOptions.promiseLibrary = this.s.promiseLibrary;\n\n  // Set raw if available at collection level\n  if (newOptions.raw == null && typeof this.s.raw === 'boolean') newOptions.raw = this.s.raw;\n  // Set promoteLongs if available at collection level\n  if (newOptions.promoteLongs == null && typeof this.s.promoteLongs === 'boolean')\n    newOptions.promoteLongs = this.s.promoteLongs;\n  if (newOptions.promoteValues == null && typeof this.s.promoteValues === 'boolean')\n    newOptions.promoteValues = this.s.promoteValues;\n  if (newOptions.promoteBuffers == null && typeof this.s.promoteBuffers === 'boolean')\n    newOptions.promoteBuffers = this.s.promoteBuffers;\n\n  // Sort options\n  if (findCommand.sort) {\n    findCommand.sort = formattedOrderClause(findCommand.sort);\n  }\n\n  // Set the readConcern\n  decorateWithReadConcern(findCommand, this, options);\n\n  // Decorate find command with collation options\n  decorateWithCollation(findCommand, this, options);\n\n  // Create the cursor\n  if (typeof callback === 'function')\n    return handleCallback(\n      callback,\n      null,\n      this.s.topology.cursor(this.s.namespace, findCommand, newOptions)\n    );\n  return this.s.topology.cursor(this.s.namespace, findCommand, newOptions);\n};\n\ndefine.classMethod('find', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n * can be overridden by setting the **forceServerObjectId** flag.\n *\n * @method\n * @param {object} doc Document to insert.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object.\n * @param {boolean} [options.forceServerObjectId=false] Force server to assign _id values instead of driver.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~insertOneWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.insertOne = function(doc, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, insertOne, [this, doc, options, callback]);\n};\n\nvar insertOne = function(self, doc, options, callback) {\n  if (Array.isArray(doc)) {\n    return callback(\n      MongoError.create({ message: 'doc parameter must be an object', driver: true })\n    );\n  }\n\n  insertDocuments(self, [doc], options, function(err, r) {\n    if (callback == null) return;\n    if (err && callback) return callback(err);\n    // Workaround for pre 2.6 servers\n    if (r == null) return callback(null, { result: { ok: 1 } });\n    // Add values to top level to ensure crud spec compatibility\n    r.insertedCount = r.result.n;\n    r.insertedId = doc._id;\n    if (callback) callback(null, r);\n  });\n};\n\nvar mapInserManyResults = function(docs, r) {\n  var finalResult = {\n    result: { ok: 1, n: r.insertedCount },\n    ops: docs,\n    insertedCount: r.insertedCount,\n    insertedIds: r.insertedIds\n  };\n\n  if (r.getLastOp()) {\n    finalResult.result.opTime = r.getLastOp();\n  }\n\n  return finalResult;\n};\n\ndefine.classMethod('insertOne', { callback: true, promise: true });\n\n/**\n * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n * can be overridden by setting the **forceServerObjectId** flag.\n *\n * @method\n * @param {object[]} docs Documents to insert.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object.\n * @param {boolean} [options.forceServerObjectId=false] Force server to assign _id values instead of driver.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {boolean} [options.ordered=true] If true, when an insert fails, don't execute the remaining writes. If false, continue with remaining inserts when one fails.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~insertWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.insertMany = function(docs, options, callback) {\n  var self = this;\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options ? shallowClone(options) : { ordered: true };\n  if (!Array.isArray(docs) && typeof callback === 'function') {\n    return callback(\n      MongoError.create({ message: 'docs parameter must be an array of documents', driver: true })\n    );\n  } else if (!Array.isArray(docs)) {\n    return new this.s.promiseLibrary(function(resolve, reject) {\n      reject(\n        MongoError.create({ message: 'docs parameter must be an array of documents', driver: true })\n      );\n    });\n  }\n\n  // If keep going set unordered\n  options['serializeFunctions'] = options['serializeFunctions'] || self.s.serializeFunctions;\n\n  // Set up the force server object id\n  var forceServerObjectId =\n    typeof options.forceServerObjectId === 'boolean'\n      ? options.forceServerObjectId\n      : self.s.db.options.forceServerObjectId;\n\n  // Do we want to force the server to assign the _id key\n  if (forceServerObjectId !== true) {\n    // Add _id if not specified\n    for (var i = 0; i < docs.length; i++) {\n      if (docs[i]._id == null) docs[i]._id = self.s.pkFactory.createPk();\n    }\n  }\n\n  // Generate the bulk write operations\n  var operations = [\n    {\n      insertMany: docs\n    }\n  ];\n\n  return executeOperation(this.s.topology, bulkWrite, [this, operations, options, callback], {\n    resultMutator: result => mapInserManyResults(docs, result)\n  });\n};\n\ndefine.classMethod('insertMany', { callback: true, promise: true });\n\n/**\n * @typedef {Object} Collection~BulkWriteOpResult\n * @property {number} insertedCount Number of documents inserted.\n * @property {number} matchedCount Number of documents matched for update.\n * @property {number} modifiedCount Number of documents modified.\n * @property {number} deletedCount Number of documents deleted.\n * @property {number} upsertedCount Number of documents upserted.\n * @property {object} insertedIds Inserted document generated Id's, hash key is the index of the originating operation\n * @property {object} upsertedIds Upserted document generated Id's, hash key is the index of the originating operation\n * @property {object} result The command result object.\n */\n\n/**\n * The callback format for inserts\n * @callback Collection~bulkWriteOpCallback\n * @param {BulkWriteError} error An error instance representing the error during the execution.\n * @param {Collection~BulkWriteOpResult} result The result object if the command was executed successfully.\n */\n\n/**\n * Perform a bulkWrite operation without a fluent API\n *\n * Legal operation types are\n *\n *  { insertOne: { document: { a: 1 } } }\n *\n *  { updateOne: { filter: {a:2}, update: {$set: {a:2}}, upsert:true } }\n *\n *  { updateMany: { filter: {a:2}, update: {$set: {a:2}}, upsert:true } }\n *\n *  { deleteOne: { filter: {c:1} } }\n *\n *  { deleteMany: { filter: {c:1} } }\n *\n *  { replaceOne: { filter: {c:3}, replacement: {c:4}, upsert:true}}\n *\n * If documents passed in do not contain the **_id** field,\n * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n * can be overridden by setting the **forceServerObjectId** flag.\n *\n * @method\n * @param {object[]} operations Bulk operations to perform.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object.\n * @param {boolean} [options.ordered=true] Execute write operation in ordered or unordered fashion.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~bulkWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.bulkWrite = function(operations, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || { ordered: true };\n\n  if (!Array.isArray(operations)) {\n    throw MongoError.create({ message: 'operations must be an array of documents', driver: true });\n  }\n\n  return executeOperation(this.s.topology, bulkWrite, [this, operations, options, callback]);\n};\n\nvar bulkWrite = function(self, operations, options, callback) {\n  // Add ignoreUndfined\n  if (self.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = self.s.options.ignoreUndefined;\n  }\n\n  // Create the bulk operation\n  var bulk =\n    options.ordered === true || options.ordered == null\n      ? self.initializeOrderedBulkOp(options)\n      : self.initializeUnorderedBulkOp(options);\n\n  // Do we have a collation\n  var collation = false;\n\n  // for each op go through and add to the bulk\n  try {\n    for (var i = 0; i < operations.length; i++) {\n      // Get the operation type\n      var key = Object.keys(operations[i])[0];\n      // Check if we have a collation\n      if (operations[i][key].collation) {\n        collation = true;\n      }\n\n      // Pass to the raw bulk\n      bulk.raw(operations[i]);\n    }\n  } catch (err) {\n    return callback(err, null);\n  }\n\n  // Final options for write concern\n  var finalOptions = writeConcern(shallowClone(options), self.s.db, self, options);\n  var writeCon = finalOptions.writeConcern ? finalOptions.writeConcern : {};\n  var capabilities = self.s.topology.capabilities();\n\n  // Did the user pass in a collation, check if our write server supports it\n  if (collation && capabilities && !capabilities.commandsTakeCollation) {\n    return callback(new MongoError(f('server/primary/mongos does not support collation')));\n  }\n\n  // Execute the bulk\n  bulk.execute(writeCon, finalOptions, function(err, r) {\n    // We have connection level error\n    if (!r && err) {\n      return callback(err, null);\n    }\n\n    r.insertedCount = r.nInserted;\n    r.matchedCount = r.nMatched;\n    r.modifiedCount = r.nModified || 0;\n    r.deletedCount = r.nRemoved;\n    r.upsertedCount = r.getUpsertedIds().length;\n    r.upsertedIds = {};\n    r.insertedIds = {};\n\n    // Update the n\n    r.n = r.insertedCount;\n\n    // Inserted documents\n    var inserted = r.getInsertedIds();\n    // Map inserted ids\n    for (var i = 0; i < inserted.length; i++) {\n      r.insertedIds[inserted[i].index] = inserted[i]._id;\n    }\n\n    // Upserted documents\n    var upserted = r.getUpsertedIds();\n    // Map upserted ids\n    for (i = 0; i < upserted.length; i++) {\n      r.upsertedIds[upserted[i].index] = upserted[i]._id;\n    }\n\n    // Return the results\n    callback(null, r);\n  });\n};\n\nvar insertDocuments = function(self, docs, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n  // Ensure we are operating on an array op docs\n  docs = Array.isArray(docs) ? docs : [docs];\n\n  // Get the write concern options\n  var finalOptions = writeConcern(shallowClone(options), self.s.db, self, options);\n\n  // If keep going set unordered\n  if (finalOptions.keepGoing === true) finalOptions.ordered = false;\n  finalOptions['serializeFunctions'] = options['serializeFunctions'] || self.s.serializeFunctions;\n\n  // Set up the force server object id\n  var forceServerObjectId =\n    typeof options.forceServerObjectId === 'boolean'\n      ? options.forceServerObjectId\n      : self.s.db.options.forceServerObjectId;\n\n  // Add _id if not specified\n  if (forceServerObjectId !== true) {\n    for (var i = 0; i < docs.length; i++) {\n      if (docs[i]._id === void 0) docs[i]._id = self.s.pkFactory.createPk();\n    }\n  }\n\n  // File inserts\n  self.s.topology.insert(self.s.namespace, docs, finalOptions, function(err, result) {\n    if (callback == null) return;\n    if (err) return handleCallback(callback, err);\n    if (result == null) return handleCallback(callback, null, null);\n    if (result.result.code) return handleCallback(callback, toError(result.result));\n    if (result.result.writeErrors)\n      return handleCallback(callback, toError(result.result.writeErrors[0]));\n    // Add docs to the list\n    result.ops = docs;\n    // Return the results\n    handleCallback(callback, null, result);\n  });\n};\n\ndefine.classMethod('bulkWrite', { callback: true, promise: true });\n\n/**\n * @typedef {Object} Collection~WriteOpResult\n * @property {object[]} ops All the documents inserted using insertOne/insertMany/replaceOne. Documents contain the _id field if forceServerObjectId == false for insertOne/insertMany\n * @property {object} connection The connection object used for the operation.\n * @property {object} result The command result object.\n */\n\n/**\n * The callback format for inserts\n * @callback Collection~writeOpCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection~WriteOpResult} result The result object if the command was executed successfully.\n */\n\n/**\n * @typedef {Object} Collection~insertWriteOpResult\n * @property {Number} insertedCount The total amount of documents inserted.\n * @property {object[]} ops All the documents inserted using insertOne/insertMany/replaceOne. Documents contain the _id field if forceServerObjectId == false for insertOne/insertMany\n * @property {Object.<Number, ObjectId>} insertedIds Map of the index of the inserted document to the id of the inserted document.\n * @property {object} connection The connection object used for the operation.\n * @property {object} result The raw command result object returned from MongoDB (content might vary by server version).\n * @property {Number} result.ok Is 1 if the command executed correctly.\n * @property {Number} result.n The total count of documents inserted.\n */\n\n/**\n * @typedef {Object} Collection~insertOneWriteOpResult\n * @property {Number} insertedCount The total amount of documents inserted.\n * @property {object[]} ops All the documents inserted using insertOne/insertMany/replaceOne. Documents contain the _id field if forceServerObjectId == false for insertOne/insertMany\n * @property {ObjectId} insertedId The driver generated ObjectId for the insert operation.\n * @property {object} connection The connection object used for the operation.\n * @property {object} result The raw command result object returned from MongoDB (content might vary by server version).\n * @property {Number} result.ok Is 1 if the command executed correctly.\n * @property {Number} result.n The total count of documents inserted.\n */\n\n/**\n * The callback format for inserts\n * @callback Collection~insertWriteOpCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection~insertWriteOpResult} result The result object if the command was executed successfully.\n */\n\n/**\n * The callback format for inserts\n * @callback Collection~insertOneWriteOpCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection~insertOneWriteOpResult} result The result object if the command was executed successfully.\n */\n\n/**\n * Inserts a single document or a an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n * can be overridden by setting the **forceServerObjectId** flag.\n *\n * @method\n * @param {(object|object[])} docs Documents to insert.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object.\n * @param {boolean} [options.forceServerObjectId=false] Force server to assign _id values instead of driver.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~insertWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use insertOne, insertMany or bulkWrite\n */\nCollection.prototype.insert = function(docs, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || { ordered: false };\n  docs = !Array.isArray(docs) ? [docs] : docs;\n\n  if (options.keepGoing === true) {\n    options.ordered = false;\n  }\n\n  return this.insertMany(docs, options, callback);\n};\n\ndefine.classMethod('insert', { callback: true, promise: true });\n\n/**\n * @typedef {Object} Collection~updateWriteOpResult\n * @property {Object} result The raw result returned from MongoDB, field will vary depending on server version.\n * @property {Number} result.ok Is 1 if the command executed correctly.\n * @property {Number} result.n The total count of documents scanned.\n * @property {Number} result.nModified The total count of documents modified.\n * @property {Object} connection The connection object used for the operation.\n * @property {Number} matchedCount The number of documents that matched the filter.\n * @property {Number} modifiedCount The number of documents that were modified.\n * @property {Number} upsertedCount The number of documents upserted.\n * @property {Object} upsertedId The upserted id.\n * @property {ObjectId} upsertedId._id The upserted _id returned from the server.\n */\n\n/**\n * The callback format for inserts\n * @callback Collection~updateWriteOpCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection~updateWriteOpResult} result The result object if the command was executed successfully.\n */\n\n/**\n * Update a single document on MongoDB\n * @method\n * @param {object} filter The Filter used to select the document to update\n * @param {object} update The update operations to be applied to the document\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.upsert=false] Update operation is an upsert.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {Array} [options.arrayFilters=null] optional list of array filters referenced in filtered positional operators\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~updateWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.updateOne = function(filter, update, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  var err = checkForAtomicOperators(update);\n  if (err) {\n    if (typeof callback === 'function') return callback(err);\n    return this.s.promiseLibrary.reject(err);\n  }\n\n  options = shallowClone(options);\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, updateOne, [this, filter, update, options, callback]);\n};\n\nvar checkForAtomicOperators = function(update) {\n  var keys = Object.keys(update);\n\n  // same errors as the server would give for update doc lacking atomic operators\n  if (keys.length === 0) {\n    return toError('The update operation document must contain at least one atomic operator.');\n  }\n\n  if (keys[0][0] !== '$') {\n    return toError('the update operation document must contain atomic operators.');\n  }\n};\n\nvar updateOne = function(self, filter, update, options, callback) {\n  // Set single document update\n  options.multi = false;\n  // Execute update\n  updateDocuments(self, filter, update, options, function(err, r) {\n    if (callback == null) return;\n    if (err && callback) return callback(err);\n    if (r == null) return callback(null, { result: { ok: 1 } });\n    r.modifiedCount = r.result.nModified != null ? r.result.nModified : r.result.n;\n    r.upsertedId =\n      Array.isArray(r.result.upserted) && r.result.upserted.length > 0\n        ? r.result.upserted[0]\n        : null;\n    r.upsertedCount =\n      Array.isArray(r.result.upserted) && r.result.upserted.length ? r.result.upserted.length : 0;\n    r.matchedCount =\n      Array.isArray(r.result.upserted) && r.result.upserted.length > 0 ? 0 : r.result.n;\n    if (callback) callback(null, r);\n  });\n};\n\ndefine.classMethod('updateOne', { callback: true, promise: true });\n\n/**\n * Replace a document on MongoDB\n * @method\n * @param {object} filter The Filter used to select the document to update\n * @param {object} doc The Document that replaces the matching document\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.upsert=false] Update operation is an upsert.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~updateWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.replaceOne = function(filter, doc, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = shallowClone(options);\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, replaceOne, [this, filter, doc, options, callback]);\n};\n\nvar replaceOne = function(self, filter, doc, options, callback) {\n  // Set single document update\n  options.multi = false;\n\n  // Execute update\n  updateDocuments(self, filter, doc, options, function(err, r) {\n    if (callback == null) return;\n    if (err && callback) return callback(err);\n    if (r == null) return callback(null, { result: { ok: 1 } });\n\n    r.modifiedCount = r.result.nModified != null ? r.result.nModified : r.result.n;\n    r.upsertedId =\n      Array.isArray(r.result.upserted) && r.result.upserted.length > 0\n        ? r.result.upserted[0]\n        : null;\n    r.upsertedCount =\n      Array.isArray(r.result.upserted) && r.result.upserted.length ? r.result.upserted.length : 0;\n    r.matchedCount =\n      Array.isArray(r.result.upserted) && r.result.upserted.length > 0 ? 0 : r.result.n;\n    r.ops = [doc];\n    if (callback) callback(null, r);\n  });\n};\n\ndefine.classMethod('replaceOne', { callback: true, promise: true });\n\n/**\n * Update multiple documents on MongoDB\n * @method\n * @param {object} filter The Filter used to select the documents to update\n * @param {object} update The update operations to be applied to the document\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.upsert=false] Update operation is an upsert.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {Array} [options.arrayFilters=null] optional list of array filters referenced in filtered positional operators\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~updateWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.updateMany = function(filter, update, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  var err = checkForAtomicOperators(update);\n  if (err) {\n    if (typeof callback === 'function') return callback(err);\n    return this.s.promiseLibrary.reject(err);\n  }\n\n  options = shallowClone(options);\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, updateMany, [this, filter, update, options, callback]);\n};\n\nvar updateMany = function(self, filter, update, options, callback) {\n  // Set single document update\n  options.multi = true;\n  // Execute update\n  updateDocuments(self, filter, update, options, function(err, r) {\n    if (callback == null) return;\n    if (err && callback) return callback(err);\n    if (r == null) return callback(null, { result: { ok: 1 } });\n    r.modifiedCount = r.result.nModified != null ? r.result.nModified : r.result.n;\n    r.upsertedId =\n      Array.isArray(r.result.upserted) && r.result.upserted.length > 0\n        ? r.result.upserted[0]\n        : null;\n    r.upsertedCount =\n      Array.isArray(r.result.upserted) && r.result.upserted.length ? r.result.upserted.length : 0;\n    r.matchedCount =\n      Array.isArray(r.result.upserted) && r.result.upserted.length > 0 ? 0 : r.result.n;\n    if (callback) callback(null, r);\n  });\n};\n\ndefine.classMethod('updateMany', { callback: true, promise: true });\n\nvar updateDocuments = function(self, selector, document, options, callback) {\n  if ('function' === typeof options) (callback = options), (options = null);\n  if (options == null) options = {};\n  if (!('function' === typeof callback)) callback = null;\n\n  // If we are not providing a selector or document throw\n  if (selector == null || typeof selector !== 'object')\n    return callback(toError('selector must be a valid JavaScript object'));\n  if (document == null || typeof document !== 'object')\n    return callback(toError('document must be a valid JavaScript object'));\n\n  // Get the write concern options\n  var finalOptions = writeConcern(shallowClone(options), self.s.db, self, options);\n\n  // Do we return the actual result document\n  // Either use override on the function, or go back to default on either the collection\n  // level or db\n  finalOptions['serializeFunctions'] = options['serializeFunctions'] || self.s.serializeFunctions;\n\n  // Execute the operation\n  var op = { q: selector, u: document };\n  op.upsert = options.upsert !== void 0 ? !!options.upsert : false;\n  op.multi = options.multi !== void 0 ? !!options.multi : false;\n\n  if (finalOptions.arrayFilters) {\n    op.arrayFilters = finalOptions.arrayFilters;\n    delete finalOptions.arrayFilters;\n  }\n\n  // Have we specified collation\n  decorateWithCollation(finalOptions, self, options);\n\n  // Update options\n  self.s.topology.update(self.s.namespace, [op], finalOptions, function(err, result) {\n    if (callback == null) return;\n    if (err) return handleCallback(callback, err, null);\n    if (result == null) return handleCallback(callback, null, null);\n    if (result.result.code) return handleCallback(callback, toError(result.result));\n    if (result.result.writeErrors)\n      return handleCallback(callback, toError(result.result.writeErrors[0]));\n    // Return the results\n    handleCallback(callback, null, result);\n  });\n};\n\n/**\n * Updates documents.\n * @method\n * @param {object} selector The selector for the update operation.\n * @param {object} document The update document.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.upsert=false] Update operation is an upsert.\n * @param {boolean} [options.multi=false] Update one/all documents with operation.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {object} [options.collation=null] Specify collation (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @param {Array} [options.arrayFilters=null] optional list of array filters referenced in filtered positional operators\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~writeOpCallback} [callback] The command result callback\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n * @deprecated use updateOne, updateMany or bulkWrite\n */\nCollection.prototype.update = function(selector, document, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, updateDocuments, [\n    this,\n    selector,\n    document,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('update', { callback: true, promise: true });\n\n/**\n * @typedef {Object} Collection~deleteWriteOpResult\n * @property {Object} result The raw result returned from MongoDB, field will vary depending on server version.\n * @property {Number} result.ok Is 1 if the command executed correctly.\n * @property {Number} result.n The total count of documents deleted.\n * @property {Object} connection The connection object used for the operation.\n * @property {Number} deletedCount The number of documents deleted.\n */\n\n/**\n * The callback format for inserts\n * @callback Collection~deleteWriteOpCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection~deleteWriteOpResult} result The result object if the command was executed successfully.\n */\n\n/**\n * Delete a document on MongoDB\n * @method\n * @param {object} filter The Filter used to select the document to remove\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~deleteWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.deleteOne = function(filter, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = shallowClone(options);\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, deleteOne, [this, filter, options, callback]);\n};\n\nvar deleteOne = function(self, filter, options, callback) {\n  options.single = true;\n  removeDocuments(self, filter, options, function(err, r) {\n    if (callback == null) return;\n    if (err && callback) return callback(err);\n    if (r == null) return callback(null, { result: { ok: 1 } });\n    r.deletedCount = r.result.n;\n    if (callback) callback(null, r);\n  });\n};\n\ndefine.classMethod('deleteOne', { callback: true, promise: true });\n\nCollection.prototype.removeOne = Collection.prototype.deleteOne;\n\ndefine.classMethod('removeOne', { callback: true, promise: true });\n\n/**\n * Delete multiple documents on MongoDB\n * @method\n * @param {object} filter The Filter used to select the documents to remove\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~deleteWriteOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.deleteMany = function(filter, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = shallowClone(options);\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, deleteMany, [this, filter, options, callback]);\n};\n\nvar deleteMany = function(self, filter, options, callback) {\n  options.single = false;\n\n  removeDocuments(self, filter, options, function(err, r) {\n    if (callback == null) return;\n    if (err && callback) return callback(err);\n    if (r == null) return callback(null, { result: { ok: 1 } });\n    r.deletedCount = r.result.n;\n    if (callback) callback(null, r);\n  });\n};\n\nvar removeDocuments = function(self, selector, options, callback) {\n  if (typeof options === 'function') {\n    (callback = options), (options = {});\n  } else if (typeof selector === 'function') {\n    callback = selector;\n    options = {};\n    selector = {};\n  }\n\n  // Create an empty options object if the provided one is null\n  options = options || {};\n\n  // Get the write concern options\n  var finalOptions = writeConcern(shallowClone(options), self.s.db, self, options);\n\n  // If selector is null set empty\n  if (selector == null) selector = {};\n\n  // Build the op\n  var op = { q: selector, limit: 0 };\n  if (options.single) op.limit = 1;\n\n  // Have we specified collation\n  decorateWithCollation(finalOptions, self, options);\n\n  // Execute the remove\n  self.s.topology.remove(self.s.namespace, [op], finalOptions, function(err, result) {\n    if (callback == null) return;\n    if (err) return handleCallback(callback, err, null);\n    if (result == null) return handleCallback(callback, null, null);\n    if (result.result.code) return handleCallback(callback, toError(result.result));\n    if (result.result.writeErrors)\n      return handleCallback(callback, toError(result.result.writeErrors[0]));\n    // Return the results\n    handleCallback(callback, null, result);\n  });\n};\n\ndefine.classMethod('deleteMany', { callback: true, promise: true });\n\nCollection.prototype.removeMany = Collection.prototype.deleteMany;\n\ndefine.classMethod('removeMany', { callback: true, promise: true });\n\n/**\n * Remove documents.\n * @method\n * @param {object} selector The selector for the update operation.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.single=false] Removes the first document found.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~writeOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n * @deprecated use deleteOne, deleteMany or bulkWrite\n */\nCollection.prototype.remove = function(selector, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, removeDocuments, [this, selector, options, callback]);\n};\n\ndefine.classMethod('remove', { callback: true, promise: true });\n\n/**\n * Save a document. Simple full document replacement function. Not recommended for efficiency, use atomic\n * operators and update instead for more efficient operations.\n * @method\n * @param {object} doc Document to save\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~writeOpCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n * @deprecated use insertOne, insertMany, updateOne or updateMany\n */\nCollection.prototype.save = function(doc, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Add ignoreUndfined\n  if (this.s.options.ignoreUndefined) {\n    options = shallowClone(options);\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  return executeOperation(this.s.topology, save, [this, doc, options, callback]);\n};\n\nvar save = function(self, doc, options, callback) {\n  // Get the write concern options\n  var finalOptions = writeConcern(shallowClone(options), self.s.db, self, options);\n  // Establish if we need to perform an insert or update\n  if (doc._id != null) {\n    finalOptions.upsert = true;\n    return updateDocuments(self, { _id: doc._id }, doc, finalOptions, callback);\n  }\n\n  // Insert the document\n  insertDocuments(self, [doc], finalOptions, function(err, r) {\n    if (callback == null) return;\n    if (doc == null) return handleCallback(callback, null, null);\n    if (err) return handleCallback(callback, err, null);\n    handleCallback(callback, null, r);\n  });\n};\n\ndefine.classMethod('save', { callback: true, promise: true });\n\n/**\n * The callback format for results\n * @callback Collection~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {object} result The result object if the command was executed successfully.\n */\n\n/**\n * The callback format for an aggregation call\n * @callback Collection~aggregationCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {AggregationCursor} cursor The cursor if the aggregation command was executed successfully.\n */\n\n/**\n * Fetches the first document that matches the query\n * @method\n * @param {object} query Query for find Operation\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.limit=0] Sets the limit of documents returned in the query.\n * @param {(array|object)} [options.sort=null] Set to sort the documents coming back from the query. Array of indexes, [['a', 1]] etc.\n * @param {object} [options.projection=null] The fields to return in the query. Object of fields to include or exclude (not both), {'a':1}\n * @param {object} [options.fields=null] **Deprecated** Use `options.projection` instead\n * @param {number} [options.skip=0] Set to skip N documents ahead in your query (useful for pagination).\n * @param {Object} [options.hint=null] Tell the query to use specific indexes in the query. Object of indexes to use, {'_id':1}\n * @param {boolean} [options.explain=false] Explain the query instead of returning the data.\n * @param {boolean} [options.snapshot=false] Snapshot query.\n * @param {boolean} [options.timeout=false] Specify if the cursor can timeout.\n * @param {boolean} [options.tailable=false] Specify if the cursor is tailable.\n * @param {number} [options.batchSize=0] Set the batchSize for the getMoreCommand when iterating over the query results.\n * @param {boolean} [options.returnKey=false] Only return the index key.\n * @param {number} [options.maxScan=null] Limit the number of items to scan.\n * @param {number} [options.min=null] Set index bounds.\n * @param {number} [options.max=null] Set index bounds.\n * @param {boolean} [options.showDiskLoc=false] Show disk location of results.\n * @param {string} [options.comment=null] You can put a $comment field on a query to make looking in the profiler logs simpler.\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers.\n * @param {boolean} [options.promoteLongs=true] Promotes Long values to number if they fit inside the 53 bits resolution.\n * @param {boolean} [options.promoteValues=true] Promotes BSON values to native types where possible, set to false to only receive wrapper types.\n * @param {boolean} [options.promoteBuffers=false] Promotes Binary BSON values to native Node Buffers.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {boolean} [options.partial=false] Specify if the cursor should return partial results when querying against a sharded system\n * @param {number} [options.maxTimeMS=null] Number of miliseconds to wait before aborting the query.\n * @param {object} [options.collation=null] Specify collation (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.findOne = function(query, options, callback) {\n  if (typeof query === 'function') (callback = query), (query = {}), (options = {});\n  if (typeof options === 'function') (callback = options), (options = {});\n  query = query || {};\n  options = options || {};\n\n  return executeOperation(this.s.topology, findOne, [this, query, options, callback]);\n};\n\nvar findOne = function(self, query, options, callback) {\n  const cursor = self\n    .find(query, options)\n    .limit(-1)\n    .batchSize(1);\n\n  // Return the item\n  cursor.next(function(err, item) {\n    if (err != null) return handleCallback(callback, toError(err), null);\n    handleCallback(callback, null, item);\n  });\n};\n\ndefine.classMethod('findOne', { callback: true, promise: true });\n\n/**\n * The callback format for the collection method, must be used if strict is specified\n * @callback Collection~collectionResultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection} collection The collection instance.\n */\n\n/**\n * Rename the collection.\n *\n * @method\n * @param {string} newName New name of of the collection.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.dropTarget=false] Drop the target name collection if it previously exists.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~collectionResultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.rename = function(newName, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = Object.assign({}, options, { readPreference: ReadPreference.PRIMARY });\n\n  return executeOperation(this.s.topology, rename, [this, newName, options, callback]);\n};\n\nvar rename = function(self, newName, options, callback) {\n  // Check the collection name\n  checkCollectionName(newName);\n  // Build the command\n  var renameCollection = f('%s.%s', self.s.dbName, self.s.name);\n  var toCollection = f('%s.%s', self.s.dbName, newName);\n  var dropTarget = typeof options.dropTarget === 'boolean' ? options.dropTarget : false;\n  var cmd = { renameCollection: renameCollection, to: toCollection, dropTarget: dropTarget };\n\n  // Decorate command with writeConcern if supported\n  decorateWithWriteConcern(cmd, self, options);\n\n  // Execute against admin\n  self.s.db.admin().command(cmd, options, function(err, doc) {\n    if (err) return handleCallback(callback, err, null);\n    // We have an error\n    if (doc.errmsg) return handleCallback(callback, toError(doc), null);\n    try {\n      return handleCallback(\n        callback,\n        null,\n        new Collection(\n          self.s.db,\n          self.s.topology,\n          self.s.dbName,\n          newName,\n          self.s.pkFactory,\n          self.s.options\n        )\n      );\n    } catch (err) {\n      return handleCallback(callback, toError(err), null);\n    }\n  });\n};\n\ndefine.classMethod('rename', { callback: true, promise: true });\n\n/**\n * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.drop = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, this.s.db.dropCollection.bind(this.s.db), [\n    this.s.name,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('drop', { callback: true, promise: true });\n\n/**\n * Returns the options of the collection.\n *\n * @method\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.options = function(opts, callback) {\n  if (typeof opts === 'function') (callback = opts), (opts = {});\n  opts = opts || {};\n\n  return executeOperation(this.s.topology, options, [this, opts, callback]);\n};\n\nvar options = function(self, opts, callback) {\n  self.s.db.listCollections({ name: self.s.name }, opts).toArray(function(err, collections) {\n    if (err) return handleCallback(callback, err);\n    if (collections.length === 0) {\n      return handleCallback(\n        callback,\n        MongoError.create({ message: f('collection %s not found', self.s.namespace), driver: true })\n      );\n    }\n\n    handleCallback(callback, err, collections[0].options || null);\n  });\n};\n\ndefine.classMethod('options', { callback: true, promise: true });\n\n/**\n * Returns if the collection is a capped collection\n *\n * @method\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.isCapped = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, isCapped, [this, options, callback]);\n};\n\nvar isCapped = function(self, options, callback) {\n  self.options(options, function(err, document) {\n    if (err) return handleCallback(callback, err);\n    handleCallback(callback, null, document && document.capped);\n  });\n};\n\ndefine.classMethod('isCapped', { callback: true, promise: true });\n\n/**\n * Creates an index on the db and collection collection.\n * @method\n * @param {(string|object)} fieldOrSpec Defines the index.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.unique=false] Creates an unique index.\n * @param {boolean} [options.sparse=false] Creates a sparse index.\n * @param {boolean} [options.background=false] Creates the index in the background, yielding whenever possible.\n * @param {boolean} [options.dropDups=false] A unique index cannot be created on a key that has pre-existing duplicate values. If you would like to create the index anyway, keeping the first document the database indexes and deleting all subsequent documents that have duplicate value\n * @param {number} [options.min=null] For geospatial indexes set the lower bound for the co-ordinates.\n * @param {number} [options.max=null] For geospatial indexes set the high bound for the co-ordinates.\n * @param {number} [options.v=null] Specify the format version of the indexes.\n * @param {number} [options.expireAfterSeconds=null] Allows you to expire data on indexes applied to a data (MongoDB 2.2 or higher)\n * @param {string} [options.name=null] Override the autogenerated index name (useful if the resulting name is larger than 128 bytes)\n * @param {object} [options.partialFilterExpression=null] Creates a partial index based on the given filter object (MongoDB 3.2 or higher)\n * @param {object} [options.collation=null] Specify collation (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.createIndex = function(fieldOrSpec, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, createIndex, [this, fieldOrSpec, options, callback]);\n};\n\nvar createIndex = function(self, fieldOrSpec, options, callback) {\n  self.s.db.createIndex(self.s.name, fieldOrSpec, options, callback);\n};\n\ndefine.classMethod('createIndex', { callback: true, promise: true });\n\n/**\n * Creates multiple indexes in the collection, this method is only supported for\n * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n * error. Index specifications are defined at http://docs.mongodb.org/manual/reference/command/createIndexes/.\n * @method\n * @param {array} indexSpecs An array of index specifications to be created\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.createIndexes = function(indexSpecs, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n\n  options = options ? shallowClone(options) : {};\n  if (typeof options.maxTimeMS !== 'number') delete options.maxTimeMS;\n\n  return executeOperation(this.s.topology, createIndexes, [this, indexSpecs, options, callback]);\n};\n\nvar createIndexes = function(self, indexSpecs, options, callback) {\n  var capabilities = self.s.topology.capabilities();\n\n  // Ensure we generate the correct name if the parameter is not set\n  for (var i = 0; i < indexSpecs.length; i++) {\n    if (indexSpecs[i].name == null) {\n      var keys = [];\n\n      // Did the user pass in a collation, check if our write server supports it\n      if (indexSpecs[i].collation && capabilities && !capabilities.commandsTakeCollation) {\n        return callback(new MongoError(f('server/primary/mongos does not support collation')));\n      }\n\n      for (var name in indexSpecs[i].key) {\n        keys.push(f('%s_%s', name, indexSpecs[i].key[name]));\n      }\n\n      // Set the name\n      indexSpecs[i].name = keys.join('_');\n    }\n  }\n\n  options = Object.assign({}, options, { readPreference: ReadPreference.PRIMARY });\n\n  // Execute the index\n  self.s.db.command(\n    {\n      createIndexes: self.s.name,\n      indexes: indexSpecs\n    },\n    options,\n    callback\n  );\n};\n\ndefine.classMethod('createIndexes', { callback: true, promise: true });\n\n/**\n * Drops an index from this collection.\n * @method\n * @param {string} indexName Name of the index to drop.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {number} [options.maxTimeMS] Number of miliseconds to wait before aborting the query.\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.dropIndex = function(indexName, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n\n  options = args.length ? args.shift() || {} : {};\n  // Run only against primary\n  options.readPreference = ReadPreference.PRIMARY;\n\n  return executeOperation(this.s.topology, dropIndex, [this, indexName, options, callback]);\n};\n\nvar dropIndex = function(self, indexName, options, callback) {\n  // Delete index command\n  var cmd = { dropIndexes: self.s.name, index: indexName };\n\n  // Decorate command with writeConcern if supported\n  decorateWithWriteConcern(cmd, self, options);\n\n  // Execute command\n  self.s.db.command(cmd, options, function(err, result) {\n    if (typeof callback !== 'function') return;\n    if (err) return handleCallback(callback, err, null);\n    handleCallback(callback, null, result);\n  });\n};\n\ndefine.classMethod('dropIndex', { callback: true, promise: true });\n\n/**\n * Drops all indexes from this collection.\n * @method\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {number} [options.maxTimeMS] Number of miliseconds to wait before aborting the query.\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.dropIndexes = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options ? shallowClone(options) : {};\n\n  if (typeof options.maxTimeMS !== 'number') delete options.maxTimeMS;\n\n  return executeOperation(this.s.topology, dropIndexes, [this, options, callback]);\n};\n\nvar dropIndexes = function(self, options, callback) {\n  self.dropIndex('*', options, function(err) {\n    if (err) return handleCallback(callback, err, false);\n    handleCallback(callback, null, true);\n  });\n};\n\ndefine.classMethod('dropIndexes', { callback: true, promise: true });\n\n/**\n * Drops all indexes from this collection.\n * @method\n * @deprecated use dropIndexes\n * @param {Collection~resultCallback} callback The command result callback\n * @return {Promise} returns Promise if no [callback] passed\n */\nCollection.prototype.dropAllIndexes = Collection.prototype.dropIndexes;\n\ndefine.classMethod('dropAllIndexes', { callback: true, promise: true });\n\n/**\n * Reindex all indexes on the collection\n * Warning: reIndex is a blocking operation (indexes are rebuilt in the foreground) and will be slow for large collections.\n * @method\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.reIndex = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, reIndex, [this, options, callback]);\n};\n\nvar reIndex = function(self, options, callback) {\n  // Reindex\n  var cmd = { reIndex: self.s.name };\n\n  // Execute the command\n  self.s.db.command(cmd, options, function(err, result) {\n    if (callback == null) return;\n    if (err) return handleCallback(callback, err, null);\n    handleCallback(callback, null, result.ok ? true : false);\n  });\n};\n\ndefine.classMethod('reIndex', { callback: true, promise: true });\n\n/**\n * Get the list of all indexes information for the collection.\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.batchSize=null] The batchSize for the returned command cursor or if pre 2.8 the systems batch collection\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @return {CommandCursor}\n */\nCollection.prototype.listIndexes = function(options) {\n  options = options || {};\n  // Clone the options\n  options = shallowClone(options);\n  // Determine the read preference in the options.\n  options = getReadPreference(this, options, this.s.db, this);\n  // Set the CommandCursor constructor\n  options.cursorFactory = CommandCursor;\n  // Set the promiseLibrary\n  options.promiseLibrary = this.s.promiseLibrary;\n\n  if (!this.s.topology.capabilities()) {\n    throw new MongoError('cannot connect to server');\n  }\n\n  // We have a list collections command\n  if (this.s.topology.capabilities().hasListIndexesCommand) {\n    // Cursor options\n    var cursor = options.batchSize ? { batchSize: options.batchSize } : {};\n    // Build the command\n    var command = { listIndexes: this.s.name, cursor: cursor };\n    // Execute the cursor\n    cursor = this.s.topology.cursor(f('%s.$cmd', this.s.dbName), command, options);\n    // Do we have a readPreference, apply it\n    if (options.readPreference) cursor.setReadPreference(options.readPreference);\n    // Return the cursor\n    return cursor;\n  }\n\n  // Get the namespace\n  var ns = f('%s.system.indexes', this.s.dbName);\n  // Get the query\n  cursor = this.s.topology.cursor(ns, { find: ns, query: { ns: this.s.namespace } }, options);\n  // Do we have a readPreference, apply it\n  if (options.readPreference) cursor.setReadPreference(options.readPreference);\n  // Set the passed in batch size if one was provided\n  if (options.batchSize) cursor = cursor.batchSize(options.batchSize);\n  // Return the cursor\n  return cursor;\n};\n\ndefine.classMethod('listIndexes', { callback: false, promise: false, returns: [CommandCursor] });\n\n/**\n * Ensures that an index exists, if it does not it creates it\n * @method\n * @deprecated use createIndexes instead\n * @param {(string|object)} fieldOrSpec Defines the index.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.unique=false] Creates an unique index.\n * @param {boolean} [options.sparse=false] Creates a sparse index.\n * @param {boolean} [options.background=false] Creates the index in the background, yielding whenever possible.\n * @param {boolean} [options.dropDups=false] A unique index cannot be created on a key that has pre-existing duplicate values. If you would like to create the index anyway, keeping the first document the database indexes and deleting all subsequent documents that have duplicate value\n * @param {number} [options.min=null] For geospatial indexes set the lower bound for the co-ordinates.\n * @param {number} [options.max=null] For geospatial indexes set the high bound for the co-ordinates.\n * @param {number} [options.v=null] Specify the format version of the indexes.\n * @param {number} [options.expireAfterSeconds=null] Allows you to expire data on indexes applied to a data (MongoDB 2.2 or higher)\n * @param {number} [options.name=null] Override the autogenerated index name (useful if the resulting name is larger than 128 bytes)\n * @param {object} [options.collation=null] Specify collation (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.ensureIndex = function(fieldOrSpec, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, ensureIndex, [this, fieldOrSpec, options, callback]);\n};\n\nvar ensureIndex = function(self, fieldOrSpec, options, callback) {\n  self.s.db.ensureIndex(self.s.name, fieldOrSpec, options, callback);\n};\n\ndefine.classMethod('ensureIndex', { callback: true, promise: true });\n\n/**\n * Checks if one or more indexes exist on the collection, fails on first non-existing index\n * @method\n * @param {(string|array)} indexes One or more index names to check.\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.indexExists = function(indexes, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, indexExists, [this, indexes, options, callback]);\n};\n\nvar indexExists = function(self, indexes, options, callback) {\n  self.indexInformation(options, function(err, indexInformation) {\n    // If we have an error return\n    if (err != null) return handleCallback(callback, err, null);\n    // Let's check for the index names\n    if (!Array.isArray(indexes))\n      return handleCallback(callback, null, indexInformation[indexes] != null);\n    // Check in list of indexes\n    for (var i = 0; i < indexes.length; i++) {\n      if (indexInformation[indexes[i]] == null) {\n        return handleCallback(callback, null, false);\n      }\n    }\n\n    // All keys found return true\n    return handleCallback(callback, null, true);\n  });\n};\n\ndefine.classMethod('indexExists', { callback: true, promise: true });\n\n/**\n * Retrieves this collections index info.\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.full=false] Returns the full raw index information.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.indexInformation = function(options, callback) {\n  var args = Array.prototype.slice.call(arguments, 0);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, indexInformation, [this, options, callback]);\n};\n\nvar indexInformation = function(self, options, callback) {\n  self.s.db.indexInformation(self.s.name, options, callback);\n};\n\ndefine.classMethod('indexInformation', { callback: true, promise: true });\n\n/**\n * The callback format for results\n * @callback Collection~countCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {number} result The count of documents that matched the query.\n */\n\n/**\n * Count number of matching documents in the db to a query.\n * @method\n * @param {object} query The query for the count.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.limit=null] The limit of documents to count.\n * @param {boolean} [options.skip=null] The number of documents to skip for the count.\n * @param {string} [options.hint=null] An index name hint for the query.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {number} [options.maxTimeMS=null] Number of miliseconds to wait before aborting the query.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~countCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.count = function(query, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 0);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  query = args.length ? args.shift() || {} : {};\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, count, [this, query, options, callback]);\n};\n\nvar count = function(self, query, options, callback) {\n  var skip = options.skip;\n  var limit = options.limit;\n  var hint = options.hint;\n  var maxTimeMS = options.maxTimeMS;\n\n  // Final query\n  var cmd = {\n    count: self.s.name,\n    query: query\n  };\n\n  // Add limit, skip and maxTimeMS if defined\n  if (typeof skip === 'number') cmd.skip = skip;\n  if (typeof limit === 'number') cmd.limit = limit;\n  if (typeof maxTimeMS === 'number') cmd.maxTimeMS = maxTimeMS;\n  if (hint) cmd.hint = hint;\n\n  options = shallowClone(options);\n\n  // Ensure we have the right read preference inheritance\n  options = getReadPreference(self, options, self.s.db);\n\n  // Do we have a readConcern specified\n  decorateWithReadConcern(cmd, self, options);\n\n  // Have we specified collation\n  decorateWithCollation(cmd, self, options);\n\n  // Execute command\n  self.s.db.command(cmd, options, function(err, result) {\n    if (err) return handleCallback(callback, err);\n    handleCallback(callback, null, result.n);\n  });\n};\n\ndefine.classMethod('count', { callback: true, promise: true });\n\n/**\n * The distinct command returns returns a list of distinct values for the given key across a collection.\n * @method\n * @param {string} key Field of the document to find distinct values for.\n * @param {object} query The query for filtering the set of documents to which we apply the distinct filter.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {number} [options.maxTimeMS=null] Number of miliseconds to wait before aborting the query.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.distinct = function(key, query, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  var queryOption = args.length ? args.shift() || {} : {};\n  var optionsOption = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, distinct, [\n    this,\n    key,\n    queryOption,\n    optionsOption,\n    callback\n  ]);\n};\n\nvar distinct = function(self, key, query, options, callback) {\n  // maxTimeMS option\n  var maxTimeMS = options.maxTimeMS;\n\n  // Distinct command\n  var cmd = {\n    distinct: self.s.name,\n    key: key,\n    query: query\n  };\n\n  options = shallowClone(options);\n  // Ensure we have the right read preference inheritance\n  options = getReadPreference(self, options, self.s.db, self);\n\n  // Add maxTimeMS if defined\n  if (typeof maxTimeMS === 'number') cmd.maxTimeMS = maxTimeMS;\n\n  // Do we have a readConcern specified\n  decorateWithReadConcern(cmd, self, options);\n\n  // Have we specified collation\n  decorateWithCollation(cmd, self, options);\n\n  // Execute the command\n  self.s.db.command(cmd, options, function(err, result) {\n    if (err) return handleCallback(callback, err);\n    handleCallback(callback, null, result.values);\n  });\n};\n\ndefine.classMethod('distinct', { callback: true, promise: true });\n\n/**\n * Retrieve all the indexes on the collection.\n * @method\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.indexes = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, indexes, [this, options, callback]);\n};\n\nvar indexes = function(self, options, callback) {\n  options = Object.assign({}, { full: true }, options);\n  self.s.db.indexInformation(self.s.name, options, callback);\n};\n\ndefine.classMethod('indexes', { callback: true, promise: true });\n\n/**\n * Get all the collection statistics.\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.scale=null] Divide the returned sizes by scale value.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The collection result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.stats = function(options, callback) {\n  var args = Array.prototype.slice.call(arguments, 0);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, stats, [this, options, callback]);\n};\n\nvar stats = function(self, options, callback) {\n  // Build command object\n  var commandObject = {\n    collStats: self.s.name\n  };\n\n  // Check if we have the scale value\n  if (options['scale'] != null) commandObject['scale'] = options['scale'];\n\n  options = shallowClone(options);\n  // Ensure we have the right read preference inheritance\n  options = getReadPreference(self, options, self.s.db, self);\n\n  // Execute the command\n  self.s.db.command(commandObject, options, callback);\n};\n\ndefine.classMethod('stats', { callback: true, promise: true });\n\n/**\n * @typedef {Object} Collection~findAndModifyWriteOpResult\n * @property {object} value Document returned from findAndModify command.\n * @property {object} lastErrorObject The raw lastErrorObject returned from the command.\n * @property {Number} ok Is 1 if the command executed correctly.\n */\n\n/**\n * The callback format for inserts\n * @callback Collection~findAndModifyCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection~findAndModifyWriteOpResult} result The result object if the command was executed successfully.\n */\n\n/**\n * Find a document and delete it in one atomic operation, requires a write lock for the duration of the operation.\n *\n * @method\n * @param {object} filter Document selection filter.\n * @param {object} [options=null] Optional settings.\n * @param {object} [options.projection=null] Limits the fields to return for all matching documents.\n * @param {object} [options.sort=null] Determines which document the operation modifies if the query selects multiple documents.\n * @param {number} [options.maxTimeMS=null] The maximum amount of time to allow the query to run.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~findAndModifyCallback} [callback] The collection result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.findOneAndDelete = function(filter, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Basic validation\n  if (filter == null || typeof filter !== 'object')\n    throw toError('filter parameter must be an object');\n\n  return executeOperation(this.s.topology, findOneAndDelete, [this, filter, options, callback]);\n};\n\nvar findOneAndDelete = function(self, filter, options, callback) {\n  // Final options\n  var finalOptions = shallowClone(options);\n  finalOptions['fields'] = options.projection;\n  finalOptions['remove'] = true;\n  // Execute find and Modify\n  self.findAndModify(filter, options.sort, null, finalOptions, callback);\n};\n\ndefine.classMethod('findOneAndDelete', { callback: true, promise: true });\n\n/**\n * Find a document and replace it in one atomic operation, requires a write lock for the duration of the operation.\n *\n * @method\n * @param {object} filter Document selection filter.\n * @param {object} replacement Document replacing the matching document.\n * @param {object} [options=null] Optional settings.\n * @param {object} [options.projection=null] Limits the fields to return for all matching documents.\n * @param {object} [options.sort=null] Determines which document the operation modifies if the query selects multiple documents.\n * @param {number} [options.maxTimeMS=null] The maximum amount of time to allow the query to run.\n * @param {boolean} [options.upsert=false] Upsert the document if it does not exist.\n * @param {boolean} [options.returnOriginal=true] When false, returns the updated document rather than the original. The default is true.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~findAndModifyCallback} [callback] The collection result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.findOneAndReplace = function(filter, replacement, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Basic validation\n  if (filter == null || typeof filter !== 'object')\n    throw toError('filter parameter must be an object');\n  if (replacement == null || typeof replacement !== 'object')\n    throw toError('replacement parameter must be an object');\n\n  return executeOperation(this.s.topology, findOneAndReplace, [\n    this,\n    filter,\n    replacement,\n    options,\n    callback\n  ]);\n};\n\nvar findOneAndReplace = function(self, filter, replacement, options, callback) {\n  // Final options\n  var finalOptions = shallowClone(options);\n  finalOptions['fields'] = options.projection;\n  finalOptions['update'] = true;\n  finalOptions['new'] = options.returnOriginal !== void 0 ? !options.returnOriginal : false;\n  finalOptions['upsert'] = options.upsert !== void 0 ? !!options.upsert : false;\n\n  // Execute findAndModify\n  self.findAndModify(filter, options.sort, replacement, finalOptions, callback);\n};\n\ndefine.classMethod('findOneAndReplace', { callback: true, promise: true });\n\n/**\n * Find a document and update it in one atomic operation, requires a write lock for the duration of the operation.\n *\n * @method\n * @param {object} filter Document selection filter.\n * @param {object} update Update operations to be performed on the document\n * @param {object} [options=null] Optional settings.\n * @param {object} [options.projection=null] Limits the fields to return for all matching documents.\n * @param {object} [options.sort=null] Determines which document the operation modifies if the query selects multiple documents.\n * @param {number} [options.maxTimeMS=null] The maximum amount of time to allow the query to run.\n * @param {boolean} [options.upsert=false] Upsert the document if it does not exist.\n * @param {boolean} [options.returnOriginal=true] When false, returns the updated document rather than the original. The default is true.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~findAndModifyCallback} [callback] The collection result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.findOneAndUpdate = function(filter, update, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Basic validation\n  if (filter == null || typeof filter !== 'object')\n    throw toError('filter parameter must be an object');\n  if (update == null || typeof update !== 'object')\n    throw toError('update parameter must be an object');\n\n  return executeOperation(this.s.topology, findOneAndUpdate, [\n    this,\n    filter,\n    update,\n    options,\n    callback\n  ]);\n};\n\nvar findOneAndUpdate = function(self, filter, update, options, callback) {\n  // Final options\n  var finalOptions = shallowClone(options);\n  finalOptions['fields'] = options.projection;\n  finalOptions['update'] = true;\n  finalOptions['new'] =\n    typeof options.returnOriginal === 'boolean' ? !options.returnOriginal : false;\n  finalOptions['upsert'] = typeof options.upsert === 'boolean' ? options.upsert : false;\n\n  // Execute findAndModify\n  self.findAndModify(filter, options.sort, update, finalOptions, callback);\n};\n\ndefine.classMethod('findOneAndUpdate', { callback: true, promise: true });\n\n/**\n * Find and update a document.\n * @method\n * @param {object} query Query object to locate the object to modify.\n * @param {array} sort If multiple docs match, choose the first one in the specified sort order as the object to manipulate.\n * @param {object} doc The fields/vals to be updated.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.remove=false] Set to true to remove the object before returning.\n * @param {boolean} [options.upsert=false] Perform an upsert operation.\n * @param {boolean} [options.new=false] Set to true if you want to return the modified object rather than the original. Ignored for remove.\n * @param {object} [options.projection=null] Object containing the field projection for the result returned from the operation.\n * @param {object} [options.fields=null] **Deprecated** Use `options.projection` instead\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~findAndModifyCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n * @deprecated use findOneAndUpdate, findOneAndReplace or findOneAndDelete instead\n */\nCollection.prototype.findAndModify = function(query, sort, doc, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  sort = args.length ? args.shift() || [] : [];\n  doc = args.length ? args.shift() : null;\n  options = args.length ? args.shift() || {} : {};\n\n  // Clone options\n  options = shallowClone(options);\n  // Force read preference primary\n  options.readPreference = ReadPreference.PRIMARY;\n\n  return executeOperation(this.s.topology, findAndModify, [\n    this,\n    query,\n    sort,\n    doc,\n    options,\n    callback\n  ]);\n};\n\nvar findAndModify = function(self, query, sort, doc, options, callback) {\n  // Create findAndModify command object\n  var queryObject = {\n    findandmodify: self.s.name,\n    query: query\n  };\n\n  sort = formattedOrderClause(sort);\n  if (sort) {\n    queryObject.sort = sort;\n  }\n\n  queryObject.new = options.new ? true : false;\n  queryObject.remove = options.remove ? true : false;\n  queryObject.upsert = options.upsert ? true : false;\n\n  const projection = options.projection || options.fields;\n\n  if (projection) {\n    queryObject.fields = projection;\n  }\n\n  if (options.arrayFilters) {\n    queryObject.arrayFilters = options.arrayFilters;\n    delete options.arrayFilters;\n  }\n\n  if (doc && !options.remove) {\n    queryObject.update = doc;\n  }\n\n  if (options.maxTimeMS) queryObject.maxTimeMS = options.maxTimeMS;\n\n  // Either use override on the function, or go back to default on either the collection\n  // level or db\n  if (options['serializeFunctions'] != null) {\n    options['serializeFunctions'] = options['serializeFunctions'];\n  } else {\n    options['serializeFunctions'] = self.s.serializeFunctions;\n  }\n\n  // No check on the documents\n  options.checkKeys = false;\n\n  // Get the write concern settings\n  var finalOptions = writeConcern(options, self.s.db, self, options);\n\n  // Decorate the findAndModify command with the write Concern\n  if (finalOptions.writeConcern) {\n    queryObject.writeConcern = finalOptions.writeConcern;\n  }\n\n  // Have we specified bypassDocumentValidation\n  if (typeof finalOptions.bypassDocumentValidation === 'boolean') {\n    queryObject.bypassDocumentValidation = finalOptions.bypassDocumentValidation;\n  }\n\n  // Have we specified collation\n  decorateWithCollation(queryObject, self, finalOptions);\n\n  // Execute the command\n  self.s.db.command(queryObject, finalOptions, function(err, result) {\n    if (err) return handleCallback(callback, err, null);\n    return handleCallback(callback, null, result);\n  });\n};\n\ndefine.classMethod('findAndModify', { callback: true, promise: true });\n\n/**\n * Find and remove a document.\n * @method\n * @param {object} query Query object to locate the object to modify.\n * @param {array} sort If multiple docs match, choose the first one in the specified sort order as the object to manipulate.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n * @deprecated use findOneAndDelete instead\n */\nCollection.prototype.findAndRemove = function(query, sort, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  sort = args.length ? args.shift() || [] : [];\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, findAndRemove, [this, query, sort, options, callback]);\n};\n\nvar findAndRemove = function(self, query, sort, options, callback) {\n  // Add the remove option\n  options['remove'] = true;\n  // Execute the callback\n  self.findAndModify(query, sort, null, options, callback);\n};\n\ndefine.classMethod('findAndRemove', { callback: true, promise: true });\n\nfunction decorateWithWriteConcern(command, self, options) {\n  // Do we support collation 3.4 and higher\n  var capabilities = self.s.topology.capabilities();\n  // Do we support write concerns 3.4 and higher\n  if (capabilities && capabilities.commandsTakeWriteConcern) {\n    // Get the write concern settings\n    var finalOptions = writeConcern(shallowClone(options), self.s.db, self, options);\n    // Add the write concern to the command\n    if (finalOptions.writeConcern) {\n      command.writeConcern = finalOptions.writeConcern;\n    }\n  }\n}\n\nfunction decorateWithCollation(command, self, options) {\n  // Do we support collation 3.4 and higher\n  var capabilities = self.s.topology.capabilities();\n  // Do we support write concerns 3.4 and higher\n  if (capabilities && capabilities.commandsTakeCollation) {\n    if (options.collation && typeof options.collation === 'object') {\n      command.collation = options.collation;\n    }\n  }\n}\n\nfunction decorateWithReadConcern(command, self, options) {\n  let readConcern = Object.assign({}, command.readConcern || {});\n  if (self.s.readConcern) {\n    Object.assign(readConcern, self.s.readConcern);\n  }\n\n  if (\n    options.session &&\n    options.session.supports.causalConsistency &&\n    options.session.operationTime\n  ) {\n    Object.assign(readConcern, { afterClusterTime: options.session.operationTime });\n  }\n\n  if (Object.keys(readConcern).length > 0) {\n    Object.assign(command, { readConcern: readConcern });\n  }\n}\n\n/**\n * Execute an aggregation framework pipeline against the collection, needs MongoDB >= 2.2\n * @method\n * @param {object} pipeline Array containing all the aggregation framework commands for the execution.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {object} [options.cursor=null] Return the query as cursor, on 2.6 > it returns as a real cursor on pre 2.6 it returns as an emulated cursor.\n * @param {number} [options.cursor.batchSize=null] The batchSize for the cursor\n * @param {boolean} [options.explain=false] Explain returns the aggregation execution plan (requires mongodb 2.6 >).\n * @param {boolean} [options.allowDiskUse=false] allowDiskUse lets the server know if it can use disk to store temporary results for the aggregation (requires mongodb 2.6 >).\n * @param {number} [options.maxTimeMS=null] maxTimeMS specifies a cumulative time limit in milliseconds for processing operations on the cursor. MongoDB interrupts the operation at the earliest following interrupt point.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers.\n * @param {boolean} [options.promoteLongs=true] Promotes Long values to number if they fit inside the 53 bits resolution.\n * @param {boolean} [options.promoteValues=true] Promotes BSON values to native types where possible, set to false to only receive wrapper types.\n * @param {boolean} [options.promoteBuffers=false] Promotes Binary BSON values to native Node Buffers.\n * @param {object} [options.collation=null] Specify collation (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @param {string} [options.comment] Add a comment to an aggregation command\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~aggregationCallback} callback The command result callback\n * @return {(null|AggregationCursor)}\n */\nCollection.prototype.aggregate = function(pipeline, options, callback) {\n  var self = this;\n\n  if (Array.isArray(pipeline)) {\n    // Set up callback if one is provided\n    if (typeof options === 'function') {\n      callback = options;\n      options = {};\n    }\n\n    // If we have no options or callback we are doing\n    // a cursor based aggregation\n    if (options == null && callback == null) {\n      options = {};\n    }\n  } else {\n    // Aggregation pipeline passed as arguments on the method\n    var args = Array.prototype.slice.call(arguments, 0);\n    // Get the callback\n    callback = args.pop();\n    // Get the possible options object\n    var opts = args[args.length - 1];\n    // If it contains any of the admissible options pop it of the args\n    options =\n      opts &&\n      (opts.readPreference ||\n        opts.explain ||\n        opts.cursor ||\n        opts.out ||\n        opts.maxTimeMS ||\n        opts.hint ||\n        opts.allowDiskUse)\n        ? args.pop()\n        : {};\n    // Left over arguments is the pipeline\n    pipeline = args;\n  }\n\n  // Ignore readConcern option\n  var ignoreReadConcern = false;\n\n  // Build the command\n  var command = { aggregate: this.s.name, pipeline: pipeline };\n\n  // If out was specified\n  if (typeof options.out === 'string') {\n    pipeline.push({ $out: options.out });\n    // Ignore read concern\n    ignoreReadConcern = true;\n  } else if (pipeline.length > 0 && pipeline[pipeline.length - 1]['$out']) {\n    ignoreReadConcern = true;\n  }\n\n  // Decorate command with writeConcern if out has been specified\n  if (pipeline.length > 0 && pipeline[pipeline.length - 1]['$out']) {\n    decorateWithWriteConcern(command, self, options);\n  }\n\n  // Have we specified collation\n  decorateWithCollation(command, self, options);\n\n  // If we have bypassDocumentValidation set\n  if (typeof options.bypassDocumentValidation === 'boolean') {\n    command.bypassDocumentValidation = options.bypassDocumentValidation;\n  }\n\n  // Do we have a readConcern specified\n  if (!ignoreReadConcern) {\n    decorateWithReadConcern(command, self, options);\n  }\n\n  // If we have allowDiskUse defined\n  if (options.allowDiskUse) command.allowDiskUse = options.allowDiskUse;\n  if (typeof options.maxTimeMS === 'number') command.maxTimeMS = options.maxTimeMS;\n\n  // If we are giving a hint\n  if (options.hint) command.hint = options.hint;\n\n  options = shallowClone(options);\n  // Ensure we have the right read preference inheritance\n  options = getReadPreference(this, options, this.s.db, this);\n\n  // If explain has been specified add it\n  if (options.explain) {\n    if (command.readConcern || command.writeConcern) {\n      throw toError('\"explain\" cannot be used on an aggregate call with readConcern/writeConcern');\n    }\n    command.explain = options.explain;\n  }\n\n  if (typeof options.comment === 'string') command.comment = options.comment;\n\n  // Validate that cursor options is valid\n  if (options.cursor != null && typeof options.cursor !== 'object') {\n    throw toError('cursor options must be an object');\n  }\n\n  options.cursor = options.cursor || { batchSize: 1000 };\n  command.cursor = options.cursor;\n\n  // promiseLibrary\n  options.promiseLibrary = this.s.promiseLibrary;\n\n  // Set the AggregationCursor constructor\n  options.cursorFactory = AggregationCursor;\n  if (typeof callback !== 'function') {\n    if (!this.s.topology.capabilities()) {\n      throw new MongoError('cannot connect to server');\n    }\n\n    // Allow disk usage command\n    if (typeof options.allowDiskUse === 'boolean') command.allowDiskUse = options.allowDiskUse;\n    if (typeof options.maxTimeMS === 'number') command.maxTimeMS = options.maxTimeMS;\n\n    // Execute the cursor\n    return this.s.topology.cursor(this.s.namespace, command, options);\n  }\n\n  return handleCallback(callback, null, this.s.topology.cursor(this.s.namespace, command, options));\n};\n\ndefine.classMethod('aggregate', { callback: true, promise: false });\n\n/**\n * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n * @method\n * @since 3.0.0\n * @param {Array} [pipeline=null] An array of {@link https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n * @param {object} [options=null] Optional settings\n * @param {string} [options.fullDocument='default'] Allowed values: default, updateLookup. When set to updateLookup, the change stream will include both a delta describing the changes to the document, as well as a copy of the entire document that was changed from some time after the change occurred.\n * @param {object} [options.resumeAfter=null] Specifies the logical starting point for the new change stream. This should be the _id field from a previously returned change stream document.\n * @param {number} [options.maxAwaitTimeMS] The maximum amount of time for the server to wait on new documents to satisfy a change stream query\n * @param {number} [options.batchSize=null] The number of documents to return per batch. See {@link https://docs.mongodb.com/manual/reference/command/aggregate|aggregation documentation}.\n * @param {object} [options.collation=null] Specify collation settings for operation. See {@link https://docs.mongodb.com/manual/reference/command/aggregate|aggregation documentation}.\n * @param {ReadPreference} [options.readPreference=null] The read preference. Defaults to the read preference of the database or collection. See {@link https://docs.mongodb.com/manual/reference/read-preference|read preference documentation}.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @return {ChangeStream} a ChangeStream instance.\n */\nCollection.prototype.watch = function(pipeline, options) {\n  pipeline = pipeline || [];\n  options = options || {};\n\n  // Allow optionally not specifying a pipeline\n  if (!Array.isArray(pipeline)) {\n    options = pipeline;\n    pipeline = [];\n  }\n\n  return new ChangeStream(this, pipeline, options);\n};\n\ndefine.classMethod('watch', { callback: false, promise: false });\n\n/**\n * The callback format for results\n * @callback Collection~parallelCollectionScanCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Cursor[]} cursors A list of cursors returned allowing for parallel reading of collection.\n */\n\n/**\n * Return N number of parallel cursors for a collection allowing parallel reading of entire collection. There are\n * no ordering guarantees for returned results.\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {number} [options.batchSize=null] Set the batchSize for the getMoreCommand when iterating over the query results.\n * @param {number} [options.numCursors=1] The maximum number of parallel command cursors to return (the number of returned cursors will be in the range 1:numCursors)\n * @param {boolean} [options.raw=false] Return all BSON documents as Raw Buffer documents.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~parallelCollectionScanCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.parallelCollectionScan = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = { numCursors: 1 });\n  // Set number of cursors to 1\n  options.numCursors = options.numCursors || 1;\n  options.batchSize = options.batchSize || 1000;\n\n  options = shallowClone(options);\n  // Ensure we have the right read preference inheritance\n  options = getReadPreference(this, options, this.s.db, this);\n\n  // Add a promiseLibrary\n  options.promiseLibrary = this.s.promiseLibrary;\n\n  return executeOperation(this.s.topology, parallelCollectionScan, [this, options, callback], {\n    returnsCursor: true\n  });\n};\n\nvar parallelCollectionScan = function(self, options, callback) {\n  // Create command object\n  var commandObject = {\n    parallelCollectionScan: self.s.name,\n    numCursors: options.numCursors\n  };\n\n  // Do we have a readConcern specified\n  decorateWithReadConcern(commandObject, self, options);\n\n  // Store the raw value\n  var raw = options.raw;\n  delete options['raw'];\n\n  // Execute the command\n  self.s.db.command(commandObject, options, function(err, result) {\n    if (err) return handleCallback(callback, err, null);\n    if (result == null)\n      return handleCallback(\n        callback,\n        new Error('no result returned for parallelCollectionScan'),\n        null\n      );\n\n    var cursors = [];\n    // Add the raw back to the option\n    if (raw) options.raw = raw;\n    // Create command cursors for each item\n    for (var i = 0; i < result.cursors.length; i++) {\n      var rawId = result.cursors[i].cursor.id;\n      // Convert cursorId to Long if needed\n      var cursorId = typeof rawId === 'number' ? Long.fromNumber(rawId) : rawId;\n      // Add a command cursor\n      cursors.push(self.s.topology.cursor(self.s.namespace, cursorId, options));\n    }\n\n    handleCallback(callback, null, cursors);\n  });\n};\n\ndefine.classMethod('parallelCollectionScan', { callback: true, promise: true });\n\n/**\n * Execute a geo search using a geo haystack index on a collection.\n *\n * @method\n * @param {number} x Point to search on the x axis, ensure the indexes are ordered in the same order.\n * @param {number} y Point to search on the y axis, ensure the indexes are ordered in the same order.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {number} [options.maxDistance=null] Include results up to maxDistance from the point.\n * @param {object} [options.search=null] Filter the results by a query.\n * @param {number} [options.limit=false] Max number of results to return.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.geoHaystackSearch = function(x, y, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 2);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, geoHaystackSearch, [this, x, y, options, callback]);\n};\n\nvar geoHaystackSearch = function(self, x, y, options, callback) {\n  // Build command object\n  var commandObject = {\n    geoSearch: self.s.name,\n    near: [x, y]\n  };\n\n  // Remove read preference from hash if it exists\n  commandObject = decorateCommand(commandObject, options, { readPreference: true, session: true });\n\n  options = shallowClone(options);\n  // Ensure we have the right read preference inheritance\n  options = getReadPreference(self, options, self.s.db, self);\n\n  // Do we have a readConcern specified\n  decorateWithReadConcern(commandObject, self, options);\n\n  // Execute the command\n  self.s.db.command(commandObject, options, function(err, res) {\n    if (err) return handleCallback(callback, err);\n    if (res.err || res.errmsg) handleCallback(callback, toError(res));\n    // should we only be returning res.results here? Not sure if the user\n    // should see the other return information\n    handleCallback(callback, null, res);\n  });\n};\n\ndefine.classMethod('geoHaystackSearch', { callback: true, promise: true });\n\n/**\n * Group function helper\n * @ignore\n */\n// var groupFunction = function () {\n//   var c = db[ns].find(condition);\n//   var map = new Map();\n//   var reduce_function = reduce;\n//\n//   while (c.hasNext()) {\n//     var obj = c.next();\n//     var key = {};\n//\n//     for (var i = 0, len = keys.length; i < len; ++i) {\n//       var k = keys[i];\n//       key[k] = obj[k];\n//     }\n//\n//     var aggObj = map.get(key);\n//\n//     if (aggObj == null) {\n//       var newObj = Object.extend({}, key);\n//       aggObj = Object.extend(newObj, initial);\n//       map.put(key, aggObj);\n//     }\n//\n//     reduce_function(obj, aggObj);\n//   }\n//\n//   return { \"result\": map.values() };\n// }.toString();\nvar groupFunction =\n  'function () {\\nvar c = db[ns].find(condition);\\nvar map = new Map();\\nvar reduce_function = reduce;\\n\\nwhile (c.hasNext()) {\\nvar obj = c.next();\\nvar key = {};\\n\\nfor (var i = 0, len = keys.length; i < len; ++i) {\\nvar k = keys[i];\\nkey[k] = obj[k];\\n}\\n\\nvar aggObj = map.get(key);\\n\\nif (aggObj == null) {\\nvar newObj = Object.extend({}, key);\\naggObj = Object.extend(newObj, initial);\\nmap.put(key, aggObj);\\n}\\n\\nreduce_function(obj, aggObj);\\n}\\n\\nreturn { \"result\": map.values() };\\n}';\n\n/**\n * Run a group command across a collection\n *\n * @method\n * @param {(object|array|function|code)} keys An object, array or function expressing the keys to group by.\n * @param {object} condition An optional condition that must be true for a row to be considered.\n * @param {object} initial Initial value of the aggregation counter object.\n * @param {(function|Code)} reduce The reduce function aggregates (reduces) the objects iterated\n * @param {(function|Code)} finalize An optional function to be run on each item in the result set just before the item is returned.\n * @param {boolean} command Specify if you wish to run using the internal group command or using eval, default is true.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n * @deprecated MongoDB 3.6 or higher will no longer support the group command. We recommend rewriting using the aggregation framework.\n */\nCollection.prototype.group = function(\n  keys,\n  condition,\n  initial,\n  reduce,\n  finalize,\n  command,\n  options,\n  callback\n) {\n  var args = Array.prototype.slice.call(arguments, 3);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  reduce = args.length ? args.shift() : null;\n  finalize = args.length ? args.shift() : null;\n  command = args.length ? args.shift() : null;\n  options = args.length ? args.shift() || {} : {};\n\n  // Make sure we are backward compatible\n  if (!(typeof finalize === 'function')) {\n    command = finalize;\n    finalize = null;\n  }\n\n  if (\n    !Array.isArray(keys) &&\n    keys instanceof Object &&\n    typeof keys !== 'function' &&\n    !(keys._bsontype === 'Code')\n  ) {\n    keys = Object.keys(keys);\n  }\n\n  if (typeof reduce === 'function') {\n    reduce = reduce.toString();\n  }\n\n  if (typeof finalize === 'function') {\n    finalize = finalize.toString();\n  }\n\n  // Set up the command as default\n  command = command == null ? true : command;\n\n  return executeOperation(this.s.topology, group, [\n    this,\n    keys,\n    condition,\n    initial,\n    reduce,\n    finalize,\n    command,\n    options,\n    callback\n  ]);\n};\n\nvar group = function(self, keys, condition, initial, reduce, finalize, command, options, callback) {\n  // Execute using the command\n  if (command) {\n    var reduceFunction = reduce && reduce._bsontype === 'Code' ? reduce : new Code(reduce);\n\n    var selector = {\n      group: {\n        ns: self.s.name,\n        $reduce: reduceFunction,\n        cond: condition,\n        initial: initial,\n        out: 'inline'\n      }\n    };\n\n    // if finalize is defined\n    if (finalize != null) selector.group['finalize'] = finalize;\n    // Set up group selector\n    if ('function' === typeof keys || (keys && keys._bsontype === 'Code')) {\n      selector.group.$keyf = keys && keys._bsontype === 'Code' ? keys : new Code(keys);\n    } else {\n      var hash = {};\n      keys.forEach(function(key) {\n        hash[key] = 1;\n      });\n      selector.group.key = hash;\n    }\n\n    options = shallowClone(options);\n    // Ensure we have the right read preference inheritance\n    options = getReadPreference(self, options, self.s.db, self);\n\n    // Do we have a readConcern specified\n    decorateWithReadConcern(selector, self, options);\n\n    // Have we specified collation\n    decorateWithCollation(selector, self, options);\n\n    // Execute command\n    self.s.db.command(selector, options, function(err, result) {\n      if (err) return handleCallback(callback, err, null);\n      handleCallback(callback, null, result.retval);\n    });\n  } else {\n    // Create execution scope\n    var scope = reduce != null && reduce._bsontype === 'Code' ? reduce.scope : {};\n\n    scope.ns = self.s.name;\n    scope.keys = keys;\n    scope.condition = condition;\n    scope.initial = initial;\n\n    // Pass in the function text to execute within mongodb.\n    var groupfn = groupFunction.replace(/ reduce;/, reduce.toString() + ';');\n\n    self.s.db.eval(new Code(groupfn, scope), null, options, function(err, results) {\n      if (err) return handleCallback(callback, err, null);\n      handleCallback(callback, null, results.result || results);\n    });\n  }\n};\n\ndefine.classMethod('group', { callback: true, promise: true });\n\n/**\n * Functions that are passed as scope args must\n * be converted to Code instances.\n * @ignore\n */\nfunction processScope(scope) {\n  if (!isObject(scope) || scope._bsontype === 'ObjectID') {\n    return scope;\n  }\n\n  var keys = Object.keys(scope);\n  var i = keys.length;\n  var key;\n  var new_scope = {};\n\n  while (i--) {\n    key = keys[i];\n    if ('function' === typeof scope[key]) {\n      new_scope[key] = new Code(String(scope[key]));\n    } else {\n      new_scope[key] = processScope(scope[key]);\n    }\n  }\n\n  return new_scope;\n}\n\n/**\n * Run Map Reduce across a collection. Be aware that the inline option for out will return an array of results not a collection.\n *\n * @method\n * @param {(function|string)} map The mapping function.\n * @param {(function|string)} reduce The reduce function.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {object} [options.out=null] Sets the output target for the map reduce job. *{inline:1} | {replace:'collectionName'} | {merge:'collectionName'} | {reduce:'collectionName'}*\n * @param {object} [options.query=null] Query filter object.\n * @param {object} [options.sort=null] Sorts the input objects using this key. Useful for optimization, like sorting by the emit key for fewer reduces.\n * @param {number} [options.limit=null] Number of objects to return from collection.\n * @param {boolean} [options.keeptemp=false] Keep temporary data.\n * @param {(function|string)} [options.finalize=null] Finalize function.\n * @param {object} [options.scope=null] Can pass in variables that can be access from map/reduce/finalize.\n * @param {boolean} [options.jsMode=false] It is possible to make the execution stay in JS. Provided in MongoDB > 2.0.X.\n * @param {boolean} [options.verbose=false] Provide statistics on job execution time.\n * @param {boolean} [options.bypassDocumentValidation=false] Allow driver to bypass schema validation in MongoDB 3.2 or higher.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Collection~resultCallback} [callback] The command result callback\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nCollection.prototype.mapReduce = function(map, reduce, options, callback) {\n  if ('function' === typeof options) (callback = options), (options = {});\n  // Out must allways be defined (make sure we don't break weirdly on pre 1.8+ servers)\n  if (null == options.out) {\n    throw new Error(\n      'the out option parameter must be defined, see mongodb docs for possible values'\n    );\n  }\n\n  if ('function' === typeof map) {\n    map = map.toString();\n  }\n\n  if ('function' === typeof reduce) {\n    reduce = reduce.toString();\n  }\n\n  if ('function' === typeof options.finalize) {\n    options.finalize = options.finalize.toString();\n  }\n\n  return executeOperation(this.s.topology, mapReduce, [this, map, reduce, options, callback]);\n};\n\nvar mapReduce = function(self, map, reduce, options, callback) {\n  var mapCommandHash = {\n    mapreduce: self.s.name,\n    map: map,\n    reduce: reduce\n  };\n\n  // Exclusion list\n  var exclusionList = ['readPreference', 'session'];\n\n  // Add any other options passed in\n  for (var n in options) {\n    if ('scope' === n) {\n      mapCommandHash[n] = processScope(options[n]);\n    } else {\n      // Only include if not in exclusion list\n      if (exclusionList.indexOf(n) === -1) {\n        mapCommandHash[n] = options[n];\n      }\n    }\n  }\n\n  options = shallowClone(options);\n\n  // Ensure we have the right read preference inheritance\n  options = getReadPreference(self, options, self.s.db, self);\n\n  // If we have a read preference and inline is not set as output fail hard\n  if (\n    options.readPreference !== false &&\n    options.readPreference !== 'primary' &&\n    options['out'] &&\n    (options['out'].inline !== 1 && options['out'] !== 'inline')\n  ) {\n    // Force readPreference to primary\n    options.readPreference = 'primary';\n    // Decorate command with writeConcern if supported\n    decorateWithWriteConcern(mapCommandHash, self, options);\n  } else {\n    decorateWithReadConcern(mapCommandHash, self, options);\n  }\n\n  // Is bypassDocumentValidation specified\n  if (typeof options.bypassDocumentValidation === 'boolean') {\n    mapCommandHash.bypassDocumentValidation = options.bypassDocumentValidation;\n  }\n\n  // Have we specified collation\n  decorateWithCollation(mapCommandHash, self, options);\n\n  // Execute command\n  self.s.db.command(mapCommandHash, options, function(err, result) {\n    if (err) return handleCallback(callback, err);\n    // Check if we have an error\n    if (1 !== result.ok || result.err || result.errmsg) {\n      return handleCallback(callback, toError(result));\n    }\n\n    // Create statistics value\n    var stats = {};\n    if (result.timeMillis) stats['processtime'] = result.timeMillis;\n    if (result.counts) stats['counts'] = result.counts;\n    if (result.timing) stats['timing'] = result.timing;\n\n    // invoked with inline?\n    if (result.results) {\n      // If we wish for no verbosity\n      if (options['verbose'] == null || !options['verbose']) {\n        return handleCallback(callback, null, result.results);\n      }\n\n      return handleCallback(callback, null, { results: result.results, stats: stats });\n    }\n\n    // The returned collection\n    var collection = null;\n\n    // If we have an object it's a different db\n    if (result.result != null && typeof result.result === 'object') {\n      var doc = result.result;\n      // Return a collection from another db\n      var Db = __webpack_require__(/*! ./db */ \"./node_modules/mongoDb/lib/db.js\");\n      collection = new Db(doc.db, self.s.db.s.topology, self.s.db.s.options).collection(\n        doc.collection\n      );\n    } else {\n      // Create a collection object that wraps the result collection\n      collection = self.s.db.collection(result.result);\n    }\n\n    // If we wish for no verbosity\n    if (options['verbose'] == null || !options['verbose']) {\n      return handleCallback(callback, err, collection);\n    }\n\n    // Return stats as third set of values\n    handleCallback(callback, err, { collection: collection, stats: stats });\n  });\n};\n\ndefine.classMethod('mapReduce', { callback: true, promise: true });\n\n/**\n * Initiate a Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @return {UnorderedBulkOperation}\n */\nCollection.prototype.initializeUnorderedBulkOp = function(options) {\n  options = options || {};\n  options.promiseLibrary = this.s.promiseLibrary;\n  return unordered(this.s.topology, this, options);\n};\n\ndefine.classMethod('initializeUnorderedBulkOp', {\n  callback: false,\n  promise: false,\n  returns: [ordered.UnorderedBulkOperation]\n});\n\n/**\n * Initiate an In order bulk write operation, operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {OrderedBulkOperation} callback The command result callback\n * @return {null}\n */\nCollection.prototype.initializeOrderedBulkOp = function(options) {\n  options = options || {};\n  options.promiseLibrary = this.s.promiseLibrary;\n  return ordered(this.s.topology, this, options);\n};\n\ndefine.classMethod('initializeOrderedBulkOp', {\n  callback: false,\n  promise: false,\n  returns: [ordered.OrderedBulkOperation]\n});\n\n// Get write concern\nvar writeConcern = function(target, db, col, options) {\n  if (options.w != null || options.j != null || options.fsync != null) {\n    var opts = {};\n    if (options.w != null) opts.w = options.w;\n    if (options.wtimeout != null) opts.wtimeout = options.wtimeout;\n    if (options.j != null) opts.j = options.j;\n    if (options.fsync != null) opts.fsync = options.fsync;\n    target.writeConcern = opts;\n  } else if (\n    col.writeConcern.w != null ||\n    col.writeConcern.j != null ||\n    col.writeConcern.fsync != null\n  ) {\n    target.writeConcern = col.writeConcern;\n  } else if (\n    db.writeConcern.w != null ||\n    db.writeConcern.j != null ||\n    db.writeConcern.fsync != null\n  ) {\n    target.writeConcern = db.writeConcern;\n  }\n\n  // NOTE: there is probably a much better place for this\n  if (db.s.options.retryWrites) target.retryWrites = true;\n\n  return target;\n};\n\n// Figure out the read preference\nvar getReadPreference = function(self, options, db) {\n  let r = null;\n  if (options.readPreference) {\n    r = options.readPreference;\n  } else if (self.s.readPreference) {\n    r = self.s.readPreference;\n  } else if (db.s.readPreference) {\n    r = db.s.readPreference;\n  } else {\n    return options;\n  }\n\n  if (typeof r === 'string') {\n    options.readPreference = new ReadPreference(r);\n  } else if (r && !(r instanceof ReadPreference) && typeof r === 'object') {\n    const mode = r.mode || r.preference;\n    if (mode && typeof mode === 'string') {\n      options.readPreference = new ReadPreference(mode, r.tags, {\n        maxStalenessSeconds: r.maxStalenessSeconds\n      });\n    }\n  } else if (!(r instanceof ReadPreference)) {\n    throw new TypeError('Invalid read preference: ' + r);\n  }\n\n  return options;\n};\n\nmodule.exports = Collection;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/collection.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/command_cursor.js":
/*!****************************************************!*\
  !*** ./node_modules/mongoDb/lib/command_cursor.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits,\n  ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  Readable = __webpack_require__(/*! stream */ \"stream\").Readable,\n  Define = __webpack_require__(/*! ./metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  CoreCursor = __webpack_require__(/*! ./cursor */ \"./node_modules/mongoDb/lib/cursor.js\");\n\n/**\n * @fileOverview The **CommandCursor** class is an internal class that embodies a\n * generalized cursor based on a MongoDB command allowing for iteration over the\n * results returned. It supports one by one document iteration, conversion to an\n * array or can be iterated as a Node 0.10.X or higher stream\n *\n * **CommandCursor Cannot directly be instantiated**\n * @example\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   // Create a collection we want to drop later\n *   const col = client.db(dbName).collection('listCollectionsExample1');\n *   // Insert a bunch of documents\n *   col.insert([{a:1, b:1}\n *     , {a:2, b:2}, {a:3, b:3}\n *     , {a:4, b:4}], {w:1}, function(err, result) {\n *     test.equal(null, err);\n *     // List the database collections available\n *     db.listCollections().toArray(function(err, items) {\n *       test.equal(null, err);\n *       client.close();\n *     });\n *   });\n * });\n */\n\n/**\n * Namespace provided by the browser.\n * @external Readable\n */\n\n/**\n * Creates a new Command Cursor instance (INTERNAL TYPE, do not instantiate directly)\n * @class CommandCursor\n * @extends external:Readable\n * @fires CommandCursor#data\n * @fires CommandCursor#end\n * @fires CommandCursor#close\n * @fires CommandCursor#readable\n * @return {CommandCursor} an CommandCursor instance.\n */\nvar CommandCursor = function(bson, ns, cmd, options, topology, topologyOptions) {\n  CoreCursor.apply(this, Array.prototype.slice.call(arguments, 0));\n  var state = CommandCursor.INIT;\n  var streamOptions = {};\n\n  // MaxTimeMS\n  var maxTimeMS = null;\n\n  // Get the promiseLibrary\n  var promiseLibrary = options.promiseLibrary || Promise;\n\n  // Set up\n  Readable.call(this, { objectMode: true });\n\n  // Internal state\n  this.s = {\n    // MaxTimeMS\n    maxTimeMS: maxTimeMS,\n    // State\n    state: state,\n    // Stream options\n    streamOptions: streamOptions,\n    // BSON\n    bson: bson,\n    // Namespace\n    ns: ns,\n    // Command\n    cmd: cmd,\n    // Options\n    options: options,\n    // Topology\n    topology: topology,\n    // Topology Options\n    topologyOptions: topologyOptions,\n    // Promise library\n    promiseLibrary: promiseLibrary\n  };\n};\n\n/**\n * CommandCursor stream data event, fired for each document in the cursor.\n *\n * @event CommandCursor#data\n * @type {object}\n */\n\n/**\n * CommandCursor stream end event\n *\n * @event CommandCursor#end\n * @type {null}\n */\n\n/**\n * CommandCursor stream close event\n *\n * @event CommandCursor#close\n * @type {null}\n */\n\n/**\n * CommandCursor stream readable event\n *\n * @event CommandCursor#readable\n * @type {null}\n */\n\n// Inherit from Readable\ninherits(CommandCursor, Readable);\n\n// Set the methods to inherit from prototype\nvar methodsToInherit = [\n  '_next',\n  'next',\n  'hasNext',\n  'each',\n  'forEach',\n  'toArray',\n  'rewind',\n  'bufferedCount',\n  'readBufferedDocuments',\n  'close',\n  'isClosed',\n  'kill',\n  'setCursorBatchSize',\n  '_find',\n  '_getmore',\n  '_killcursor',\n  'isDead',\n  'explain',\n  'isNotified',\n  'isKilled'\n];\n\n// Only inherit the types we need\nfor (var i = 0; i < methodsToInherit.length; i++) {\n  CommandCursor.prototype[methodsToInherit[i]] = CoreCursor.prototype[methodsToInherit[i]];\n}\n\nvar define = (CommandCursor.define = new Define('CommandCursor', CommandCursor, true));\n\n/**\n * Set the ReadPreference for the cursor.\n * @method\n * @param {(string|ReadPreference)} readPreference The new read preference for the cursor.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCommandCursor.prototype.setReadPreference = function(readPreference) {\n  if (this.s.state === CommandCursor.CLOSED || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  if (this.s.state !== CommandCursor.INIT) {\n    throw MongoError.create({\n      message: 'cannot change cursor readPreference after cursor has been accessed',\n      driver: true\n    });\n  }\n\n  if (readPreference instanceof ReadPreference) {\n    this.s.options.readPreference = readPreference;\n  } else if (typeof readPreference === 'string') {\n    this.s.options.readPreference = new ReadPreference(readPreference);\n  } else {\n    throw new TypeError('Invalid read preference: ' + readPreference);\n  }\n\n  return this;\n};\n\ndefine.classMethod('setReadPreference', {\n  callback: false,\n  promise: false,\n  returns: [CommandCursor]\n});\n\n/**\n * Set the batch size for the cursor.\n * @method\n * @param {number} value The batchSize for the cursor.\n * @throws {MongoError}\n * @return {CommandCursor}\n */\nCommandCursor.prototype.batchSize = function(value) {\n  if (this.s.state === CommandCursor.CLOSED || this.isDead())\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  if (typeof value !== 'number')\n    throw MongoError.create({ message: 'batchSize requires an integer', driver: true });\n  if (this.s.cmd.cursor) this.s.cmd.cursor.batchSize = value;\n  this.setCursorBatchSize(value);\n  return this;\n};\n\ndefine.classMethod('batchSize', { callback: false, promise: false, returns: [CommandCursor] });\n\n/**\n * Add a maxTimeMS stage to the aggregation pipeline\n * @method\n * @param {number} value The state maxTimeMS value.\n * @return {CommandCursor}\n */\nCommandCursor.prototype.maxTimeMS = function(value) {\n  if (this.s.topology.lastIsMaster().minWireVersion > 2) {\n    this.s.cmd.maxTimeMS = value;\n  }\n  return this;\n};\n\ndefine.classMethod('maxTimeMS', { callback: false, promise: false, returns: [CommandCursor] });\n\nCommandCursor.prototype.get = CommandCursor.prototype.toArray;\n\ndefine.classMethod('get', { callback: true, promise: false });\n\n// Inherited methods\ndefine.classMethod('toArray', { callback: true, promise: true });\ndefine.classMethod('each', { callback: true, promise: false });\ndefine.classMethod('forEach', { callback: true, promise: false });\ndefine.classMethod('next', { callback: true, promise: true });\ndefine.classMethod('hasNext', { callback: true, promise: true });\ndefine.classMethod('close', { callback: true, promise: true });\ndefine.classMethod('isClosed', { callback: false, promise: false, returns: [Boolean] });\ndefine.classMethod('rewind', { callback: false, promise: false });\ndefine.classMethod('bufferedCount', { callback: false, promise: false, returns: [Number] });\ndefine.classMethod('readBufferedDocuments', { callback: false, promise: false, returns: [Array] });\n\n/**\n * Get the next available document from the cursor, returns null if no more documents are available.\n * @function CommandCursor.prototype.next\n * @param {CommandCursor~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * Check if there is any document still available in the cursor\n * @function CommandCursor.prototype.hasNext\n * @param {CommandCursor~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * The callback format for results\n * @callback CommandCursor~toArrayResultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {object[]} documents All the documents the satisfy the cursor.\n */\n\n/**\n * Returns an array of documents. The caller is responsible for making sure that there\n * is enough memory to store the results. Note that the array only contain partial\n * results when this cursor had been previouly accessed.\n * @method CommandCursor.prototype.toArray\n * @param {CommandCursor~toArrayResultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * The callback format for results\n * @callback CommandCursor~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {(object|null)} result The result object if the command was executed successfully.\n */\n\n/**\n * Iterates over all the documents for this cursor. As with **{cursor.toArray}**,\n * not all of the elements will be iterated if this cursor had been previouly accessed.\n * In that case, **{cursor.rewind}** can be used to reset the cursor. However, unlike\n * **{cursor.toArray}**, the cursor will only hold a maximum of batch size elements\n * at any given time if batch size is specified. Otherwise, the caller is responsible\n * for making sure that the entire result can fit the memory.\n * @method CommandCursor.prototype.each\n * @param {CommandCursor~resultCallback} callback The result callback.\n * @throws {MongoError}\n * @return {null}\n */\n\n/**\n * Close the cursor, sending a KillCursor command and emitting close.\n * @method CommandCursor.prototype.close\n * @param {CommandCursor~resultCallback} [callback] The result callback.\n * @return {Promise} returns Promise if no callback passed\n */\n\n/**\n * Is the cursor closed\n * @method CommandCursor.prototype.isClosed\n * @return {boolean}\n */\n\n/**\n * Clone the cursor\n * @function CommandCursor.prototype.clone\n * @return {CommandCursor}\n */\n\n/**\n * Resets the cursor\n * @function CommandCursor.prototype.rewind\n * @return {CommandCursor}\n */\n\n/**\n * The callback format for the forEach iterator method\n * @callback CommandCursor~iteratorCallback\n * @param {Object} doc An emitted document for the iterator\n */\n\n/**\n * The callback error format for the forEach iterator method\n * @callback CommandCursor~endCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n */\n\n/*\n * Iterates over all the documents for this cursor using the iterator, callback pattern.\n * @method CommandCursor.prototype.forEach\n * @param {CommandCursor~iteratorCallback} iterator The iteration callback.\n * @param {CommandCursor~endCallback} callback The end callback.\n * @throws {MongoError}\n * @return {null}\n */\n\nCommandCursor.INIT = 0;\nCommandCursor.OPEN = 1;\nCommandCursor.CLOSED = 2;\n\nmodule.exports = CommandCursor;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/command_cursor.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/cursor.js":
/*!********************************************!*\
  !*** ./node_modules/mongoDb/lib/cursor.js ***!
  \********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar inherits = __webpack_require__(/*! util */ \"util\").inherits,\n  f = __webpack_require__(/*! util */ \"util\").format,\n  formattedOrderClause = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").formattedOrderClause,\n  handleCallback = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").handleCallback,\n  ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  Readable = __webpack_require__(/*! stream */ \"stream\").Readable,\n  Define = __webpack_require__(/*! ./metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  CoreCursor = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Cursor,\n  Map = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.Map,\n  executeOperation = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation;\n\n/**\n * @fileOverview The **Cursor** class is an internal class that embodies a cursor on MongoDB\n * allowing for iteration over the results returned from the underlying query. It supports\n * one by one document iteration, conversion to an array or can be iterated as a Node 4.X\n * or higher stream\n *\n * **CURSORS Cannot directly be instantiated**\n * @example\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   // Create a collection we want to drop later\n *   const col = client.db(dbName).collection('createIndexExample1');\n *   // Insert a bunch of documents\n *   col.insert([{a:1, b:1}\n *     , {a:2, b:2}, {a:3, b:3}\n *     , {a:4, b:4}], {w:1}, function(err, result) {\n *     test.equal(null, err);\n *     // Show that duplicate records got dropped\n *     col.find({}).toArray(function(err, items) {\n *       test.equal(null, err);\n *       test.equal(4, items.length);\n *       client.close();\n *     });\n *   });\n * });\n */\n\n/**\n * Namespace provided by the mongodb-core and node.js\n * @external CoreCursor\n * @external Readable\n */\n\n// Flags allowed for cursor\nvar flags = ['tailable', 'oplogReplay', 'noCursorTimeout', 'awaitData', 'exhaust', 'partial'];\nvar fields = ['numberOfRetries', 'tailableRetryInterval'];\nvar push = Array.prototype.push;\n\n/**\n * Creates a new Cursor instance (INTERNAL TYPE, do not instantiate directly)\n * @class Cursor\n * @extends external:CoreCursor\n * @extends external:Readable\n * @property {string} sortValue Cursor query sort setting.\n * @property {boolean} timeout Is Cursor able to time out.\n * @property {ReadPreference} readPreference Get cursor ReadPreference.\n * @fires Cursor#data\n * @fires Cursor#end\n * @fires Cursor#close\n * @fires Cursor#readable\n * @return {Cursor} a Cursor instance.\n * @example\n * Cursor cursor options.\n *\n * collection.find({}).project({a:1})                             // Create a projection of field a\n * collection.find({}).skip(1).limit(10)                          // Skip 1 and limit 10\n * collection.find({}).batchSize(5)                               // Set batchSize on cursor to 5\n * collection.find({}).filter({a:1})                              // Set query on the cursor\n * collection.find({}).comment('add a comment')                   // Add a comment to the query, allowing to correlate queries\n * collection.find({}).addCursorFlag('tailable', true)            // Set cursor as tailable\n * collection.find({}).addCursorFlag('oplogReplay', true)         // Set cursor as oplogReplay\n * collection.find({}).addCursorFlag('noCursorTimeout', true)     // Set cursor as noCursorTimeout\n * collection.find({}).addCursorFlag('awaitData', true)           // Set cursor as awaitData\n * collection.find({}).addCursorFlag('partial', true)             // Set cursor as partial\n * collection.find({}).addQueryModifier('$orderby', {a:1})        // Set $orderby {a:1}\n * collection.find({}).max(10)                                    // Set the cursor maxScan\n * collection.find({}).maxScan(10)                                // Set the cursor maxScan\n * collection.find({}).maxTimeMS(1000)                            // Set the cursor maxTimeMS\n * collection.find({}).min(100)                                   // Set the cursor min\n * collection.find({}).returnKey(10)                              // Set the cursor returnKey\n * collection.find({}).setReadPreference(ReadPreference.PRIMARY)  // Set the cursor readPreference\n * collection.find({}).showRecordId(true)                         // Set the cursor showRecordId\n * collection.find({}).snapshot(true)                             // Set the cursor snapshot\n * collection.find({}).sort([['a', 1]])                           // Sets the sort order of the cursor query\n * collection.find({}).hint('a_1')                                // Set the cursor hint\n *\n * All options are chainable, so one can do the following.\n *\n * collection.find({}).maxTimeMS(1000).maxScan(100).skip(1).toArray(..)\n */\nvar Cursor = function(bson, ns, cmd, options, topology, topologyOptions) {\n  CoreCursor.apply(this, Array.prototype.slice.call(arguments, 0));\n  var state = Cursor.INIT;\n  var streamOptions = {};\n\n  // Tailable cursor options\n  var numberOfRetries = options.numberOfRetries || 5;\n  var tailableRetryInterval = options.tailableRetryInterval || 500;\n  var currentNumberOfRetries = numberOfRetries;\n\n  // Get the promiseLibrary\n  var promiseLibrary = options.promiseLibrary || Promise;\n\n  // Set up\n  Readable.call(this, { objectMode: true });\n\n  // Internal cursor state\n  this.s = {\n    // Tailable cursor options\n    numberOfRetries: numberOfRetries,\n    tailableRetryInterval: tailableRetryInterval,\n    currentNumberOfRetries: currentNumberOfRetries,\n    // State\n    state: state,\n    // Stream options\n    streamOptions: streamOptions,\n    // BSON\n    bson: bson,\n    // Namespace\n    ns: ns,\n    // Command\n    cmd: cmd,\n    // Options\n    options: options,\n    // Topology\n    topology: topology,\n    // Topology options\n    topologyOptions: topologyOptions,\n    // Promise library\n    promiseLibrary: promiseLibrary,\n    // Current doc\n    currentDoc: null,\n    // Optional ClientSession\n    session: options.session\n  };\n\n  // Translate correctly\n  if (this.s.options.noCursorTimeout === true) {\n    this.addCursorFlag('noCursorTimeout', true);\n  }\n\n  // Set the sort value\n  this.sortValue = this.s.cmd.sort;\n\n  // Get the batchSize\n  var batchSize =\n    cmd.cursor && cmd.cursor.batchSize\n      ? cmd.cursor && cmd.cursor.batchSize\n      : options.cursor && options.cursor.batchSize ? options.cursor.batchSize : 1000;\n\n  // Set the batchSize\n  this.setCursorBatchSize(batchSize);\n};\n\n/**\n * Cursor stream data event, fired for each document in the cursor.\n *\n * @event Cursor#data\n * @type {object}\n */\n\n/**\n * Cursor stream end event\n *\n * @event Cursor#end\n * @type {null}\n */\n\n/**\n * Cursor stream close event\n *\n * @event Cursor#close\n * @type {null}\n */\n\n/**\n * Cursor stream readable event\n *\n * @event Cursor#readable\n * @type {null}\n */\n\n// Inherit from Readable\ninherits(Cursor, Readable);\n\n// Map core cursor _next method so we can apply mapping\nCoreCursor.prototype._next = CoreCursor.prototype.next;\n\nfor (var name in CoreCursor.prototype) {\n  Cursor.prototype[name] = CoreCursor.prototype[name];\n}\n\nvar define = (Cursor.define = new Define('Cursor', Cursor, true));\n\n/**\n * Check if there is any document still available in the cursor\n * @method\n * @param {Cursor~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nCursor.prototype.hasNext = function(callback) {\n  return executeOperation(this.s.topology, hasNext, [this, callback], {\n    skipSessions: true\n  });\n};\n\nconst hasNext = (self, callback) => {\n  if (self.s.currentDoc) {\n    return callback(null, true);\n  }\n\n  nextObject(self, function(err, doc) {\n    if (err) return callback(err, null);\n    if (self.s.state === Cursor.CLOSED || self.isDead()) return callback(null, false);\n    if (!doc) return callback(null, false);\n    self.s.currentDoc = doc;\n    callback(null, true);\n  });\n};\n\ndefine.classMethod('hasNext', { callback: true, promise: true });\n\n/**\n * Get the next available document from the cursor, returns null if no more documents are available.\n * @method\n * @param {Cursor~resultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nCursor.prototype.next = function(callback) {\n  return executeOperation(this.s.topology, next, [this, callback], {\n    skipSessions: true\n  });\n};\n\nconst next = (self, callback) => {\n  // Return the currentDoc if someone called hasNext first\n  if (self.s.currentDoc) {\n    var doc = self.s.currentDoc;\n    self.s.currentDoc = null;\n    return callback(null, doc);\n  }\n\n  // Return the next object\n  nextObject(self, callback);\n};\n\ndefine.classMethod('next', { callback: true, promise: true });\n\n/**\n * Set the cursor query\n * @method\n * @param {object} filter The filter object used for the cursor.\n * @return {Cursor}\n */\nCursor.prototype.filter = function(filter) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.query = filter;\n  return this;\n};\n\ndefine.classMethod('filter', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the cursor maxScan\n * @method\n * @param {object} maxScan Constrains the query to only scan the specified number of documents when fulfilling the query\n * @return {Cursor}\n */\nCursor.prototype.maxScan = function(maxScan) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.maxScan = maxScan;\n  return this;\n};\n\ndefine.classMethod('maxScan', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the cursor hint\n * @method\n * @param {object} hint If specified, then the query system will only consider plans using the hinted index.\n * @return {Cursor}\n */\nCursor.prototype.hint = function(hint) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.hint = hint;\n  return this;\n};\n\ndefine.classMethod('hint', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the cursor min\n * @method\n * @param {object} min Specify a $min value to specify the inclusive lower bound for a specific index in order to constrain the results of find(). The $min specifies the lower bound for all keys of a specific index in order.\n * @return {Cursor}\n */\nCursor.prototype.min = function(min) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead())\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  this.s.cmd.min = min;\n  return this;\n};\n\ndefine.classMethod('min', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the cursor max\n * @method\n * @param {object} max Specify a $max value to specify the exclusive upper bound for a specific index in order to constrain the results of find(). The $max specifies the upper bound for all keys of a specific index in order.\n * @return {Cursor}\n */\nCursor.prototype.max = function(max) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.max = max;\n  return this;\n};\n\ndefine.classMethod('max', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the cursor returnKey\n * @method\n * @param {object} returnKey Only return the index field or fields for the results of the query. If $returnKey is set to true and the query does not use an index to perform the read operation, the returned documents will not contain any fields. Use one of the following forms:\n * @return {Cursor}\n */\nCursor.prototype.returnKey = function(value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.returnKey = value;\n  return this;\n};\n\ndefine.classMethod('returnKey', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the cursor showRecordId\n * @method\n * @param {object} showRecordId The $showDiskLoc option has now been deprecated and replaced with the showRecordId field. $showDiskLoc will still be accepted for OP_QUERY stye find.\n * @return {Cursor}\n */\nCursor.prototype.showRecordId = function(value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.showDiskLoc = value;\n  return this;\n};\n\ndefine.classMethod('showRecordId', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the cursor snapshot\n * @method\n * @param {object} snapshot The $snapshot operator prevents the cursor from returning a document more than once because an intervening write operation results in a move of the document.\n * @return {Cursor}\n */\nCursor.prototype.snapshot = function(value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.snapshot = value;\n  return this;\n};\n\ndefine.classMethod('snapshot', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set a node.js specific cursor option\n * @method\n * @param {string} field The cursor option to set ['numberOfRetries', 'tailableRetryInterval'].\n * @param {object} value The field value.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.setCursorOption = function(field, value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  if (fields.indexOf(field) === -1) {\n    throw MongoError.create({\n      message: f('option %s not a supported option %s', field, fields),\n      driver: true\n    });\n  }\n\n  this.s[field] = value;\n  if (field === 'numberOfRetries') this.s.currentNumberOfRetries = value;\n  return this;\n};\n\ndefine.classMethod('setCursorOption', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Add a cursor flag to the cursor\n * @method\n * @param {string} flag The flag to set, must be one of following ['tailable', 'oplogReplay', 'noCursorTimeout', 'awaitData', 'partial'].\n * @param {boolean} value The flag boolean value.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.addCursorFlag = function(flag, value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  if (flags.indexOf(flag) === -1) {\n    throw MongoError.create({\n      message: f('flag %s not a supported flag %s', flag, flags),\n      driver: true\n    });\n  }\n\n  if (typeof value !== 'boolean') {\n    throw MongoError.create({ message: f('flag %s must be a boolean value', flag), driver: true });\n  }\n\n  this.s.cmd[flag] = value;\n  return this;\n};\n\ndefine.classMethod('addCursorFlag', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Add a query modifier to the cursor query\n * @method\n * @param {string} name The query modifier (must start with $, such as $orderby etc)\n * @param {boolean} value The flag boolean value.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.addQueryModifier = function(name, value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  if (name[0] !== '$') {\n    throw MongoError.create({ message: f('%s is not a valid query modifier'), driver: true });\n  }\n\n  // Strip of the $\n  var field = name.substr(1);\n  // Set on the command\n  this.s.cmd[field] = value;\n  // Deal with the special case for sort\n  if (field === 'orderby') this.s.cmd.sort = this.s.cmd[field];\n  return this;\n};\n\ndefine.classMethod('addQueryModifier', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Add a comment to the cursor query allowing for tracking the comment in the log.\n * @method\n * @param {string} value The comment attached to this query.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.comment = function(value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.comment = value;\n  return this;\n};\n\ndefine.classMethod('comment', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set a maxAwaitTimeMS on a tailing cursor query to allow to customize the timeout value for the option awaitData (Only supported on MongoDB 3.2 or higher, ignored otherwise)\n * @method\n * @param {number} value Number of milliseconds to wait before aborting the tailed query.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.maxAwaitTimeMS = function(value) {\n  if (typeof value !== 'number') {\n    throw MongoError.create({ message: 'maxAwaitTimeMS must be a number', driver: true });\n  }\n\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.maxAwaitTimeMS = value;\n  return this;\n};\n\ndefine.classMethod('maxAwaitTimeMS', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n * @method\n * @param {number} value Number of milliseconds to wait before aborting the query.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.maxTimeMS = function(value) {\n  if (typeof value !== 'number') {\n    throw MongoError.create({ message: 'maxTimeMS must be a number', driver: true });\n  }\n\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.maxTimeMS = value;\n  return this;\n};\n\ndefine.classMethod('maxTimeMS', { callback: false, promise: false, returns: [Cursor] });\n\nCursor.prototype.maxTimeMs = Cursor.prototype.maxTimeMS;\n\ndefine.classMethod('maxTimeMs', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Sets a field projection for the query.\n * @method\n * @param {object} value The field projection object.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.project = function(value) {\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  this.s.cmd.fields = value;\n  return this;\n};\n\ndefine.classMethod('project', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Sets the sort order of the cursor query.\n * @method\n * @param {(string|array|object)} keyOrList The key or keys set for the sort.\n * @param {number} [direction] The direction of the sorting (1 or -1).\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.sort = function(keyOrList, direction) {\n  if (this.s.options.tailable) {\n    throw MongoError.create({ message: \"Tailable cursor doesn't support sorting\", driver: true });\n  }\n\n  if (this.s.state === Cursor.CLOSED || this.s.state === Cursor.OPEN || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  var order = keyOrList;\n\n  // We have an array of arrays, we need to preserve the order of the sort\n  // so we will us a Map\n  if (Array.isArray(order) && Array.isArray(order[0])) {\n    order = new Map(\n      order.map(function(x) {\n        var value = [x[0], null];\n        if (x[1] === 'asc') {\n          value[1] = 1;\n        } else if (x[1] === 'desc') {\n          value[1] = -1;\n        } else if (x[1] === 1 || x[1] === -1) {\n          value[1] = x[1];\n        } else {\n          throw new MongoError(\n            \"Illegal sort clause, must be of the form [['field1', '(ascending|descending)'], ['field2', '(ascending|descending)']]\"\n          );\n        }\n\n        return value;\n      })\n    );\n  }\n\n  if (direction != null) {\n    order = [[keyOrList, direction]];\n  }\n\n  this.s.cmd.sort = order;\n  this.sortValue = order;\n  return this;\n};\n\ndefine.classMethod('sort', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the batch size for the cursor.\n * @method\n * @param {number} value The batchSize for the cursor.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.batchSize = function(value) {\n  if (this.s.options.tailable) {\n    throw MongoError.create({ message: \"Tailable cursor doesn't support batchSize\", driver: true });\n  }\n\n  if (this.s.state === Cursor.CLOSED || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  if (typeof value !== 'number') {\n    throw MongoError.create({ message: 'batchSize requires an integer', driver: true });\n  }\n\n  this.s.cmd.batchSize = value;\n  this.setCursorBatchSize(value);\n  return this;\n};\n\ndefine.classMethod('batchSize', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the collation options for the cursor.\n * @method\n * @param {object} value The cursor collation options (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.collation = function(value) {\n  this.s.cmd.collation = value;\n  return this;\n};\n\ndefine.classMethod('collation', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the limit for the cursor.\n * @method\n * @param {number} value The limit for the cursor query.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.limit = function(value) {\n  if (this.s.options.tailable) {\n    throw MongoError.create({ message: \"Tailable cursor doesn't support limit\", driver: true });\n  }\n\n  if (this.s.state === Cursor.OPEN || this.s.state === Cursor.CLOSED || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  if (typeof value !== 'number') {\n    throw MongoError.create({ message: 'limit requires an integer', driver: true });\n  }\n\n  this.s.cmd.limit = value;\n  // this.cursorLimit = value;\n  this.setCursorLimit(value);\n  return this;\n};\n\ndefine.classMethod('limit', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Set the skip for the cursor.\n * @method\n * @param {number} value The skip for the cursor query.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.skip = function(value) {\n  if (this.s.options.tailable) {\n    throw MongoError.create({ message: \"Tailable cursor doesn't support skip\", driver: true });\n  }\n\n  if (this.s.state === Cursor.OPEN || this.s.state === Cursor.CLOSED || this.isDead()) {\n    throw MongoError.create({ message: 'Cursor is closed', driver: true });\n  }\n\n  if (typeof value !== 'number') {\n    throw MongoError.create({ message: 'skip requires an integer', driver: true });\n  }\n\n  this.s.cmd.skip = value;\n  this.setCursorSkip(value);\n  return this;\n};\n\ndefine.classMethod('skip', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * The callback format for results\n * @callback Cursor~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {(object|null|boolean)} result The result object if the command was executed successfully.\n */\n\n/**\n * Clone the cursor\n * @function external:CoreCursor#clone\n * @return {Cursor}\n */\n\n/**\n * Resets the cursor\n * @function external:CoreCursor#rewind\n * @return {null}\n */\n\n// Get the next available document from the cursor, returns null if no more documents are available.\nvar nextObject = function(self, callback) {\n  if (self.s.state === Cursor.CLOSED || (self.isDead && self.isDead()))\n    return handleCallback(\n      callback,\n      MongoError.create({ message: 'Cursor is closed', driver: true })\n    );\n  if (self.s.state === Cursor.INIT && self.s.cmd.sort) {\n    try {\n      self.s.cmd.sort = formattedOrderClause(self.s.cmd.sort);\n    } catch (err) {\n      return handleCallback(callback, err);\n    }\n  }\n\n  // Get the next object\n  self._next(function(err, doc) {\n    self.s.state = Cursor.OPEN;\n    if (err) return handleCallback(callback, err);\n    handleCallback(callback, null, doc);\n  });\n};\n\n// Trampoline emptying the number of retrieved items\n// without incurring a nextTick operation\nvar loop = function(self, callback) {\n  // No more items we are done\n  if (self.bufferedCount() === 0) return;\n  // Get the next document\n  self._next(callback);\n  // Loop\n  return loop;\n};\n\n/**\n * Iterates over all the documents for this cursor. As with **{cursor.toArray}**,\n * not all of the elements will be iterated if this cursor had been previouly accessed.\n * In that case, **{cursor.rewind}** can be used to reset the cursor. However, unlike\n * **{cursor.toArray}**, the cursor will only hold a maximum of batch size elements\n * at any given time if batch size is specified. Otherwise, the caller is responsible\n * for making sure that the entire result can fit the memory.\n * @method\n * @deprecated\n * @param {Cursor~resultCallback} callback The result callback.\n * @throws {MongoError}\n * @return {null}\n */\nCursor.prototype.each = function(callback) {\n  // Rewind cursor state\n  this.rewind();\n  // Set current cursor to INIT\n  this.s.state = Cursor.INIT;\n  // Run the query\n  _each(this, callback);\n};\n\ndefine.classMethod('each', { callback: true, promise: false });\n\n// Run the each loop\nvar _each = function(self, callback) {\n  if (!callback) throw MongoError.create({ message: 'callback is mandatory', driver: true });\n  if (self.isNotified()) return;\n  if (self.s.state === Cursor.CLOSED || self.isDead()) {\n    return handleCallback(\n      callback,\n      MongoError.create({ message: 'Cursor is closed', driver: true })\n    );\n  }\n\n  if (self.s.state === Cursor.INIT) self.s.state = Cursor.OPEN;\n\n  // Define function to avoid global scope escape\n  var fn = null;\n  // Trampoline all the entries\n  if (self.bufferedCount() > 0) {\n    while ((fn = loop(self, callback))) fn(self, callback);\n    _each(self, callback);\n  } else {\n    self.next(function(err, item) {\n      if (err) return handleCallback(callback, err);\n      if (item == null) {\n        return self.close({ skipKillCursors: true }, () => handleCallback(callback, null, null));\n      }\n\n      if (handleCallback(callback, null, item) === false) return;\n      _each(self, callback);\n    });\n  }\n};\n\n/**\n * The callback format for the forEach iterator method\n * @callback Cursor~iteratorCallback\n * @param {Object} doc An emitted document for the iterator\n */\n\n/**\n * The callback error format for the forEach iterator method\n * @callback Cursor~endCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n */\n\n/**\n * Iterates over all the documents for this cursor using the iterator, callback pattern.\n * @method\n * @param {Cursor~iteratorCallback} iterator The iteration callback.\n * @param {Cursor~endCallback} callback The end callback.\n * @throws {MongoError}\n * @return {null}\n */\nCursor.prototype.forEach = function(iterator, callback) {\n  this.each(function(err, doc) {\n    if (err) {\n      callback(err);\n      return false;\n    }\n    if (doc != null) {\n      iterator(doc);\n      return true;\n    }\n    if (doc == null && callback) {\n      var internalCallback = callback;\n      callback = null;\n      internalCallback(null);\n      return false;\n    }\n  });\n};\n\ndefine.classMethod('forEach', { callback: true, promise: false });\n\n/**\n * Set the ReadPreference for the cursor.\n * @method\n * @param {(string|ReadPreference)} readPreference The new read preference for the cursor.\n * @throws {MongoError}\n * @return {Cursor}\n */\nCursor.prototype.setReadPreference = function(readPreference) {\n  if (this.s.state !== Cursor.INIT) {\n    throw MongoError.create({\n      message: 'cannot change cursor readPreference after cursor has been accessed',\n      driver: true\n    });\n  }\n\n  if (readPreference instanceof ReadPreference) {\n    this.s.options.readPreference = readPreference;\n  } else if (typeof readPreference === 'string') {\n    this.s.options.readPreference = new ReadPreference(readPreference);\n  } else {\n    throw new TypeError('Invalid read preference: ' + readPreference);\n  }\n\n  return this;\n};\n\ndefine.classMethod('setReadPreference', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * The callback format for results\n * @callback Cursor~toArrayResultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {object[]} documents All the documents the satisfy the cursor.\n */\n\n/**\n * Returns an array of documents. The caller is responsible for making sure that there\n * is enough memory to store the results. Note that the array only contain partial\n * results when this cursor had been previouly accessed. In that case,\n * cursor.rewind() can be used to reset the cursor.\n * @method\n * @param {Cursor~toArrayResultCallback} [callback] The result callback.\n * @throws {MongoError}\n * @return {Promise} returns Promise if no callback passed\n */\nCursor.prototype.toArray = function(callback) {\n  var self = this;\n  if (self.s.options.tailable) {\n    throw MongoError.create({\n      message: 'Tailable cursor cannot be converted to array',\n      driver: true\n    });\n  }\n\n  return executeOperation(this.s.topology, toArray, [this, callback], {\n    skipSessions: true\n  });\n};\n\nvar toArray = function(self, callback) {\n  var items = [];\n\n  // Reset cursor\n  self.rewind();\n  self.s.state = Cursor.INIT;\n\n  // Fetch all the documents\n  var fetchDocs = function() {\n    self._next(function(err, doc) {\n      if (err) return handleCallback(callback, err);\n      if (doc == null) {\n        return self.close({ skipKillCursors: true }, () => handleCallback(callback, null, items));\n      }\n\n      // Add doc to items\n      items.push(doc);\n\n      // Get all buffered objects\n      if (self.bufferedCount() > 0) {\n        var docs = self.readBufferedDocuments(self.bufferedCount());\n\n        // Transform the doc if transform method added\n        if (self.s.transforms && typeof self.s.transforms.doc === 'function') {\n          docs = docs.map(self.s.transforms.doc);\n        }\n\n        push.apply(items, docs);\n      }\n\n      // Attempt a fetch\n      fetchDocs();\n    });\n  };\n\n  fetchDocs();\n};\n\ndefine.classMethod('toArray', { callback: true, promise: true });\n\n/**\n * The callback format for results\n * @callback Cursor~countResultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {number} count The count of documents.\n */\n\n/**\n * Get the count of documents for this cursor\n * @method\n * @param {boolean} [applySkipLimit=true] Should the count command apply limit and skip settings on the cursor or in the passed in options.\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.skip=null] The number of documents to skip.\n * @param {number} [options.limit=null] The maximum amounts to count before aborting.\n * @param {number} [options.maxTimeMS=null] Number of miliseconds to wait before aborting the query.\n * @param {string} [options.hint=null] An index name hint for the query.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {Cursor~countResultCallback} [callback] The result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nCursor.prototype.count = function(applySkipLimit, opts, callback) {\n  if (this.s.cmd.query == null)\n    throw MongoError.create({ message: 'count can only be used with find command', driver: true });\n  if (typeof opts === 'function') (callback = opts), (opts = {});\n  opts = opts || {};\n\n  return executeOperation(this.s.topology, count, [this, applySkipLimit, opts, callback], {\n    skipSessions: true\n  });\n};\n\nvar count = function(self, applySkipLimit, opts, callback) {\n  if (typeof applySkipLimit === 'function') {\n    callback = applySkipLimit;\n    applySkipLimit = true;\n  }\n\n  if (applySkipLimit) {\n    if (typeof self.cursorSkip() === 'number') opts.skip = self.cursorSkip();\n    if (typeof self.cursorLimit() === 'number') opts.limit = self.cursorLimit();\n  }\n\n  // Command\n  var delimiter = self.s.ns.indexOf('.');\n\n  var command = {\n    count: self.s.ns.substr(delimiter + 1),\n    query: self.s.cmd.query\n  };\n\n  // Apply a readConcern if set\n  if (self.s.cmd.readConcern) {\n    command.readConcern = self.s.cmd.readConcern;\n  }\n\n  // Apply a hint if set\n  if (self.s.cmd.hint) {\n    command.hint = self.s.cmd.hint;\n  }\n\n  if (typeof opts.maxTimeMS === 'number') {\n    command.maxTimeMS = opts.maxTimeMS;\n  } else if (self.s.cmd && typeof self.s.cmd.maxTimeMS === 'number') {\n    command.maxTimeMS = self.s.cmd.maxTimeMS;\n  }\n\n  // Merge in any options\n  if (opts.skip) command.skip = opts.skip;\n  if (opts.limit) command.limit = opts.limit;\n  if (self.s.options.hint) command.hint = self.s.options.hint;\n\n  // Set cursor server to the same as the topology\n  self.server = self.topology.s.coreTopology;\n\n  // Execute the command\n  self.s.topology.command(\n    f('%s.$cmd', self.s.ns.substr(0, delimiter)),\n    command,\n    function(err, result) {\n      callback(err, result ? result.result.n : null);\n    },\n    self.options\n  );\n};\n\ndefine.classMethod('count', { callback: true, promise: true });\n\n/**\n * Close the cursor, sending a KillCursor command and emitting close.\n * @method\n * @param {object} [options] Optional settings.\n * @param {boolean} [options.skipKillCursors] Bypass calling killCursors when closing the cursor.\n * @param {Cursor~resultCallback} [callback] The result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nCursor.prototype.close = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = Object.assign({}, { skipKillCursors: false }, options);\n\n  this.s.state = Cursor.CLOSED;\n  if (!options.skipKillCursors) {\n    // Kill the cursor\n    this.kill();\n  }\n\n  const completeClose = () => {\n    // Emit the close event for the cursor\n    this.emit('close');\n\n    // Callback if provided\n    if (typeof callback === 'function') {\n      return handleCallback(callback, null, this);\n    }\n\n    // Return a Promise\n    return new this.s.promiseLibrary(function(resolve) {\n      resolve();\n    });\n  };\n\n  if (this.s.session) {\n    return this.s.session.endSession(() => completeClose());\n  }\n\n  return completeClose();\n};\n\ndefine.classMethod('close', { callback: true, promise: true });\n\n/**\n * Map all documents using the provided function\n * @method\n * @param {function} [transform] The mapping transformation method.\n * @return {Cursor}\n */\nCursor.prototype.map = function(transform) {\n  if (this.cursorState.transforms && this.cursorState.transforms.doc) {\n    var oldTransform = this.cursorState.transforms.doc;\n    this.cursorState.transforms.doc = function(doc) {\n      return transform(oldTransform(doc));\n    };\n  } else {\n    this.cursorState.transforms = { doc: transform };\n  }\n  return this;\n};\n\ndefine.classMethod('map', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Is the cursor closed\n * @method\n * @return {boolean}\n */\nCursor.prototype.isClosed = function() {\n  return this.isDead();\n};\n\ndefine.classMethod('isClosed', { callback: false, promise: false, returns: [Boolean] });\n\nCursor.prototype.destroy = function(err) {\n  if (err) this.emit('error', err);\n  this.pause();\n  this.close();\n};\n\ndefine.classMethod('destroy', { callback: false, promise: false });\n\n/**\n * Return a modified Readable stream including a possible transform method.\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {function} [options.transform=null] A transformation method applied to each document emitted by the stream.\n * @return {Cursor}\n */\nCursor.prototype.stream = function(options) {\n  this.s.streamOptions = options || {};\n  return this;\n};\n\ndefine.classMethod('stream', { callback: false, promise: false, returns: [Cursor] });\n\n/**\n * Execute the explain for the cursor\n * @method\n * @param {Cursor~resultCallback} [callback] The result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nCursor.prototype.explain = function(callback) {\n  this.s.cmd.explain = true;\n\n  // Do we have a readConcern\n  if (this.s.cmd.readConcern) {\n    delete this.s.cmd['readConcern'];\n  }\n\n  return executeOperation(this.s.topology, this._next.bind(this), [callback], {\n    skipSessions: true\n  });\n};\n\ndefine.classMethod('explain', { callback: true, promise: true });\n\nCursor.prototype._read = function() {\n  var self = this;\n  if (self.s.state === Cursor.CLOSED || self.isDead()) {\n    return self.push(null);\n  }\n\n  // Get the next item\n  self.next(function(err, result) {\n    if (err) {\n      if (self.listeners('error') && self.listeners('error').length > 0) {\n        self.emit('error', err);\n      }\n      if (!self.isDead()) self.close();\n\n      // Emit end event\n      self.emit('end');\n      return self.emit('finish');\n    }\n\n    // If we provided a transformation method\n    if (typeof self.s.streamOptions.transform === 'function' && result != null) {\n      return self.push(self.s.streamOptions.transform(result));\n    }\n\n    // If we provided a map function\n    if (\n      self.cursorState.transforms &&\n      typeof self.cursorState.transforms.doc === 'function' &&\n      result != null\n    ) {\n      return self.push(self.cursorState.transforms.doc(result));\n    }\n\n    // Return the result\n    self.push(result);\n\n    if (result === null && self.isDead()) {\n      self.once('end', () => {\n        self.close();\n        self.emit('finish');\n      });\n    }\n  });\n};\n\nObject.defineProperty(Cursor.prototype, 'readPreference', {\n  enumerable: true,\n  get: function() {\n    if (!this || !this.s) {\n      return null;\n    }\n\n    return this.s.options.readPreference;\n  }\n});\n\nObject.defineProperty(Cursor.prototype, 'namespace', {\n  enumerable: true,\n  get: function() {\n    if (!this || !this.s) {\n      return null;\n    }\n\n    // TODO: refactor this logic into core\n    var ns = this.s.ns || '';\n    var firstDot = ns.indexOf('.');\n    if (firstDot < 0) {\n      return {\n        database: this.s.ns,\n        collection: ''\n      };\n    }\n    return {\n      database: ns.substr(0, firstDot),\n      collection: ns.substr(firstDot + 1)\n    };\n  }\n});\n\n/**\n * The read() method pulls some data out of the internal buffer and returns it. If there is no data available, then it will return null.\n * @function external:Readable#read\n * @param {number} size Optional argument to specify how much data to read.\n * @return {(String | Buffer | null)}\n */\n\n/**\n * Call this function to cause the stream to return strings of the specified encoding instead of Buffer objects.\n * @function external:Readable#setEncoding\n * @param {string} encoding The encoding to use.\n * @return {null}\n */\n\n/**\n * This method will cause the readable stream to resume emitting data events.\n * @function external:Readable#resume\n * @return {null}\n */\n\n/**\n * This method will cause a stream in flowing-mode to stop emitting data events. Any data that becomes available will remain in the internal buffer.\n * @function external:Readable#pause\n * @return {null}\n */\n\n/**\n * This method pulls all the data out of a readable stream, and writes it to the supplied destination, automatically managing the flow so that the destination is not overwhelmed by a fast readable stream.\n * @function external:Readable#pipe\n * @param {Writable} destination The destination for writing data\n * @param {object} [options] Pipe options\n * @return {null}\n */\n\n/**\n * This method will remove the hooks set up for a previous pipe() call.\n * @function external:Readable#unpipe\n * @param {Writable} [destination] The destination for writing data\n * @return {null}\n */\n\n/**\n * This is useful in certain cases where a stream is being consumed by a parser, which needs to \"un-consume\" some data that it has optimistically pulled out of the source, so that the stream can be passed on to some other party.\n * @function external:Readable#unshift\n * @param {(Buffer|string)} chunk Chunk of data to unshift onto the read queue.\n * @return {null}\n */\n\n/**\n * Versions of Node prior to v0.10 had streams that did not implement the entire Streams API as it is today. (See \"Compatibility\" below for more information.)\n * @function external:Readable#wrap\n * @param {Stream} stream An \"old style\" readable stream.\n * @return {null}\n */\n\nCursor.INIT = 0;\nCursor.OPEN = 1;\nCursor.CLOSED = 2;\nCursor.GET_MORE = 3;\n\nmodule.exports = Cursor;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/cursor.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/db.js":
/*!****************************************!*\
  !*** ./node_modules/mongoDb/lib/db.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter,\n  inherits = __webpack_require__(/*! util */ \"util\").inherits,\n  getSingleProperty = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").getSingleProperty,\n  shallowClone = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").shallowClone,\n  parseIndexOptions = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").parseIndexOptions,\n  debugOptions = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").debugOptions,\n  CommandCursor = __webpack_require__(/*! ./command_cursor */ \"./node_modules/mongoDb/lib/command_cursor.js\"),\n  handleCallback = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").handleCallback,\n  filterOptions = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").filterOptions,\n  toError = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").toError,\n  ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference,\n  f = __webpack_require__(/*! util */ \"util\").format,\n  Admin = __webpack_require__(/*! ./admin */ \"./node_modules/mongoDb/lib/admin.js\"),\n  Code = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.Code,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  ObjectID = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ObjectID,\n  Define = __webpack_require__(/*! ./metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  Logger = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Logger,\n  Collection = __webpack_require__(/*! ./collection */ \"./node_modules/mongoDb/lib/collection.js\"),\n  crypto = __webpack_require__(/*! crypto */ \"crypto\"),\n  mergeOptionsAndWriteConcern = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").mergeOptionsAndWriteConcern,\n  executeOperation = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation;\n\nvar debugFields = [\n  'authSource',\n  'w',\n  'wtimeout',\n  'j',\n  'native_parser',\n  'forceServerObjectId',\n  'serializeFunctions',\n  'raw',\n  'promoteLongs',\n  'promoteValues',\n  'promoteBuffers',\n  'bufferMaxEntries',\n  'numberOfRetries',\n  'retryMiliSeconds',\n  'readPreference',\n  'pkFactory',\n  'parentDb',\n  'promiseLibrary',\n  'noListener'\n];\n\n// Filter out any write concern options\nvar illegalCommandFields = [\n  'w',\n  'wtimeout',\n  'j',\n  'fsync',\n  'autoIndexId',\n  'strict',\n  'serializeFunctions',\n  'pkFactory',\n  'raw',\n  'readPreference',\n  'session'\n];\n\n/**\n * @fileOverview The **Db** class is a class that represents a MongoDB Database.\n *\n * @example\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   // Get an additional db\n *   const testDb = client.db('test');\n *   client.close();\n * });\n */\n\n// Allowed parameters\nvar legalOptionNames = [\n  'w',\n  'wtimeout',\n  'fsync',\n  'j',\n  'readPreference',\n  'readPreferenceTags',\n  'native_parser',\n  'forceServerObjectId',\n  'pkFactory',\n  'serializeFunctions',\n  'raw',\n  'bufferMaxEntries',\n  'authSource',\n  'ignoreUndefined',\n  'promoteLongs',\n  'promiseLibrary',\n  'readConcern',\n  'retryMiliSeconds',\n  'numberOfRetries',\n  'parentDb',\n  'noListener',\n  'loggerLevel',\n  'logger',\n  'promoteBuffers',\n  'promoteLongs',\n  'promoteValues',\n  'compression',\n  'retryWrites'\n];\n\n/**\n * Creates a new Db instance\n * @class\n * @param {string} databaseName The name of the database this instance represents.\n * @param {(Server|ReplSet|Mongos)} topology The server topology for the database.\n * @param {object} [options=null] Optional settings.\n * @param {string} [options.authSource=null] If the database authentication is dependent on another databaseName.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.forceServerObjectId=false] Force server to assign _id values instead of driver.\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object.\n * @param {Boolean} [options.ignoreUndefined=false] Specify if the BSON serializer should ignore undefined fields.\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers.\n * @param {boolean} [options.promoteLongs=true] Promotes Long values to number if they fit inside the 53 bits resolution.\n * @param {boolean} [options.promoteBuffers=false] Promotes Binary BSON values to native Node Buffers.\n * @param {boolean} [options.promoteValues=true] Promotes BSON values to native types where possible, set to false to only receive wrapper types.\n * @param {number} [options.bufferMaxEntries=-1] Sets a cap on how many operations the driver will buffer up before giving up on getting a working connection, default is -1 which is unlimited.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {object} [options.pkFactory=null] A primary key factory object for generation of custom _id keys.\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {object} [options.readConcern=null] Specify a read concern for the collection. (only MongoDB 3.2 or higher supported)\n * @param {object} [options.readConcern.level='local'] Specify a read concern level for the collection operations, one of [local|majority]. (only MongoDB 3.2 or higher supported)\n * @property {(Server|ReplSet|Mongos)} serverConfig Get the current db topology.\n * @property {number} bufferMaxEntries Current bufferMaxEntries value for the database\n * @property {string} databaseName The name of the database this instance represents.\n * @property {object} options The options associated with the db instance.\n * @property {boolean} native_parser The current value of the parameter native_parser.\n * @property {boolean} slaveOk The current slaveOk value for the db instance.\n * @property {object} writeConcern The current write concern values.\n * @property {object} topology Access the topology object (single server, replicaset or mongos).\n * @fires Db#close\n * @fires Db#reconnect\n * @fires Db#error\n * @fires Db#timeout\n * @fires Db#parseError\n * @fires Db#fullsetup\n * @return {Db} a Db instance.\n */\nvar Db = function(databaseName, topology, options) {\n  options = options || {};\n  if (!(this instanceof Db)) return new Db(databaseName, topology, options);\n  EventEmitter.call(this);\n  var self = this;\n\n  // Get the promiseLibrary\n  var promiseLibrary = options.promiseLibrary || Promise;\n\n  // Filter the options\n  options = filterOptions(options, legalOptionNames);\n\n  // Ensure we put the promiseLib in the options\n  options.promiseLibrary = promiseLibrary;\n\n  // var self = this;  // Internal state of the db object\n  this.s = {\n    // Database name\n    databaseName: databaseName,\n    // DbCache\n    dbCache: {},\n    // Children db's\n    children: [],\n    // Topology\n    topology: topology,\n    // Options\n    options: options,\n    // Logger instance\n    logger: Logger('Db', options),\n    // Get the bson parser\n    bson: topology ? topology.bson : null,\n    // Unpack read preference\n    readPreference: options.readPreference,\n    // Set buffermaxEntries\n    bufferMaxEntries: typeof options.bufferMaxEntries === 'number' ? options.bufferMaxEntries : -1,\n    // Parent db (if chained)\n    parentDb: options.parentDb || null,\n    // Set up the primary key factory or fallback to ObjectID\n    pkFactory: options.pkFactory || ObjectID,\n    // Get native parser\n    nativeParser: options.nativeParser || options.native_parser,\n    // Promise library\n    promiseLibrary: promiseLibrary,\n    // No listener\n    noListener: typeof options.noListener === 'boolean' ? options.noListener : false,\n    // ReadConcern\n    readConcern: options.readConcern\n  };\n\n  // Ensure we have a valid db name\n  validateDatabaseName(self.s.databaseName);\n\n  // Add a read Only property\n  getSingleProperty(this, 'serverConfig', self.s.topology);\n  getSingleProperty(this, 'bufferMaxEntries', self.s.bufferMaxEntries);\n  getSingleProperty(this, 'databaseName', self.s.databaseName);\n\n  // This is a child db, do not register any listeners\n  if (options.parentDb) return;\n  if (this.s.noListener) return;\n\n  // Add listeners\n  topology.on('error', createListener(self, 'error', self));\n  topology.on('timeout', createListener(self, 'timeout', self));\n  topology.on('close', createListener(self, 'close', self));\n  topology.on('parseError', createListener(self, 'parseError', self));\n  topology.once('open', createListener(self, 'open', self));\n  topology.once('fullsetup', createListener(self, 'fullsetup', self));\n  topology.once('all', createListener(self, 'all', self));\n  topology.on('reconnect', createListener(self, 'reconnect', self));\n};\n\ninherits(Db, EventEmitter);\n\nvar define = (Db.define = new Define('Db', Db, false));\n\n// Topology\nObject.defineProperty(Db.prototype, 'topology', {\n  enumerable: true,\n  get: function() {\n    return this.s.topology;\n  }\n});\n\n// Options\nObject.defineProperty(Db.prototype, 'options', {\n  enumerable: true,\n  get: function() {\n    return this.s.options;\n  }\n});\n\n// slaveOk specified\nObject.defineProperty(Db.prototype, 'slaveOk', {\n  enumerable: true,\n  get: function() {\n    if (\n      this.s.options.readPreference != null &&\n      (this.s.options.readPreference !== 'primary' ||\n        this.s.options.readPreference.mode !== 'primary')\n    ) {\n      return true;\n    }\n    return false;\n  }\n});\n\n// get the write Concern\nObject.defineProperty(Db.prototype, 'writeConcern', {\n  enumerable: true,\n  get: function() {\n    var ops = {};\n    if (this.s.options.w != null) ops.w = this.s.options.w;\n    if (this.s.options.j != null) ops.j = this.s.options.j;\n    if (this.s.options.fsync != null) ops.fsync = this.s.options.fsync;\n    if (this.s.options.wtimeout != null) ops.wtimeout = this.s.options.wtimeout;\n    return ops;\n  }\n});\n\n/**\n * Ensures provided read preference is properly converted into an object\n * @param {(ReadPreference|string|object)} readPreference the user provided read preference\n * @return {ReadPreference}\n */\nconst convertReadPreference = function(readPreference) {\n  if (readPreference) {\n    if (typeof readPreference === 'string') {\n      return new ReadPreference(readPreference);\n    } else if (\n      readPreference &&\n      !(readPreference instanceof ReadPreference) &&\n      typeof readPreference === 'object'\n    ) {\n      const mode = readPreference.mode || readPreference.preference;\n      if (mode && typeof mode === 'string') {\n        return new ReadPreference(mode, readPreference.tags, {\n          maxStalenessSeconds: readPreference.maxStalenessSeconds\n        });\n      }\n    } else if (!(readPreference instanceof ReadPreference)) {\n      throw new TypeError('Invalid read preference: ' + readPreference);\n    }\n  }\n\n  return readPreference;\n};\n\n/**\n * The callback format for results\n * @callback Db~resultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {object} result The result object if the command was executed successfully.\n */\nvar executeCommand = function(self, command, options, callback) {\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n  // Get the db name we are executing against\n  var dbName = options.dbName || options.authdb || self.s.databaseName;\n\n  // If we have a readPreference set\n  if (options.readPreference == null && self.s.readPreference) {\n    options.readPreference = self.s.readPreference;\n  }\n\n  // Convert the readPreference if its not a write\n  if (options.readPreference) {\n    options.readPreference = convertReadPreference(options.readPreference);\n  } else {\n    options.readPreference = ReadPreference.primary;\n  }\n\n  // Debug information\n  if (self.s.logger.isDebug())\n    self.s.logger.debug(\n      f(\n        'executing command %s against %s with options [%s]',\n        JSON.stringify(command),\n        f('%s.$cmd', dbName),\n        JSON.stringify(debugOptions(debugFields, options))\n      )\n    );\n\n  // Execute command\n  self.s.topology.command(f('%s.$cmd', dbName), command, options, function(err, result) {\n    if (err) return handleCallback(callback, err);\n    if (options.full) return handleCallback(callback, null, result);\n    handleCallback(callback, null, result.result);\n  });\n};\n\n/**\n * Execute a command\n * @method\n * @param {object} command The command hash\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.command = function(command, options, callback) {\n  // Change the callback\n  if (typeof options === 'function') (callback = options), (options = {});\n  // Clone the options\n  options = shallowClone(options);\n\n  return executeOperation(this.s.topology, executeCommand, [this, command, options, callback]);\n};\n\ndefine.classMethod('command', { callback: true, promise: true });\n\n/**\n * Return the Admin db instance\n * @method\n * @return {Admin} return the new Admin db instance\n */\nDb.prototype.admin = function() {\n  return new Admin(this, this.s.topology, this.s.promiseLibrary);\n};\n\ndefine.classMethod('admin', { callback: false, promise: false, returns: [Admin] });\n\n/**\n * The callback format for the collection method, must be used if strict is specified\n * @callback Db~collectionResultCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection} collection The collection instance.\n */\n\nvar collectionKeys = [\n  'pkFactory',\n  'readPreference',\n  'serializeFunctions',\n  'strict',\n  'readConcern',\n  'ignoreUndefined',\n  'promoteValues',\n  'promoteBuffers',\n  'promoteLongs'\n];\n\n/**\n * Fetch a specific collection (containing the actual collection information). If the application does not use strict mode you\n * can use it without a callback in the following way: `var collection = db.collection('mycollection');`\n *\n * @method\n * @param {string} name the collection name we wish to access.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers.\n * @param {object} [options.pkFactory=null] A primary key factory object for generation of custom _id keys.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object.\n * @param {boolean} [options.strict=false] Returns an error if the collection does not exist\n * @param {object} [options.readConcern=null] Specify a read concern for the collection. (only MongoDB 3.2 or higher supported)\n * @param {object} [options.readConcern.level='local'] Specify a read concern level for the collection operations, one of [local|majority]. (only MongoDB 3.2 or higher supported)\n * @param {Db~collectionResultCallback} [callback] The collection result callback\n * @return {Collection} return the new Collection instance if not in strict mode\n */\nDb.prototype.collection = function(name, options, callback) {\n  var self = this;\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n  options = shallowClone(options);\n  // Set the promise library\n  options.promiseLibrary = this.s.promiseLibrary;\n\n  // If we have not set a collection level readConcern set the db level one\n  options.readConcern = options.readConcern || this.s.readConcern;\n\n  // Do we have ignoreUndefined set\n  if (this.s.options.ignoreUndefined) {\n    options.ignoreUndefined = this.s.options.ignoreUndefined;\n  }\n\n  // Merge in all needed options and ensure correct writeConcern merging from db level\n  options = mergeOptionsAndWriteConcern(options, this.s.options, collectionKeys, true);\n\n  // Execute\n  if (options == null || !options.strict) {\n    try {\n      var collection = new Collection(\n        this,\n        this.s.topology,\n        this.s.databaseName,\n        name,\n        this.s.pkFactory,\n        options\n      );\n      if (callback) callback(null, collection);\n      return collection;\n    } catch (err) {\n      if (err instanceof MongoError && callback) return callback(err);\n      throw err;\n    }\n  }\n\n  // Strict mode\n  if (typeof callback !== 'function') {\n    throw toError(f('A callback is required in strict mode. While getting collection %s.', name));\n  }\n\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed()) {\n    return callback(new MongoError('topology was destroyed'));\n  }\n\n  // Strict mode\n  this.listCollections({ name: name }, options).toArray(function(err, collections) {\n    if (err != null) return handleCallback(callback, err, null);\n    if (collections.length === 0)\n      return handleCallback(\n        callback,\n        toError(f('Collection %s does not exist. Currently in strict mode.', name)),\n        null\n      );\n\n    try {\n      return handleCallback(\n        callback,\n        null,\n        new Collection(self, self.s.topology, self.s.databaseName, name, self.s.pkFactory, options)\n      );\n    } catch (err) {\n      return handleCallback(callback, err, null);\n    }\n  });\n};\n\ndefine.classMethod('collection', { callback: true, promise: false, returns: [Collection] });\n\nfunction decorateWithWriteConcern(command, self, options) {\n  // Do we support write concerns 3.4 and higher\n  if (self.s.topology.capabilities().commandsTakeWriteConcern) {\n    // Get the write concern settings\n    var finalOptions = writeConcern(shallowClone(options), self, options);\n    // Add the write concern to the command\n    if (finalOptions.writeConcern) {\n      command.writeConcern = finalOptions.writeConcern;\n    }\n  }\n}\n\nvar createCollection = function(self, name, options, callback) {\n  // Get the write concern options\n  var finalOptions = writeConcern(shallowClone(options), self, options);\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed()) {\n    return callback(new MongoError('topology was destroyed'));\n  }\n\n  // Check if we have the name\n  self\n    .listCollections({ name: name }, finalOptions)\n    .setReadPreference(ReadPreference.PRIMARY)\n    .toArray(function(err, collections) {\n      if (err != null) return handleCallback(callback, err, null);\n      if (collections.length > 0 && finalOptions.strict) {\n        return handleCallback(\n          callback,\n          MongoError.create({\n            message: f('Collection %s already exists. Currently in strict mode.', name),\n            driver: true\n          }),\n          null\n        );\n      } else if (collections.length > 0) {\n        try {\n          return handleCallback(\n            callback,\n            null,\n            new Collection(\n              self,\n              self.s.topology,\n              self.s.databaseName,\n              name,\n              self.s.pkFactory,\n              options\n            )\n          );\n        } catch (err) {\n          return handleCallback(callback, err);\n        }\n      }\n\n      // Create collection command\n      var cmd = { create: name };\n\n      // Decorate command with writeConcern if supported\n      decorateWithWriteConcern(cmd, self, options);\n      // Add all optional parameters\n      for (var n in options) {\n        if (\n          options[n] != null &&\n          typeof options[n] !== 'function' &&\n          illegalCommandFields.indexOf(n) === -1\n        ) {\n          cmd[n] = options[n];\n        }\n      }\n\n      // Force a primary read Preference\n      finalOptions.readPreference = ReadPreference.PRIMARY;\n\n      // Execute command\n      self.command(cmd, finalOptions, function(err) {\n        if (err) return handleCallback(callback, err);\n        handleCallback(\n          callback,\n          null,\n          new Collection(\n            self,\n            self.s.topology,\n            self.s.databaseName,\n            name,\n            self.s.pkFactory,\n            options\n          )\n        );\n      });\n    });\n};\n\n/**\n * Create a new collection on a server with the specified options. Use this to create capped collections.\n * More information about command options available at https://docs.mongodb.com/manual/reference/command/create/\n *\n * @method\n * @param {string} name the collection name we wish to access.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers.\n * @param {object} [options.pkFactory=null] A primary key factory object for generation of custom _id keys.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object.\n * @param {boolean} [options.strict=false] Returns an error if the collection does not exist\n * @param {boolean} [options.capped=false] Create a capped collection.\n * @param {boolean} [options.autoIndexId=true] Create an index on the _id field of the document, True by default on MongoDB 2.2 or higher off for version < 2.2.\n * @param {number} [options.size=null] The size of the capped collection in bytes.\n * @param {number} [options.max=null] The maximum number of documents in the capped collection.\n * @param {number} [options.flags=null] Optional. Available for the MMAPv1 storage engine only to set the usePowerOf2Sizes and the noPadding flag.\n * @param {object} [options.storageEngine=null] Allows users to specify configuration to the storage engine on a per-collection basis when creating a collection on MongoDB 3.0 or higher.\n * @param {object} [options.validator=null] Allows users to specify validation rules or expressions for the collection. For more information, see Document Validation on MongoDB 3.2 or higher.\n * @param {string} [options.validationLevel=null] Determines how strictly MongoDB applies the validation rules to existing documents during an update on MongoDB 3.2 or higher.\n * @param {string} [options.validationAction=null] Determines whether to error on invalid documents or just warn about the violations but allow invalid documents to be inserted on MongoDB 3.2 or higher.\n * @param {object} [options.indexOptionDefaults=null] Allows users to specify a default configuration for indexes when creating a collection on MongoDB 3.2 or higher.\n * @param {string} [options.viewOn=null] The name of the source collection or view from which to create the view. The name is not the full namespace of the collection or view; i.e. does not include the database name and implies the same database as the view to create on MongoDB 3.4 or higher.\n * @param {array} [options.pipeline=null] An array that consists of the aggregation pipeline stage. create creates the view by applying the specified pipeline to the viewOn collection or view on MongoDB 3.4 or higher.\n * @param {object} [options.collation=null] Specify collation (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~collectionResultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.createCollection = function(name, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n  options.promiseLibrary = options.promiseLibrary || this.s.promiseLibrary;\n\n  return executeOperation(this.s.topology, createCollection, [this, name, options, callback]);\n};\n\ndefine.classMethod('createCollection', { callback: true, promise: true });\n\n/**\n * Get all the db statistics.\n *\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.scale=null] Divide the returned sizes by scale value.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The collection result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.stats = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n  // Build command object\n  var commandObject = { dbStats: true };\n  // Check if we have the scale value\n  if (options['scale'] != null) commandObject['scale'] = options['scale'];\n\n  // If we have a readPreference set\n  if (options.readPreference == null && this.s.readPreference) {\n    options.readPreference = this.s.readPreference;\n  }\n\n  // Execute the command\n  return this.command(commandObject, options, callback);\n};\n\ndefine.classMethod('stats', { callback: true, promise: true });\n\n// Transformation methods for cursor results\nvar listCollectionsTranforms = function(databaseName) {\n  var matching = f('%s.', databaseName);\n\n  return {\n    doc: function(doc) {\n      var index = doc.name.indexOf(matching);\n      // Remove database name if available\n      if (doc.name && index === 0) {\n        doc.name = doc.name.substr(index + matching.length);\n      }\n\n      return doc;\n    }\n  };\n};\n\n/**\n * Get the list of all collection information for the specified db.\n *\n * @method\n * @param {object} [filter={}] Query to filter collections by\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.batchSize=null] The batchSize for the returned command cursor or if pre 2.8 the systems batch collection\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @return {CommandCursor}\n */\nDb.prototype.listCollections = function(filter, options) {\n  filter = filter || {};\n  options = options || {};\n\n  // Shallow clone the object\n  options = shallowClone(options);\n  // Set the promise library\n  options.promiseLibrary = this.s.promiseLibrary;\n\n  // Ensure valid readPreference\n  if (options.readPreference) {\n    options.readPreference = convertReadPreference(options.readPreference);\n  } else {\n    options.readPreference = this.s.readPreference || ReadPreference.primary;\n  }\n\n  // We have a list collections command\n  if (this.serverConfig.capabilities().hasListCollectionsCommand) {\n    // Cursor options\n    var cursor = options.batchSize ? { batchSize: options.batchSize } : {};\n    // Build the command\n    var command = { listCollections: true, filter: filter, cursor: cursor };\n    // Set the AggregationCursor constructor\n    options.cursorFactory = CommandCursor;\n    // Create the cursor\n    cursor = this.s.topology.cursor(f('%s.$cmd', this.s.databaseName), command, options);\n    // Do we have a readPreference, apply it\n    if (options.readPreference) {\n      cursor.setReadPreference(options.readPreference);\n    }\n    // Return the cursor\n    return cursor;\n  }\n\n  // We cannot use the listCollectionsCommand\n  if (!this.serverConfig.capabilities().hasListCollectionsCommand) {\n    // If we have legacy mode and have not provided a full db name filter it\n    if (\n      typeof filter.name === 'string' &&\n      !new RegExp('^' + this.databaseName + '\\\\.').test(filter.name)\n    ) {\n      filter = shallowClone(filter);\n      filter.name = f('%s.%s', this.s.databaseName, filter.name);\n    }\n  }\n\n  // No filter, filter by current database\n  if (filter == null) {\n    filter.name = f('/%s/', this.s.databaseName);\n  }\n\n  // Rewrite the filter to use $and to filter out indexes\n  if (filter.name) {\n    filter = { $and: [{ name: filter.name }, { name: /^((?!\\$).)*$/ }] };\n  } else {\n    filter = { name: /^((?!\\$).)*$/ };\n  }\n\n  // Return options\n  var _options = { transforms: listCollectionsTranforms(this.s.databaseName) };\n  // Get the cursor\n  cursor = this.collection(Db.SYSTEM_NAMESPACE_COLLECTION).find(filter, _options);\n  // Do we have a readPreference, apply it\n  if (options.readPreference) cursor.setReadPreference(options.readPreference);\n  // Set the passed in batch size if one was provided\n  if (options.batchSize) cursor = cursor.batchSize(options.batchSize);\n  // We have a fallback mode using legacy systems collections\n  return cursor;\n};\n\ndefine.classMethod('listCollections', {\n  callback: false,\n  promise: false,\n  returns: [CommandCursor]\n});\n\nvar evaluate = function(self, code, parameters, options, callback) {\n  var finalCode = code;\n  var finalParameters = [];\n\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n\n  // If not a code object translate to one\n  if (!(finalCode && finalCode._bsontype === 'Code')) finalCode = new Code(finalCode);\n  // Ensure the parameters are correct\n  if (parameters != null && !Array.isArray(parameters) && typeof parameters !== 'function') {\n    finalParameters = [parameters];\n  } else if (parameters != null && Array.isArray(parameters) && typeof parameters !== 'function') {\n    finalParameters = parameters;\n  }\n\n  // Create execution selector\n  var cmd = { $eval: finalCode, args: finalParameters };\n  // Check if the nolock parameter is passed in\n  if (options['nolock']) {\n    cmd['nolock'] = options['nolock'];\n  }\n\n  // Set primary read preference\n  options.readPreference = new ReadPreference(ReadPreference.PRIMARY);\n\n  // Execute the command\n  self.command(cmd, options, function(err, result) {\n    if (err) return handleCallback(callback, err, null);\n    if (result && result.ok === 1) return handleCallback(callback, null, result.retval);\n    if (result)\n      return handleCallback(\n        callback,\n        MongoError.create({ message: f('eval failed: %s', result.errmsg), driver: true }),\n        null\n      );\n    handleCallback(callback, err, result);\n  });\n};\n\n/**\n * Evaluate JavaScript on the server\n *\n * @method\n * @param {Code} code JavaScript to execute on server.\n * @param {(object|array)} parameters The parameters for the call.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.nolock=false] Tell MongoDB not to block on the evaulation of the javascript.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The results callback\n * @deprecated Eval is deprecated on MongoDB 3.2 and forward\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.eval = function(code, parameters, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  parameters = args.length ? args.shift() : parameters;\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, evaluate, [this, code, parameters, options, callback]);\n};\n\ndefine.classMethod('eval', { callback: true, promise: true });\n\n/**\n * Rename a collection.\n *\n * @method\n * @param {string} fromCollection Name of current collection to rename.\n * @param {string} toCollection New name of of the collection.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.dropTarget=false] Drop the target name collection if it previously exists.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~collectionResultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.renameCollection = function(fromCollection, toCollection, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n  // Add return new collection\n  options.new_collection = true;\n\n  const collection = this.collection(fromCollection);\n  return executeOperation(this.s.topology, collection.rename.bind(collection), [\n    toCollection,\n    options,\n    callback\n  ]);\n};\n\ndefine.classMethod('renameCollection', { callback: true, promise: true });\n\n/**\n * Drop a collection from the database, removing it permanently. New accesses will create a new collection.\n *\n * @method\n * @param {string} name Name of collection to drop\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.dropCollection = function(name, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Command to execute\n  var cmd = { drop: name };\n\n  // Decorate with write concern\n  decorateWithWriteConcern(cmd, this, options);\n\n  // options\n  const opts = Object.assign({}, this.s.options, { readPreference: ReadPreference.PRIMARY });\n  if (options.session) opts.session = options.session;\n\n  return executeOperation(this.s.topology, dropCollection, [this, cmd, opts, callback]);\n};\n\nconst dropCollection = (self, cmd, options, callback) => {\n  return self.command(cmd, options, function(err, result) {\n    // Did the user destroy the topology\n    if (self.serverConfig && self.serverConfig.isDestroyed()) {\n      return callback(new MongoError('topology was destroyed'));\n    }\n\n    if (err) return handleCallback(callback, err);\n    if (result.ok) return handleCallback(callback, null, true);\n    handleCallback(callback, null, false);\n  });\n};\n\ndefine.classMethod('dropCollection', { callback: true, promise: true });\n\n/**\n * Drop a database, removing it permanently from the server.\n *\n * @method\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.dropDatabase = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n  // Drop database command\n  var cmd = { dropDatabase: 1 };\n\n  // Decorate with write concern\n  decorateWithWriteConcern(cmd, this, options);\n\n  // Ensure primary only\n  const finalOptions = Object.assign(\n    {},\n    { readPreference: ReadPreference.PRIMARY },\n    this.s.options\n  );\n  if (options.session) {\n    finalOptions.session = options.session;\n  }\n\n  return executeOperation(this.s.topology, dropDatabase, [this, cmd, finalOptions, callback]);\n};\n\nconst dropDatabase = (self, cmd, options, callback) => {\n  self.command(cmd, options, function(err, result) {\n    // Did the user destroy the topology\n    if (self.serverConfig && self.serverConfig.isDestroyed()) {\n      return callback(new MongoError('topology was destroyed'));\n    }\n\n    if (callback == null) return;\n    if (err) return handleCallback(callback, err, null);\n    handleCallback(callback, null, result.ok ? true : false);\n  });\n};\n\ndefine.classMethod('dropDatabase', { callback: true, promise: true });\n\n/**\n * Fetch all collections for the current db.\n *\n * @method\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~collectionsResultCallback} [callback] The results callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.collections = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, collections, [this, options, callback]);\n};\n\nvar collections = function(self, options, callback) {\n  // Let's get the collection names\n  self.listCollections({}, options).toArray(function(err, documents) {\n    if (err != null) return handleCallback(callback, err, null);\n    // Filter collections removing any illegal ones\n    documents = documents.filter(function(doc) {\n      return doc.name.indexOf('$') === -1;\n    });\n\n    // Return the collection objects\n    handleCallback(\n      callback,\n      null,\n      documents.map(function(d) {\n        return new Collection(\n          self,\n          self.s.topology,\n          self.s.databaseName,\n          d.name,\n          self.s.pkFactory,\n          self.s.options\n        );\n      })\n    );\n  });\n};\n\ndefine.classMethod('collections', { callback: true, promise: true });\n\n/**\n * Runs a command on the database as admin.\n * @method\n * @param {object} command The command hash\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.executeDbAdminCommand = function(selector, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Convert read preference\n  if (options.readPreference) {\n    options.readPreference = convertReadPreference(options.readPreference);\n  }\n\n  return executeOperation(this.s.topology, executeDbAdminCommand, [\n    this,\n    selector,\n    options,\n    callback\n  ]);\n};\n\nconst executeDbAdminCommand = (self, selector, options, callback) => {\n  self.s.topology.command('admin.$cmd', selector, options, function(err, result) {\n    // Did the user destroy the topology\n    if (self.serverConfig && self.serverConfig.isDestroyed()) {\n      return callback(new MongoError('topology was destroyed'));\n    }\n\n    if (err) return handleCallback(callback, err);\n    handleCallback(callback, null, result.result);\n  });\n};\n\ndefine.classMethod('executeDbAdminCommand', { callback: true, promise: true });\n\n/**\n * Creates an index on the db and collection collection.\n * @method\n * @param {string} name Name of the collection to create the index on.\n * @param {(string|object)} fieldOrSpec Defines the index.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.unique=false] Creates an unique index.\n * @param {boolean} [options.sparse=false] Creates a sparse index.\n * @param {boolean} [options.background=false] Creates the index in the background, yielding whenever possible.\n * @param {boolean} [options.dropDups=false] A unique index cannot be created on a key that has pre-existing duplicate values. If you would like to create the index anyway, keeping the first document the database indexes and deleting all subsequent documents that have duplicate value\n * @param {number} [options.min=null] For geospatial indexes set the lower bound for the co-ordinates.\n * @param {number} [options.max=null] For geospatial indexes set the high bound for the co-ordinates.\n * @param {number} [options.v=null] Specify the format version of the indexes.\n * @param {number} [options.expireAfterSeconds=null] Allows you to expire data on indexes applied to a data (MongoDB 2.2 or higher)\n * @param {number} [options.name=null] Override the autogenerated index name (useful if the resulting name is larger than 128 bytes)\n * @param {object} [options.partialFilterExpression=null] Creates a partial index based on the given filter object (MongoDB 3.2 or higher)\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.createIndex = function(name, fieldOrSpec, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options ? shallowClone(options) : {};\n\n  return executeOperation(this.s.topology, createIndex, [\n    this,\n    name,\n    fieldOrSpec,\n    options,\n    callback\n  ]);\n};\n\nvar createIndex = function(self, name, fieldOrSpec, options, callback) {\n  // Get the write concern options\n  var finalOptions = Object.assign({}, { readPreference: ReadPreference.PRIMARY }, options);\n  finalOptions = writeConcern(finalOptions, self, options);\n\n  // Ensure we have a callback\n  if (finalOptions.writeConcern && typeof callback !== 'function') {\n    throw MongoError.create({\n      message: 'Cannot use a writeConcern without a provided callback',\n      driver: true\n    });\n  }\n\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n\n  // Attempt to run using createIndexes command\n  createIndexUsingCreateIndexes(self, name, fieldOrSpec, options, function(err, result) {\n    if (err == null) return handleCallback(callback, err, result);\n\n    // 67 = 'CannotCreateIndex' (malformed index options)\n    // 85 = 'IndexOptionsConflict' (index already exists with different options)\n    // 11000 = 'DuplicateKey' (couldn't build unique index because of dupes)\n    // 11600 = 'InterruptedAtShutdown' (interrupted at shutdown)\n    // These errors mean that the server recognized `createIndex` as a command\n    // and so we don't need to fallback to an insert.\n    if (err.code === 67 || err.code === 11000 || err.code === 85 || err.code === 11600) {\n      return handleCallback(callback, err, result);\n    }\n\n    // Create command\n    var doc = createCreateIndexCommand(self, name, fieldOrSpec, options);\n    // Set no key checking\n    finalOptions.checkKeys = false;\n    // Insert document\n    self.s.topology.insert(\n      f('%s.%s', self.s.databaseName, Db.SYSTEM_INDEX_COLLECTION),\n      doc,\n      finalOptions,\n      function(err, result) {\n        if (callback == null) return;\n        if (err) return handleCallback(callback, err);\n        if (result == null) return handleCallback(callback, null, null);\n        if (result.result.writeErrors)\n          return handleCallback(callback, MongoError.create(result.result.writeErrors[0]), null);\n        handleCallback(callback, null, doc.name);\n      }\n    );\n  });\n};\n\ndefine.classMethod('createIndex', { callback: true, promise: true });\n\n/**\n * Ensures that an index exists, if it does not it creates it\n * @method\n * @deprecated since version 2.0\n * @param {string} name The index name\n * @param {(string|object)} fieldOrSpec Defines the index.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.unique=false] Creates an unique index.\n * @param {boolean} [options.sparse=false] Creates a sparse index.\n * @param {boolean} [options.background=false] Creates the index in the background, yielding whenever possible.\n * @param {boolean} [options.dropDups=false] A unique index cannot be created on a key that has pre-existing duplicate values. If you would like to create the index anyway, keeping the first document the database indexes and deleting all subsequent documents that have duplicate value\n * @param {number} [options.min=null] For geospatial indexes set the lower bound for the co-ordinates.\n * @param {number} [options.max=null] For geospatial indexes set the high bound for the co-ordinates.\n * @param {number} [options.v=null] Specify the format version of the indexes.\n * @param {number} [options.expireAfterSeconds=null] Allows you to expire data on indexes applied to a data (MongoDB 2.2 or higher)\n * @param {number} [options.name=null] Override the autogenerated index name (useful if the resulting name is larger than 128 bytes)\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.ensureIndex = function(name, fieldOrSpec, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, ensureIndex, [\n    this,\n    name,\n    fieldOrSpec,\n    options,\n    callback\n  ]);\n};\n\nvar ensureIndex = function(self, name, fieldOrSpec, options, callback) {\n  // Get the write concern options\n  var finalOptions = writeConcern({}, self, options);\n  // Create command\n  var selector = createCreateIndexCommand(self, name, fieldOrSpec, options);\n  var index_name = selector.name;\n\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n\n  // Merge primary readPreference\n  finalOptions.readPreference = ReadPreference.PRIMARY;\n\n  // Check if the index allready exists\n  self.indexInformation(name, finalOptions, function(err, indexInformation) {\n    if (err != null && err.code !== 26) return handleCallback(callback, err, null);\n    // If the index does not exist, create it\n    if (indexInformation == null || !indexInformation[index_name]) {\n      self.createIndex(name, fieldOrSpec, options, callback);\n    } else {\n      if (typeof callback === 'function') return handleCallback(callback, null, index_name);\n    }\n  });\n};\n\ndefine.classMethod('ensureIndex', { callback: true, promise: true });\n\nDb.prototype.addChild = function(db) {\n  if (this.s.parentDb) return this.s.parentDb.addChild(db);\n  this.s.children.push(db);\n};\n\nvar _executeAuthCreateUserCommand = function(self, username, password, options, callback) {\n  // Special case where there is no password ($external users)\n  if (typeof username === 'string' && password != null && typeof password === 'object') {\n    options = password;\n    password = null;\n  }\n\n  // Unpack all options\n  if (typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n\n  // Error out if we digestPassword set\n  if (options.digestPassword != null) {\n    throw toError(\n      \"The digestPassword option is not supported via add_user. Please use db.command('createUser', ...) instead for this option.\"\n    );\n  }\n\n  // Get additional values\n  var customData = options.customData != null ? options.customData : {};\n  var roles = Array.isArray(options.roles) ? options.roles : [];\n  var maxTimeMS = typeof options.maxTimeMS === 'number' ? options.maxTimeMS : null;\n\n  // If not roles defined print deprecated message\n  if (roles.length === 0) {\n    console.log('Creating a user without roles is deprecated in MongoDB >= 2.6');\n  }\n\n  // Get the error options\n  var commandOptions = { writeCommand: true };\n  if (options['dbName']) commandOptions.dbName = options['dbName'];\n\n  // Add maxTimeMS to options if set\n  if (maxTimeMS != null) commandOptions.maxTimeMS = maxTimeMS;\n\n  // Check the db name and add roles if needed\n  if (\n    (self.databaseName.toLowerCase() === 'admin' || options.dbName === 'admin') &&\n    !Array.isArray(options.roles)\n  ) {\n    roles = ['root'];\n  } else if (!Array.isArray(options.roles)) {\n    roles = ['dbOwner'];\n  }\n\n  // Build the command to execute\n  var command = {\n    createUser: username,\n    customData: customData,\n    roles: roles,\n    digestPassword: false\n  };\n\n  // Apply write concern to command\n  command = writeConcern(command, self, options);\n\n  // Use node md5 generator\n  var md5 = crypto.createHash('md5');\n  // Generate keys used for authentication\n  md5.update(username + ':mongo:' + password);\n  var userPassword = md5.digest('hex');\n\n  // No password\n  if (typeof password === 'string') {\n    command.pwd = userPassword;\n  }\n\n  // Force write using primary\n  commandOptions.readPreference = ReadPreference.primary;\n\n  // Execute the command\n  self.command(command, commandOptions, function(err, result) {\n    if (err && err.ok === 0 && err.code === undefined)\n      return handleCallback(callback, { code: -5000 }, null);\n    if (err) return handleCallback(callback, err, null);\n    handleCallback(\n      callback,\n      !result.ok ? toError(result) : null,\n      result.ok ? [{ user: username, pwd: '' }] : null\n    );\n  });\n};\n\nvar addUser = function(self, username, password, options, callback) {\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n  // Attempt to execute auth command\n  _executeAuthCreateUserCommand(self, username, password, options, function(err, r) {\n    // We need to perform the backward compatible insert operation\n    if (err && err.code === -5000) {\n      var finalOptions = writeConcern(shallowClone(options), self, options);\n      // Use node md5 generator\n      var md5 = crypto.createHash('md5');\n      // Generate keys used for authentication\n      md5.update(username + ':mongo:' + password);\n      var userPassword = md5.digest('hex');\n\n      // If we have another db set\n      var db = options.dbName ? new Db(options.dbName, self.s.topology, self.s.options) : self;\n\n      // Fetch a user collection\n      var collection = db.collection(Db.SYSTEM_USER_COLLECTION);\n\n      // Check if we are inserting the first user\n      collection.count({}, finalOptions, function(err, count) {\n        // We got an error (f.ex not authorized)\n        if (err != null) return handleCallback(callback, err, null);\n        // Check if the user exists and update i\n        collection\n          .find({ user: username }, { dbName: options['dbName'] }, finalOptions)\n          .toArray(function(err) {\n            // We got an error (f.ex not authorized)\n            if (err != null) return handleCallback(callback, err, null);\n            // Add command keys\n            finalOptions.upsert = true;\n\n            // We have a user, let's update the password or upsert if not\n            collection.update(\n              { user: username },\n              { $set: { user: username, pwd: userPassword } },\n              finalOptions,\n              function(err) {\n                if (count === 0 && err)\n                  return handleCallback(callback, null, [{ user: username, pwd: userPassword }]);\n                if (err) return handleCallback(callback, err, null);\n                handleCallback(callback, null, [{ user: username, pwd: userPassword }]);\n              }\n            );\n          });\n      });\n\n      return;\n    }\n\n    if (err) return handleCallback(callback, err);\n    handleCallback(callback, err, r);\n  });\n};\n\n/**\n * Add a user to the database.\n * @method\n * @param {string} username The username.\n * @param {string} password The password.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {object} [options.customData=null] Custom data associated with the user (only Mongodb 2.6 or higher)\n * @param {object[]} [options.roles=null] Roles associated with the created user (only Mongodb 2.6 or higher)\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.addUser = function(username, password, options, callback) {\n  // Unpack the parameters\n  var args = Array.prototype.slice.call(arguments, 2);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, addUser, [this, username, password, options, callback]);\n};\n\ndefine.classMethod('addUser', { callback: true, promise: true });\n\nvar _executeAuthRemoveUserCommand = function(self, username, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n  // Get the error options\n  var commandOptions = { writeCommand: true };\n  if (options['dbName']) commandOptions.dbName = options['dbName'];\n\n  // Get additional values\n  var maxTimeMS = typeof options.maxTimeMS === 'number' ? options.maxTimeMS : null;\n\n  // Add maxTimeMS to options if set\n  if (maxTimeMS != null) commandOptions.maxTimeMS = maxTimeMS;\n\n  // Build the command to execute\n  var command = {\n    dropUser: username\n  };\n\n  // Apply write concern to command\n  command = writeConcern(command, self, options);\n\n  // Force write using primary\n  commandOptions.readPreference = ReadPreference.primary;\n\n  // Execute the command\n  self.command(command, commandOptions, function(err, result) {\n    if (err && !err.ok && err.code === undefined) return handleCallback(callback, { code: -5000 });\n    if (err) return handleCallback(callback, err, null);\n    handleCallback(callback, null, result.ok ? true : false);\n  });\n};\n\nvar removeUser = function(self, username, options, callback) {\n  // Attempt to execute command\n  _executeAuthRemoveUserCommand(self, username, options, function(err, result) {\n    if (err && err.code === -5000) {\n      var finalOptions = writeConcern(shallowClone(options), self, options);\n      // If we have another db set\n      var db = options.dbName ? new Db(options.dbName, self.s.topology, self.s.options) : self;\n\n      // Fetch a user collection\n      var collection = db.collection(Db.SYSTEM_USER_COLLECTION);\n\n      // Locate the user\n      collection.findOne({ user: username }, finalOptions, function(err, user) {\n        if (user == null) return handleCallback(callback, err, false);\n        collection.remove({ user: username }, finalOptions, function(err) {\n          handleCallback(callback, err, true);\n        });\n      });\n\n      return;\n    }\n\n    if (err) return handleCallback(callback, err);\n    handleCallback(callback, err, result);\n  });\n};\n\ndefine.classMethod('removeUser', { callback: true, promise: true });\n\n/**\n * Remove a user from a database\n * @method\n * @param {string} username The username.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.removeUser = function(username, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() || {} : {};\n\n  return executeOperation(this.s.topology, removeUser, [this, username, options, callback]);\n};\n\n/**\n * Set the current profiling level of MongoDB\n *\n * @param {string} level The new profiling level (off, slow_only, all).\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback.\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.setProfilingLevel = function(level, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, setProfilingLevel, [this, level, options, callback]);\n};\n\nvar setProfilingLevel = function(self, level, options, callback) {\n  var command = {};\n  var profile = 0;\n\n  if (level === 'off') {\n    profile = 0;\n  } else if (level === 'slow_only') {\n    profile = 1;\n  } else if (level === 'all') {\n    profile = 2;\n  } else {\n    return callback(new Error('Error: illegal profiling level value ' + level));\n  }\n\n  // Set up the profile number\n  command['profile'] = profile;\n\n  self.command(command, options, function(err, doc) {\n    if (err == null && doc.ok === 1) return callback(null, level);\n    return err != null\n      ? callback(err, null)\n      : callback(new Error('Error with profile command'), null);\n  });\n};\n\ndefine.classMethod('setProfilingLevel', { callback: true, promise: true });\n\n/**\n * Retrive the current profiling information for MongoDB\n *\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Query the system.profile collection directly.\n */\nDb.prototype.profilingInfo = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, profilingInfo, [this, options, callback]);\n};\n\nvar profilingInfo = function(self, options, callback) {\n  try {\n    self\n      .collection('system.profile')\n      .find({}, null, options)\n      .toArray(callback);\n  } catch (err) {\n    return callback(err, null);\n  }\n};\n\ndefine.classMethod('profilingInfo', { callback: true, promise: true });\n\n/**\n * Retrieve the current profiling Level for MongoDB\n *\n * @param {Object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.profilingLevel = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, profilingLevel, [this, options, callback]);\n};\n\nvar profilingLevel = function(self, options, callback) {\n  self.command({ profile: -1 }, options, function(err, doc) {\n    if (err == null && doc.ok === 1) {\n      var was = doc.was;\n      if (was === 0) return callback(null, 'off');\n      if (was === 1) return callback(null, 'slow_only');\n      if (was === 2) return callback(null, 'all');\n      return callback(new Error('Error: illegal profiling level value ' + was), null);\n    } else {\n      err != null ? callback(err, null) : callback(new Error('Error with profile command'), null);\n    }\n  });\n};\n\ndefine.classMethod('profilingLevel', { callback: true, promise: true });\n\n/**\n * Retrieves this collections index info.\n * @method\n * @param {string} name The name of the collection.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.full=false] Returns the full raw index information.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nDb.prototype.indexInformation = function(name, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.s.topology, indexInformation, [this, name, options, callback]);\n};\n\nvar indexInformation = function(self, name, options, callback) {\n  // If we specified full information\n  var full = options['full'] == null ? false : options['full'];\n\n  // Did the user destroy the topology\n  if (self.serverConfig && self.serverConfig.isDestroyed())\n    return callback(new MongoError('topology was destroyed'));\n  // Process all the results from the index command and collection\n  var processResults = function(indexes) {\n    // Contains all the information\n    var info = {};\n    // Process all the indexes\n    for (var i = 0; i < indexes.length; i++) {\n      var index = indexes[i];\n      // Let's unpack the object\n      info[index.name] = [];\n      for (var name in index.key) {\n        info[index.name].push([name, index.key[name]]);\n      }\n    }\n\n    return info;\n  };\n\n  // Get the list of indexes of the specified collection\n  self\n    .collection(name)\n    .listIndexes(options)\n    .toArray(function(err, indexes) {\n      if (err) return callback(toError(err));\n      if (!Array.isArray(indexes)) return handleCallback(callback, null, []);\n      if (full) return handleCallback(callback, null, indexes);\n      handleCallback(callback, null, processResults(indexes));\n    });\n};\n\ndefine.classMethod('indexInformation', { callback: true, promise: true });\n\nvar createCreateIndexCommand = function(db, name, fieldOrSpec, options) {\n  var indexParameters = parseIndexOptions(fieldOrSpec);\n  var fieldHash = indexParameters.fieldHash;\n\n  // Generate the index name\n  var indexName = typeof options.name === 'string' ? options.name : indexParameters.name;\n  var selector = {\n    ns: db.databaseName + '.' + name,\n    key: fieldHash,\n    name: indexName\n  };\n\n  // Ensure we have a correct finalUnique\n  var finalUnique = options == null || 'object' === typeof options ? false : options;\n  // Set up options\n  options = options == null || typeof options === 'boolean' ? {} : options;\n\n  // Add all the options\n  var keysToOmit = Object.keys(selector);\n  for (var optionName in options) {\n    if (keysToOmit.indexOf(optionName) === -1) {\n      selector[optionName] = options[optionName];\n    }\n  }\n\n  if (selector['unique'] == null) selector['unique'] = finalUnique;\n\n  // Remove any write concern operations\n  var removeKeys = ['w', 'wtimeout', 'j', 'fsync', 'readPreference'];\n  for (var i = 0; i < removeKeys.length; i++) {\n    delete selector[removeKeys[i]];\n  }\n\n  // Return the command creation selector\n  return selector;\n};\n\nvar createIndexUsingCreateIndexes = function(self, name, fieldOrSpec, options, callback) {\n  // Build the index\n  var indexParameters = parseIndexOptions(fieldOrSpec);\n  // Generate the index name\n  var indexName = typeof options.name === 'string' ? options.name : indexParameters.name;\n  // Set up the index\n  var indexes = [{ name: indexName, key: indexParameters.fieldHash }];\n  // merge all the options\n  var keysToOmit = Object.keys(indexes[0]).concat([\n    'w',\n    'wtimeout',\n    'j',\n    'fsync',\n    'readPreference',\n    'session'\n  ]);\n\n  for (var optionName in options) {\n    if (keysToOmit.indexOf(optionName) === -1) {\n      indexes[0][optionName] = options[optionName];\n    }\n  }\n\n  // Get capabilities\n  var capabilities = self.s.topology.capabilities();\n\n  // Did the user pass in a collation, check if our write server supports it\n  if (indexes[0].collation && capabilities && !capabilities.commandsTakeCollation) {\n    // Create a new error\n    var error = new MongoError(f('server/primary/mongos does not support collation'));\n    error.code = 67;\n    // Return the error\n    return callback(error);\n  }\n\n  // Create command, apply write concern to command\n  var cmd = writeConcern({ createIndexes: name, indexes: indexes }, self, options);\n\n  // Decorate command with writeConcern if supported\n  decorateWithWriteConcern(cmd, self, options);\n\n  // ReadPreference primary\n  options.readPreference = ReadPreference.PRIMARY;\n\n  // Build the command\n  self.command(cmd, options, function(err, result) {\n    if (err) return handleCallback(callback, err, null);\n    if (result.ok === 0) return handleCallback(callback, toError(result), null);\n    // Return the indexName for backward compatibility\n    handleCallback(callback, null, indexName);\n  });\n};\n\n// Validate the database name\nvar validateDatabaseName = function(databaseName) {\n  if (typeof databaseName !== 'string')\n    throw MongoError.create({ message: 'database name must be a string', driver: true });\n  if (databaseName.length === 0)\n    throw MongoError.create({ message: 'database name cannot be the empty string', driver: true });\n  if (databaseName === '$external') return;\n\n  var invalidChars = [' ', '.', '$', '/', '\\\\'];\n  for (var i = 0; i < invalidChars.length; i++) {\n    if (databaseName.indexOf(invalidChars[i]) !== -1)\n      throw MongoError.create({\n        message: \"database names cannot contain the character '\" + invalidChars[i] + \"'\",\n        driver: true\n      });\n  }\n};\n\n// Get write concern\nvar writeConcern = function(target, db, options) {\n  if (options.w != null || options.j != null || options.fsync != null) {\n    var opts = {};\n    if (options.w) opts.w = options.w;\n    if (options.wtimeout) opts.wtimeout = options.wtimeout;\n    if (options.j) opts.j = options.j;\n    if (options.fsync) opts.fsync = options.fsync;\n    target.writeConcern = opts;\n  } else if (\n    db.writeConcern.w != null ||\n    db.writeConcern.j != null ||\n    db.writeConcern.fsync != null\n  ) {\n    target.writeConcern = db.writeConcern;\n  }\n\n  return target;\n};\n\n// Add listeners to topology\nvar createListener = function(self, e, object) {\n  var listener = function(err) {\n    if (object.listeners(e).length > 0) {\n      object.emit(e, err, self);\n\n      // Emit on all associated db's if available\n      for (var i = 0; i < self.s.children.length; i++) {\n        self.s.children[i].emit(e, err, self.s.children[i]);\n      }\n    }\n  };\n  return listener;\n};\n\n/**\n * Unref all sockets\n * @method\n */\nDb.prototype.unref = function() {\n  this.s.topology.unref();\n};\n\n/**\n * Db close event\n *\n * Emitted after a socket closed against a single server or mongos proxy.\n *\n * @event Db#close\n * @type {MongoError}\n */\n\n/**\n * Db reconnect event\n *\n *  * Server: Emitted when the driver has reconnected and re-authenticated.\n *  * ReplicaSet: N/A\n *  * Mongos: Emitted when the driver reconnects and re-authenticates successfully against a Mongos.\n *\n * @event Db#reconnect\n * @type {object}\n */\n\n/**\n * Db error event\n *\n * Emitted after an error occurred against a single server or mongos proxy.\n *\n * @event Db#error\n * @type {MongoError}\n */\n\n/**\n * Db timeout event\n *\n * Emitted after a socket timeout occurred against a single server or mongos proxy.\n *\n * @event Db#timeout\n * @type {MongoError}\n */\n\n/**\n * Db parseError event\n *\n * The parseError event is emitted if the driver detects illegal or corrupt BSON being received from the server.\n *\n * @event Db#parseError\n * @type {MongoError}\n */\n\n/**\n * Db fullsetup event, emitted when all servers in the topology have been connected to at start up time.\n *\n * * Server: Emitted when the driver has connected to the single server and has authenticated.\n * * ReplSet: Emitted after the driver has attempted to connect to all replicaset members.\n * * Mongos: Emitted after the driver has attempted to connect to all mongos proxies.\n *\n * @event Db#fullsetup\n * @type {Db}\n */\n\n// Constants\nDb.SYSTEM_NAMESPACE_COLLECTION = 'system.namespaces';\nDb.SYSTEM_INDEX_COLLECTION = 'system.indexes';\nDb.SYSTEM_PROFILE_COLLECTION = 'system.profile';\nDb.SYSTEM_USER_COLLECTION = 'system.users';\nDb.SYSTEM_COMMAND_COLLECTION = '$cmd';\nDb.SYSTEM_JS_COLLECTION = 'system.js';\n\nmodule.exports = Db;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/db.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/gridfs-stream/download.js":
/*!************************************************************!*\
  !*** ./node_modules/mongoDb/lib/gridfs-stream/download.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(Buffer) {\n\nvar stream = __webpack_require__(/*! stream */ \"stream\"),\n  util = __webpack_require__(/*! util */ \"util\");\n\nmodule.exports = GridFSBucketReadStream;\n\n/**\n * A readable stream that enables you to read buffers from GridFS.\n *\n * Do not instantiate this class directly. Use `openDownloadStream()` instead.\n *\n * @class\n * @param {Collection} chunks Handle for chunks collection\n * @param {Collection} files Handle for files collection\n * @param {Object} readPreference The read preference to use\n * @param {Object} filter The query to use to find the file document\n * @param {Object} [options=null] Optional settings.\n * @param {Number} [options.sort=null] Optional sort for the file find query\n * @param {Number} [options.skip=null] Optional skip for the file find query\n * @param {Number} [options.start=null] Optional 0-based offset in bytes to start streaming from\n * @param {Number} [options.end=null] Optional 0-based offset in bytes to stop streaming before\n * @fires GridFSBucketReadStream#error\n * @fires GridFSBucketReadStream#file\n * @return {GridFSBucketReadStream} a GridFSBucketReadStream instance.\n */\n\nfunction GridFSBucketReadStream(chunks, files, readPreference, filter, options) {\n  this.s = {\n    bytesRead: 0,\n    chunks: chunks,\n    cursor: null,\n    expected: 0,\n    files: files,\n    filter: filter,\n    init: false,\n    expectedEnd: 0,\n    file: null,\n    options: options,\n    readPreference: readPreference\n  };\n\n  stream.Readable.call(this);\n}\n\nutil.inherits(GridFSBucketReadStream, stream.Readable);\n\n/**\n * An error occurred\n *\n * @event GridFSBucketReadStream#error\n * @type {Error}\n */\n\n/**\n * Fires when the stream loaded the file document corresponding to the\n * provided id.\n *\n * @event GridFSBucketReadStream#file\n * @type {object}\n */\n\n/**\n * Emitted when a chunk of data is available to be consumed.\n *\n * @event GridFSBucketReadStream#data\n * @type {object}\n */\n\n/**\n * Fired when the stream is exhausted (no more data events).\n *\n * @event GridFSBucketReadStream#end\n * @type {object}\n */\n\n/**\n * Fired when the stream is exhausted and the underlying cursor is killed\n *\n * @event GridFSBucketReadStream#close\n * @type {object}\n */\n\n/**\n * Reads from the cursor and pushes to the stream.\n * @method\n */\n\nGridFSBucketReadStream.prototype._read = function() {\n  var _this = this;\n  if (this.destroyed) {\n    return;\n  }\n\n  waitForFile(_this, function() {\n    doRead(_this);\n  });\n};\n\n/**\n * Sets the 0-based offset in bytes to start streaming from. Throws\n * an error if this stream has entered flowing mode\n * (e.g. if you've already called `on('data')`)\n * @method\n * @param {Number} start Offset in bytes to start reading at\n * @return {GridFSBucketReadStream}\n */\n\nGridFSBucketReadStream.prototype.start = function(start) {\n  throwIfInitialized(this);\n  this.s.options.start = start;\n  return this;\n};\n\n/**\n * Sets the 0-based offset in bytes to start streaming from. Throws\n * an error if this stream has entered flowing mode\n * (e.g. if you've already called `on('data')`)\n * @method\n * @param {Number} end Offset in bytes to stop reading at\n * @return {GridFSBucketReadStream}\n */\n\nGridFSBucketReadStream.prototype.end = function(end) {\n  throwIfInitialized(this);\n  this.s.options.end = end;\n  return this;\n};\n\n/**\n * Marks this stream as aborted (will never push another `data` event)\n * and kills the underlying cursor. Will emit the 'end' event, and then\n * the 'close' event once the cursor is successfully killed.\n *\n * @method\n * @param {GridFSBucket~errorCallback} [callback] called when the cursor is successfully closed or an error occurred.\n * @fires GridFSBucketWriteStream#close\n * @fires GridFSBucketWriteStream#end\n */\n\nGridFSBucketReadStream.prototype.abort = function(callback) {\n  var _this = this;\n  this.push(null);\n  this.destroyed = true;\n  if (this.s.cursor) {\n    this.s.cursor.close(function(error) {\n      _this.emit('close');\n      callback && callback(error);\n    });\n  } else {\n    if (!this.s.init) {\n      // If not initialized, fire close event because we will never\n      // get a cursor\n      _this.emit('close');\n    }\n    callback && callback();\n  }\n};\n\n/**\n * @ignore\n */\n\nfunction throwIfInitialized(self) {\n  if (self.s.init) {\n    throw new Error('You cannot change options after the stream has entered' + 'flowing mode!');\n  }\n}\n\n/**\n * @ignore\n */\n\nfunction doRead(_this) {\n  if (_this.destroyed) {\n    return;\n  }\n\n  _this.s.cursor.next(function(error, doc) {\n    if (_this.destroyed) {\n      return;\n    }\n    if (error) {\n      return __handleError(_this, error);\n    }\n    if (!doc) {\n      _this.push(null);\n      return _this.s.cursor.close(function(error) {\n        if (error) {\n          return __handleError(_this, error);\n        }\n        _this.emit('close');\n      });\n    }\n\n    var bytesRemaining = _this.s.file.length - _this.s.bytesRead;\n    var expectedN = _this.s.expected++;\n    var expectedLength = Math.min(_this.s.file.chunkSize, bytesRemaining);\n\n    if (doc.n > expectedN) {\n      var errmsg = 'ChunkIsMissing: Got unexpected n: ' + doc.n + ', expected: ' + expectedN;\n      return __handleError(_this, new Error(errmsg));\n    }\n\n    if (doc.n < expectedN) {\n      errmsg = 'ExtraChunk: Got unexpected n: ' + doc.n + ', expected: ' + expectedN;\n      return __handleError(_this, new Error(errmsg));\n    }\n\n    var buf = Buffer.isBuffer(doc.data) ? doc.data : doc.data.buffer;\n\n    if (buf.length !== expectedLength) {\n      if (bytesRemaining <= 0) {\n        errmsg = 'ExtraChunk: Got unexpected n: ' + doc.n;\n        return __handleError(_this, new Error(errmsg));\n      }\n\n      errmsg =\n        'ChunkIsWrongSize: Got unexpected length: ' + buf.length + ', expected: ' + expectedLength;\n      return __handleError(_this, new Error(errmsg));\n    }\n\n    _this.s.bytesRead += buf.length;\n\n    if (buf.length === 0) {\n      return _this.push(null);\n    }\n\n    var sliceStart = null;\n    var sliceEnd = null;\n\n    if (_this.s.bytesToSkip != null) {\n      sliceStart = _this.s.bytesToSkip;\n      _this.s.bytesToSkip = 0;\n    }\n\n    if (expectedN === _this.s.expectedEnd && _this.s.bytesToTrim != null) {\n      sliceEnd = _this.s.bytesToTrim;\n    }\n\n    // If the remaining amount of data left is < chunkSize read the right amount of data\n    if (_this.s.options.end && _this.s.options.end - _this.s.bytesToSkip < buf.length) {\n      sliceEnd = _this.s.options.end - _this.s.bytesToSkip;\n    }\n\n    if (sliceStart != null || sliceEnd != null) {\n      buf = buf.slice(sliceStart || 0, sliceEnd || buf.length);\n    }\n\n    _this.push(buf);\n  });\n}\n\n/**\n * @ignore\n */\n\nfunction init(self) {\n  var findOneOptions = {};\n  if (self.s.readPreference) {\n    findOneOptions.readPreference = self.s.readPreference;\n  }\n  if (self.s.options && self.s.options.sort) {\n    findOneOptions.sort = self.s.options.sort;\n  }\n  if (self.s.options && self.s.options.skip) {\n    findOneOptions.skip = self.s.options.skip;\n  }\n\n  self.s.files.findOne(self.s.filter, findOneOptions, function(error, doc) {\n    if (error) {\n      return __handleError(self, error);\n    }\n    if (!doc) {\n      var identifier = self.s.filter._id ? self.s.filter._id.toString() : self.s.filter.filename;\n      var errmsg = 'FileNotFound: file ' + identifier + ' was not found';\n      var err = new Error(errmsg);\n      err.code = 'ENOENT';\n      return __handleError(self, err);\n    }\n\n    // If document is empty, kill the stream immediately and don't\n    // execute any reads\n    if (doc.length <= 0) {\n      self.push(null);\n      return;\n    }\n\n    if (self.destroyed) {\n      // If user destroys the stream before we have a cursor, wait\n      // until the query is done to say we're 'closed' because we can't\n      // cancel a query.\n      self.emit('close');\n      return;\n    }\n\n    self.s.bytesToSkip = handleStartOption(self, doc, self.s.options);\n\n    var filter = { files_id: doc._id };\n\n    // Currently (MongoDB 3.4.4) skip function does not support the index,\n    // it needs to retrieve all the documents first and then skip them. (CS-25811)\n    // As work around we use $gte on the \"n\" field.\n    if (self.s.options && self.s.options.start != null) {\n      var skip = Math.floor(self.s.options.start / doc.chunkSize);\n      if (skip > 0) {\n        filter['n'] = { $gte: skip };\n      }\n    }\n    self.s.cursor = self.s.chunks.find(filter).sort({ n: 1 });\n\n    if (self.s.readPreference) {\n      self.s.cursor.setReadPreference(self.s.readPreference);\n    }\n\n    self.s.expectedEnd = Math.ceil(doc.length / doc.chunkSize);\n    self.s.file = doc;\n    self.s.bytesToTrim = handleEndOption(self, doc, self.s.cursor, self.s.options);\n    self.emit('file', doc);\n  });\n}\n\n/**\n * @ignore\n */\n\nfunction waitForFile(_this, callback) {\n  if (_this.s.file) {\n    return callback();\n  }\n\n  if (!_this.s.init) {\n    init(_this);\n    _this.s.init = true;\n  }\n\n  _this.once('file', function() {\n    callback();\n  });\n}\n\n/**\n * @ignore\n */\n\nfunction handleStartOption(stream, doc, options) {\n  if (options && options.start != null) {\n    if (options.start > doc.length) {\n      throw new Error(\n        'Stream start (' +\n          options.start +\n          ') must not be ' +\n          'more than the length of the file (' +\n          doc.length +\n          ')'\n      );\n    }\n    if (options.start < 0) {\n      throw new Error('Stream start (' + options.start + ') must not be ' + 'negative');\n    }\n    if (options.end != null && options.end < options.start) {\n      throw new Error(\n        'Stream start (' +\n          options.start +\n          ') must not be ' +\n          'greater than stream end (' +\n          options.end +\n          ')'\n      );\n    }\n\n    stream.s.bytesRead = Math.floor(options.start / doc.chunkSize) * doc.chunkSize;\n    stream.s.expected = Math.floor(options.start / doc.chunkSize);\n\n    return options.start - stream.s.bytesRead;\n  }\n}\n\n/**\n * @ignore\n */\n\nfunction handleEndOption(stream, doc, cursor, options) {\n  if (options && options.end != null) {\n    if (options.end > doc.length) {\n      throw new Error(\n        'Stream end (' +\n          options.end +\n          ') must not be ' +\n          'more than the length of the file (' +\n          doc.length +\n          ')'\n      );\n    }\n    if (options.start < 0) {\n      throw new Error('Stream end (' + options.end + ') must not be ' + 'negative');\n    }\n\n    var start = options.start != null ? Math.floor(options.start / doc.chunkSize) : 0;\n\n    cursor.limit(Math.ceil(options.end / doc.chunkSize) - start);\n\n    stream.s.expectedEnd = Math.ceil(options.end / doc.chunkSize);\n\n    return Math.ceil(options.end / doc.chunkSize) * doc.chunkSize - options.end;\n  }\n}\n\n/**\n * @ignore\n */\n\nfunction __handleError(_this, error) {\n  _this.emit('error', error);\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/gridfs-stream/download.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/gridfs-stream/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongoDb/lib/gridfs-stream/index.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar Emitter = __webpack_require__(/*! events */ \"events\").EventEmitter;\nvar GridFSBucketReadStream = __webpack_require__(/*! ./download */ \"./node_modules/mongoDb/lib/gridfs-stream/download.js\");\nvar GridFSBucketWriteStream = __webpack_require__(/*! ./upload */ \"./node_modules/mongoDb/lib/gridfs-stream/upload.js\");\nvar shallowClone = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").shallowClone;\nvar toError = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").toError;\nvar util = __webpack_require__(/*! util */ \"util\");\nvar executeOperation = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation;\n\nvar DEFAULT_GRIDFS_BUCKET_OPTIONS = {\n  bucketName: 'fs',\n  chunkSizeBytes: 255 * 1024\n};\n\nmodule.exports = GridFSBucket;\n\n/**\n * Constructor for a streaming GridFS interface\n * @class\n * @param {Db} db A db handle\n * @param {object} [options=null] Optional settings.\n * @param {string} [options.bucketName=\"fs\"] The 'files' and 'chunks' collections will be prefixed with the bucket name followed by a dot.\n * @param {number} [options.chunkSizeBytes=255 * 1024] Number of bytes stored in each chunk. Defaults to 255KB\n * @param {object} [options.writeConcern=null] Optional write concern to be passed to write operations, for instance `{ w: 1 }`\n * @param {object} [options.readPreference=null] Optional read preference to be passed to read operations\n * @fires GridFSBucketWriteStream#index\n * @return {GridFSBucket}\n */\n\nfunction GridFSBucket(db, options) {\n  Emitter.apply(this);\n  this.setMaxListeners(0);\n\n  if (options && typeof options === 'object') {\n    options = shallowClone(options);\n    var keys = Object.keys(DEFAULT_GRIDFS_BUCKET_OPTIONS);\n    for (var i = 0; i < keys.length; ++i) {\n      if (!options[keys[i]]) {\n        options[keys[i]] = DEFAULT_GRIDFS_BUCKET_OPTIONS[keys[i]];\n      }\n    }\n  } else {\n    options = DEFAULT_GRIDFS_BUCKET_OPTIONS;\n  }\n\n  this.s = {\n    db: db,\n    options: options,\n    _chunksCollection: db.collection(options.bucketName + '.chunks'),\n    _filesCollection: db.collection(options.bucketName + '.files'),\n    checkedIndexes: false,\n    calledOpenUploadStream: false,\n    promiseLibrary: db.s.promiseLibrary || Promise\n  };\n}\n\nutil.inherits(GridFSBucket, Emitter);\n\n/**\n * When the first call to openUploadStream is made, the upload stream will\n * check to see if it needs to create the proper indexes on the chunks and\n * files collections. This event is fired either when 1) it determines that\n * no index creation is necessary, 2) when it successfully creates the\n * necessary indexes.\n *\n * @event GridFSBucket#index\n * @type {Error}\n */\n\n/**\n * Returns a writable stream (GridFSBucketWriteStream) for writing\n * buffers to GridFS. The stream's 'id' property contains the resulting\n * file's id.\n * @method\n * @param {string} filename The value of the 'filename' key in the files doc\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.chunkSizeBytes=null] Optional overwrite this bucket's chunkSizeBytes for this file\n * @param {object} [options.metadata=null] Optional object to store in the file document's `metadata` field\n * @param {string} [options.contentType=null] Optional string to store in the file document's `contentType` field\n * @param {array} [options.aliases=null] Optional array of strings to store in the file document's `aliases` field\n * @return {GridFSBucketWriteStream}\n */\n\nGridFSBucket.prototype.openUploadStream = function(filename, options) {\n  if (options) {\n    options = shallowClone(options);\n  } else {\n    options = {};\n  }\n  if (!options.chunkSizeBytes) {\n    options.chunkSizeBytes = this.s.options.chunkSizeBytes;\n  }\n  return new GridFSBucketWriteStream(this, filename, options);\n};\n\n/**\n * Returns a writable stream (GridFSBucketWriteStream) for writing\n * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n * file's id.\n * @method\n * @param {string|number|object} id A custom id used to identify the file\n * @param {string} filename The value of the 'filename' key in the files doc\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.chunkSizeBytes=null] Optional overwrite this bucket's chunkSizeBytes for this file\n * @param {object} [options.metadata=null] Optional object to store in the file document's `metadata` field\n * @param {string} [options.contentType=null] Optional string to store in the file document's `contentType` field\n * @param {array} [options.aliases=null] Optional array of strings to store in the file document's `aliases` field\n * @return {GridFSBucketWriteStream}\n */\n\nGridFSBucket.prototype.openUploadStreamWithId = function(id, filename, options) {\n  if (options) {\n    options = shallowClone(options);\n  } else {\n    options = {};\n  }\n\n  if (!options.chunkSizeBytes) {\n    options.chunkSizeBytes = this.s.options.chunkSizeBytes;\n  }\n\n  options.id = id;\n\n  return new GridFSBucketWriteStream(this, filename, options);\n};\n\n/**\n * Returns a readable stream (GridFSBucketReadStream) for streaming file\n * data from GridFS.\n * @method\n * @param {ObjectId} id The id of the file doc\n * @param {Object} [options=null] Optional settings.\n * @param {Number} [options.start=null] Optional 0-based offset in bytes to start streaming from\n * @param {Number} [options.end=null] Optional 0-based offset in bytes to stop streaming before\n * @return {GridFSBucketReadStream}\n */\n\nGridFSBucket.prototype.openDownloadStream = function(id, options) {\n  var filter = { _id: id };\n  options = {\n    start: options && options.start,\n    end: options && options.end\n  };\n\n  return new GridFSBucketReadStream(\n    this.s._chunksCollection,\n    this.s._filesCollection,\n    this.s.options.readPreference,\n    filter,\n    options\n  );\n};\n\n/**\n * Deletes a file with the given id\n * @method\n * @param {ObjectId} id The id of the file doc\n * @param {GridFSBucket~errorCallback} [callback]\n */\n\nGridFSBucket.prototype.delete = function(id, callback) {\n  return executeOperation(this.s.db.s.topology, _delete, [this, id, callback], {\n    skipSessions: true\n  });\n};\n\n/**\n * @ignore\n */\n\nfunction _delete(_this, id, callback) {\n  _this.s._filesCollection.deleteOne({ _id: id }, function(error, res) {\n    if (error) {\n      return callback(error);\n    }\n\n    _this.s._chunksCollection.deleteMany({ files_id: id }, function(error) {\n      if (error) {\n        return callback(error);\n      }\n\n      // Delete orphaned chunks before returning FileNotFound\n      if (!res.result.n) {\n        var errmsg = 'FileNotFound: no file with id ' + id + ' found';\n        return callback(new Error(errmsg));\n      }\n\n      callback();\n    });\n  });\n}\n\n/**\n * Convenience wrapper around find on the files collection\n * @method\n * @param {Object} filter\n * @param {Object} [options=null] Optional settings for cursor\n * @param {number} [options.batchSize=null] Optional batch size for cursor\n * @param {number} [options.limit=null] Optional limit for cursor\n * @param {number} [options.maxTimeMS=null] Optional maxTimeMS for cursor\n * @param {boolean} [options.noCursorTimeout=null] Optionally set cursor's `noCursorTimeout` flag\n * @param {number} [options.skip=null] Optional skip for cursor\n * @param {object} [options.sort=null] Optional sort for cursor\n * @return {Cursor}\n */\n\nGridFSBucket.prototype.find = function(filter, options) {\n  filter = filter || {};\n  options = options || {};\n\n  var cursor = this.s._filesCollection.find(filter);\n\n  if (options.batchSize != null) {\n    cursor.batchSize(options.batchSize);\n  }\n  if (options.limit != null) {\n    cursor.limit(options.limit);\n  }\n  if (options.maxTimeMS != null) {\n    cursor.maxTimeMS(options.maxTimeMS);\n  }\n  if (options.noCursorTimeout != null) {\n    cursor.addCursorFlag('noCursorTimeout', options.noCursorTimeout);\n  }\n  if (options.skip != null) {\n    cursor.skip(options.skip);\n  }\n  if (options.sort != null) {\n    cursor.sort(options.sort);\n  }\n\n  return cursor;\n};\n\n/**\n * Returns a readable stream (GridFSBucketReadStream) for streaming the\n * file with the given name from GridFS. If there are multiple files with\n * the same name, this will stream the most recent file with the given name\n * (as determined by the `uploadDate` field). You can set the `revision`\n * option to change this behavior.\n * @method\n * @param {String} filename The name of the file to stream\n * @param {Object} [options=null] Optional settings\n * @param {number} [options.revision=-1] The revision number relative to the oldest file with the given filename. 0 gets you the oldest file, 1 gets you the 2nd oldest, -1 gets you the newest.\n * @param {Number} [options.start=null] Optional 0-based offset in bytes to start streaming from\n * @param {Number} [options.end=null] Optional 0-based offset in bytes to stop streaming before\n * @return {GridFSBucketReadStream}\n */\n\nGridFSBucket.prototype.openDownloadStreamByName = function(filename, options) {\n  var sort = { uploadDate: -1 };\n  var skip = null;\n  if (options && options.revision != null) {\n    if (options.revision >= 0) {\n      sort = { uploadDate: 1 };\n      skip = options.revision;\n    } else {\n      skip = -options.revision - 1;\n    }\n  }\n\n  var filter = { filename: filename };\n  options = {\n    sort: sort,\n    skip: skip,\n    start: options && options.start,\n    end: options && options.end\n  };\n  return new GridFSBucketReadStream(\n    this.s._chunksCollection,\n    this.s._filesCollection,\n    this.s.options.readPreference,\n    filter,\n    options\n  );\n};\n\n/**\n * Renames the file with the given _id to the given string\n * @method\n * @param {ObjectId} id the id of the file to rename\n * @param {String} filename new name for the file\n * @param {GridFSBucket~errorCallback} [callback]\n */\n\nGridFSBucket.prototype.rename = function(id, filename, callback) {\n  return executeOperation(this.s.db.s.topology, _rename, [this, id, filename, callback], {\n    skipSessions: true\n  });\n};\n\n/**\n * @ignore\n */\n\nfunction _rename(_this, id, filename, callback) {\n  var filter = { _id: id };\n  var update = { $set: { filename: filename } };\n  _this.s._filesCollection.updateOne(filter, update, function(error, res) {\n    if (error) {\n      return callback(error);\n    }\n    if (!res.result.n) {\n      return callback(toError('File with id ' + id + ' not found'));\n    }\n    callback();\n  });\n}\n\n/**\n * Removes this bucket's files collection, followed by its chunks collection.\n * @method\n * @param {GridFSBucket~errorCallback} [callback]\n */\n\nGridFSBucket.prototype.drop = function(callback) {\n  return executeOperation(this.s.db.s.topology, _drop, [this, callback], {\n    skipSessions: true\n  });\n};\n\n/**\n * @ignore\n */\n\nfunction _drop(_this, callback) {\n  _this.s._filesCollection.drop(function(error) {\n    if (error) {\n      return callback(error);\n    }\n    _this.s._chunksCollection.drop(function(error) {\n      if (error) {\n        return callback(error);\n      }\n\n      return callback();\n    });\n  });\n}\n\n/**\n * Callback format for all GridFSBucket methods that can accept a callback.\n * @callback GridFSBucket~errorCallback\n * @param {MongoError} error An error instance representing any errors that occurred\n */\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/gridfs-stream/index.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/gridfs-stream/upload.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongoDb/lib/gridfs-stream/upload.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(Buffer) {\n\nvar core = __webpack_require__(/*! mongodb-core */ \"mongodb-core\");\nvar crypto = __webpack_require__(/*! crypto */ \"crypto\");\nvar stream = __webpack_require__(/*! stream */ \"stream\");\nvar util = __webpack_require__(/*! util */ \"util\");\n\nvar ERROR_NAMESPACE_NOT_FOUND = 26;\n\nmodule.exports = GridFSBucketWriteStream;\n\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n *\n * @class\n * @param {GridFSBucket} bucket Handle for this stream's corresponding bucket\n * @param {string} filename The value of the 'filename' key in the files doc\n * @param {object} [options=null] Optional settings.\n * @param {string|number|object} [options.id=null] Custom file id for the GridFS file.\n * @param {number} [options.chunkSizeBytes=null] The chunk size to use, in bytes\n * @param {number} [options.w=null] The write concern\n * @param {number} [options.wtimeout=null] The write concern timeout\n * @param {number} [options.j=null] The journal write concern\n * @fires GridFSBucketWriteStream#error\n * @fires GridFSBucketWriteStream#finish\n * @return {GridFSBucketWriteStream} a GridFSBucketWriteStream instance.\n */\n\nfunction GridFSBucketWriteStream(bucket, filename, options) {\n  options = options || {};\n  this.bucket = bucket;\n  this.chunks = bucket.s._chunksCollection;\n  this.filename = filename;\n  this.files = bucket.s._filesCollection;\n  this.options = options;\n  // Signals the write is all done\n  this.done = false;\n\n  this.id = options.id ? options.id : core.BSON.ObjectId();\n  this.chunkSizeBytes = this.options.chunkSizeBytes;\n  this.bufToStore = new Buffer(this.chunkSizeBytes);\n  this.length = 0;\n  this.md5 = crypto.createHash('md5');\n  this.n = 0;\n  this.pos = 0;\n  this.state = {\n    streamEnd: false,\n    outstandingRequests: 0,\n    errored: false,\n    aborted: false,\n    promiseLibrary: this.bucket.s.promiseLibrary\n  };\n\n  if (!this.bucket.s.calledOpenUploadStream) {\n    this.bucket.s.calledOpenUploadStream = true;\n\n    var _this = this;\n    checkIndexes(this, function() {\n      _this.bucket.s.checkedIndexes = true;\n      _this.bucket.emit('index');\n    });\n  }\n}\n\nutil.inherits(GridFSBucketWriteStream, stream.Writable);\n\n/**\n * An error occurred\n *\n * @event GridFSBucketWriteStream#error\n * @type {Error}\n */\n\n/**\n * `end()` was called and the write stream successfully wrote the file\n * metadata and all the chunks to MongoDB.\n *\n * @event GridFSBucketWriteStream#finish\n * @type {object}\n */\n\n/**\n * Write a buffer to the stream.\n *\n * @method\n * @param {Buffer} chunk Buffer to write\n * @param {String} encoding Optional encoding for the buffer\n * @param {Function} callback Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n * @return {Boolean} False if this write required flushing a chunk to MongoDB. True otherwise.\n */\n\nGridFSBucketWriteStream.prototype.write = function(chunk, encoding, callback) {\n  var _this = this;\n  return waitForIndexes(this, function() {\n    return doWrite(_this, chunk, encoding, callback);\n  });\n};\n\n/**\n * Places this write stream into an aborted state (all future writes fail)\n * and deletes all chunks that have already been written.\n *\n * @method\n * @param {GridFSBucket~errorCallback} callback called when chunks are successfully removed or error occurred\n * @return {Promise} if no callback specified\n */\n\nGridFSBucketWriteStream.prototype.abort = function(callback) {\n  if (this.state.streamEnd) {\n    var error = new Error('Cannot abort a stream that has already completed');\n    if (typeof callback === 'function') {\n      return callback(error);\n    }\n    return this.state.promiseLibrary.reject(error);\n  }\n  if (this.state.aborted) {\n    error = new Error('Cannot call abort() on a stream twice');\n    if (typeof callback === 'function') {\n      return callback(error);\n    }\n    return this.state.promiseLibrary.reject(error);\n  }\n  this.state.aborted = true;\n  this.chunks.deleteMany({ files_id: this.id }, function(error) {\n    if (typeof callback === 'function') callback(error);\n  });\n};\n\n/**\n * Tells the stream that no more data will be coming in. The stream will\n * persist the remaining data to MongoDB, write the files document, and\n * then emit a 'finish' event.\n *\n * @method\n * @param {Buffer} chunk Buffer to write\n * @param {String} encoding Optional encoding for the buffer\n * @param {Function} callback Function to call when all files and chunks have been persisted to MongoDB\n */\n\nGridFSBucketWriteStream.prototype.end = function(chunk, encoding, callback) {\n  var _this = this;\n  if (typeof chunk === 'function') {\n    (callback = chunk), (chunk = null), (encoding = null);\n  } else if (typeof encoding === 'function') {\n    (callback = encoding), (encoding = null);\n  }\n\n  if (checkAborted(this, callback)) {\n    return;\n  }\n  this.state.streamEnd = true;\n\n  if (callback) {\n    this.once('finish', function(result) {\n      callback(null, result);\n    });\n  }\n\n  if (!chunk) {\n    waitForIndexes(this, function() {\n      writeRemnant(_this);\n    });\n    return;\n  }\n\n  this.write(chunk, encoding, function() {\n    writeRemnant(_this);\n  });\n};\n\n/**\n * @ignore\n */\n\nfunction __handleError(_this, error, callback) {\n  if (_this.state.errored) {\n    return;\n  }\n  _this.state.errored = true;\n  if (callback) {\n    return callback(error);\n  }\n  _this.emit('error', error);\n}\n\n/**\n * @ignore\n */\n\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: core.BSON.ObjectId(),\n    files_id: filesId,\n    n: n,\n    data: data\n  };\n}\n\n/**\n * @ignore\n */\n\nfunction checkChunksIndex(_this, callback) {\n  _this.chunks.listIndexes().toArray(function(error, indexes) {\n    if (error) {\n      // Collection doesn't exist so create index\n      if (error.code === ERROR_NAMESPACE_NOT_FOUND) {\n        var index = { files_id: 1, n: 1 };\n        _this.chunks.createIndex(index, { background: false, unique: true }, function(error) {\n          if (error) {\n            return callback(error);\n          }\n\n          callback();\n        });\n        return;\n      }\n      return callback(error);\n    }\n\n    var hasChunksIndex = false;\n    indexes.forEach(function(index) {\n      if (index.key) {\n        var keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n          hasChunksIndex = true;\n        }\n      }\n    });\n\n    if (hasChunksIndex) {\n      callback();\n    } else {\n      index = { files_id: 1, n: 1 };\n      var indexOptions = getWriteOptions(_this);\n\n      indexOptions.background = false;\n      indexOptions.unique = true;\n\n      _this.chunks.createIndex(index, indexOptions, function(error) {\n        if (error) {\n          return callback(error);\n        }\n\n        callback();\n      });\n    }\n  });\n}\n\n/**\n * @ignore\n */\n\nfunction checkDone(_this, callback) {\n  if (_this.done) return true;\n  if (_this.state.streamEnd && _this.state.outstandingRequests === 0 && !_this.state.errored) {\n    // Set done so we dont' trigger duplicate createFilesDoc\n    _this.done = true;\n    // Create a new files doc\n    var filesDoc = createFilesDoc(\n      _this.id,\n      _this.length,\n      _this.chunkSizeBytes,\n      _this.md5.digest('hex'),\n      _this.filename,\n      _this.options.contentType,\n      _this.options.aliases,\n      _this.options.metadata\n    );\n\n    if (checkAborted(_this, callback)) {\n      return false;\n    }\n\n    _this.files.insert(filesDoc, getWriteOptions(_this), function(error) {\n      if (error) {\n        return __handleError(_this, error, callback);\n      }\n      _this.emit('finish', filesDoc);\n    });\n\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * @ignore\n */\n\nfunction checkIndexes(_this, callback) {\n  _this.files.findOne({}, { _id: 1 }, function(error, doc) {\n    if (error) {\n      return callback(error);\n    }\n    if (doc) {\n      return callback();\n    }\n\n    _this.files.listIndexes().toArray(function(error, indexes) {\n      if (error) {\n        // Collection doesn't exist so create index\n        if (error.code === ERROR_NAMESPACE_NOT_FOUND) {\n          var index = { filename: 1, uploadDate: 1 };\n          _this.files.createIndex(index, { background: false }, function(error) {\n            if (error) {\n              return callback(error);\n            }\n\n            checkChunksIndex(_this, callback);\n          });\n          return;\n        }\n        return callback(error);\n      }\n\n      var hasFileIndex = false;\n      indexes.forEach(function(index) {\n        var keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n          hasFileIndex = true;\n        }\n      });\n\n      if (hasFileIndex) {\n        checkChunksIndex(_this, callback);\n      } else {\n        index = { filename: 1, uploadDate: 1 };\n\n        var indexOptions = getWriteOptions(_this);\n\n        indexOptions.background = false;\n\n        _this.files.createIndex(index, indexOptions, function(error) {\n          if (error) {\n            return callback(error);\n          }\n\n          checkChunksIndex(_this, callback);\n        });\n      }\n    });\n  });\n}\n\n/**\n * @ignore\n */\n\nfunction createFilesDoc(_id, length, chunkSize, md5, filename, contentType, aliases, metadata) {\n  var ret = {\n    _id: _id,\n    length: length,\n    chunkSize: chunkSize,\n    uploadDate: new Date(),\n    md5: md5,\n    filename: filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\n/**\n * @ignore\n */\n\nfunction doWrite(_this, chunk, encoding, callback) {\n  if (checkAborted(_this, callback)) {\n    return false;\n  }\n\n  var inputBuf = Buffer.isBuffer(chunk) ? chunk : new Buffer(chunk, encoding);\n\n  _this.length += inputBuf.length;\n\n  // Input is small enough to fit in our buffer\n  if (_this.pos + inputBuf.length < _this.chunkSizeBytes) {\n    inputBuf.copy(_this.bufToStore, _this.pos);\n    _this.pos += inputBuf.length;\n\n    callback && callback();\n\n    // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n    return true;\n  }\n\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  var inputBufRemaining = inputBuf.length;\n  var spaceRemaining = _this.chunkSizeBytes - _this.pos;\n  var numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  var outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    var inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(_this.bufToStore, _this.pos, inputBufPos, inputBufPos + numToCopy);\n    _this.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    if (spaceRemaining === 0) {\n      _this.md5.update(_this.bufToStore);\n      var doc = createChunkDoc(_this.id, _this.n, _this.bufToStore);\n      ++_this.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (checkAborted(_this, callback)) {\n        return false;\n      }\n\n      _this.chunks.insert(doc, getWriteOptions(_this), function(error) {\n        if (error) {\n          return __handleError(_this, error);\n        }\n        --_this.state.outstandingRequests;\n        --outstandingRequests;\n\n        if (!outstandingRequests) {\n          _this.emit('drain', doc);\n          callback && callback();\n          checkDone(_this);\n        }\n      });\n\n      spaceRemaining = _this.chunkSizeBytes;\n      _this.pos = 0;\n      ++_this.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n\n  // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n  return false;\n}\n\n/**\n * @ignore\n */\n\nfunction getWriteOptions(_this) {\n  var obj = {};\n  if (_this.options.writeConcern) {\n    obj.w = _this.options.writeConcern.w;\n    obj.wtimeout = _this.options.writeConcern.wtimeout;\n    obj.j = _this.options.writeConcern.j;\n  }\n  return obj;\n}\n\n/**\n * @ignore\n */\n\nfunction waitForIndexes(_this, callback) {\n  if (_this.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n\n  _this.bucket.once('index', function() {\n    callback(true);\n  });\n\n  return true;\n}\n\n/**\n * @ignore\n */\n\nfunction writeRemnant(_this, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (_this.pos === 0) {\n    return checkDone(_this, callback);\n  }\n\n  ++_this.state.outstandingRequests;\n\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  var remnant = new Buffer(_this.pos);\n  _this.bufToStore.copy(remnant, 0, 0, _this.pos);\n  _this.md5.update(remnant);\n  var doc = createChunkDoc(_this.id, _this.n, remnant);\n\n  // If the stream was aborted, do not write remnant\n  if (checkAborted(_this, callback)) {\n    return false;\n  }\n\n  _this.chunks.insert(doc, getWriteOptions(_this), function(error) {\n    if (error) {\n      return __handleError(_this, error);\n    }\n    --_this.state.outstandingRequests;\n    checkDone(_this);\n  });\n}\n\n/**\n * @ignore\n */\n\nfunction checkAborted(_this, callback) {\n  if (_this.state.aborted) {\n    if (typeof callback === 'function') {\n      callback(new Error('this stream has been aborted'));\n    }\n    return true;\n  }\n  return false;\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/gridfs-stream/upload.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/gridfs/chunk.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoDb/lib/gridfs/chunk.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(Buffer) {\n\nvar Binary = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.Binary,\n  ObjectID = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.ObjectID;\n\n/**\n * Class for representing a single chunk in GridFS.\n *\n * @class\n *\n * @param file {GridStore} The {@link GridStore} object holding this chunk.\n * @param mongoObject {object} The mongo object representation of this chunk.\n *\n * @throws Error when the type of data field for {@link mongoObject} is not\n *     supported. Currently supported types for data field are instances of\n *     {@link String}, {@link Array}, {@link Binary} and {@link Binary}\n *     from the bson module\n *\n * @see Chunk#buildMongoObject\n */\nvar Chunk = function(file, mongoObject, writeConcern) {\n  if (!(this instanceof Chunk)) return new Chunk(file, mongoObject);\n\n  this.file = file;\n  var mongoObjectFinal = mongoObject == null ? {} : mongoObject;\n  this.writeConcern = writeConcern || { w: 1 };\n  this.objectId = mongoObjectFinal._id == null ? new ObjectID() : mongoObjectFinal._id;\n  this.chunkNumber = mongoObjectFinal.n == null ? 0 : mongoObjectFinal.n;\n  this.data = new Binary();\n\n  if (typeof mongoObjectFinal.data === 'string') {\n    var buffer = new Buffer(mongoObjectFinal.data.length);\n    buffer.write(mongoObjectFinal.data, 0, mongoObjectFinal.data.length, 'binary');\n    this.data = new Binary(buffer);\n  } else if (Array.isArray(mongoObjectFinal.data)) {\n    buffer = new Buffer(mongoObjectFinal.data.length);\n    var data = mongoObjectFinal.data.join('');\n    buffer.write(data, 0, data.length, 'binary');\n    this.data = new Binary(buffer);\n  } else if (mongoObjectFinal.data && mongoObjectFinal.data._bsontype === 'Binary') {\n    this.data = mongoObjectFinal.data;\n  } else if (!Buffer.isBuffer(mongoObjectFinal.data) && !(mongoObjectFinal.data == null)) {\n    throw Error('Illegal chunk format');\n  }\n\n  // Update position\n  this.internalPosition = 0;\n};\n\n/**\n * Writes a data to this object and advance the read/write head.\n *\n * @param data {string} the data to write\n * @param callback {function(*, GridStore)} This will be called after executing\n *     this method. The first parameter will contain null and the second one\n *     will contain a reference to this object.\n */\nChunk.prototype.write = function(data, callback) {\n  this.data.write(data, this.internalPosition, data.length, 'binary');\n  this.internalPosition = this.data.length();\n  if (callback != null) return callback(null, this);\n  return this;\n};\n\n/**\n * Reads data and advances the read/write head.\n *\n * @param length {number} The length of data to read.\n *\n * @return {string} The data read if the given length will not exceed the end of\n *     the chunk. Returns an empty String otherwise.\n */\nChunk.prototype.read = function(length) {\n  // Default to full read if no index defined\n  length = length == null || length === 0 ? this.length() : length;\n\n  if (this.length() - this.internalPosition + 1 >= length) {\n    var data = this.data.read(this.internalPosition, length);\n    this.internalPosition = this.internalPosition + length;\n    return data;\n  } else {\n    return '';\n  }\n};\n\nChunk.prototype.readSlice = function(length) {\n  if (this.length() - this.internalPosition >= length) {\n    var data = null;\n    if (this.data.buffer != null) {\n      //Pure BSON\n      data = this.data.buffer.slice(this.internalPosition, this.internalPosition + length);\n    } else {\n      //Native BSON\n      data = new Buffer(length);\n      length = this.data.readInto(data, this.internalPosition);\n    }\n    this.internalPosition = this.internalPosition + length;\n    return data;\n  } else {\n    return null;\n  }\n};\n\n/**\n * Checks if the read/write head is at the end.\n *\n * @return {boolean} Whether the read/write head has reached the end of this\n *     chunk.\n */\nChunk.prototype.eof = function() {\n  return this.internalPosition === this.length() ? true : false;\n};\n\n/**\n * Reads one character from the data of this chunk and advances the read/write\n * head.\n *\n * @return {string} a single character data read if the the read/write head is\n *     not at the end of the chunk. Returns an empty String otherwise.\n */\nChunk.prototype.getc = function() {\n  return this.read(1);\n};\n\n/**\n * Clears the contents of the data in this chunk and resets the read/write head\n * to the initial position.\n */\nChunk.prototype.rewind = function() {\n  this.internalPosition = 0;\n  this.data = new Binary();\n};\n\n/**\n * Saves this chunk to the database. Also overwrites existing entries having the\n * same id as this chunk.\n *\n * @param callback {function(*, GridStore)} This will be called after executing\n *     this method. The first parameter will contain null and the second one\n *     will contain a reference to this object.\n */\nChunk.prototype.save = function(options, callback) {\n  var self = this;\n  if (typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n\n  self.file.chunkCollection(function(err, collection) {\n    if (err) return callback(err);\n\n    // Merge the options\n    var writeOptions = { upsert: true };\n    for (var name in options) writeOptions[name] = options[name];\n    for (name in self.writeConcern) writeOptions[name] = self.writeConcern[name];\n\n    if (self.data.length() > 0) {\n      self.buildMongoObject(function(mongoObject) {\n        var options = { forceServerObjectId: true };\n        for (var name in self.writeConcern) {\n          options[name] = self.writeConcern[name];\n        }\n\n        collection.replaceOne({ _id: self.objectId }, mongoObject, writeOptions, function(err) {\n          callback(err, self);\n        });\n      });\n    } else {\n      callback(null, self);\n    }\n    // });\n  });\n};\n\n/**\n * Creates a mongoDB object representation of this chunk.\n *\n * @param callback {function(Object)} This will be called after executing this\n *     method. The object will be passed to the first parameter and will have\n *     the structure:\n *\n *        <pre><code>\n *        {\n *          '_id' : , // {number} id for this chunk\n *          'files_id' : , // {number} foreign key to the file collection\n *          'n' : , // {number} chunk number\n *          'data' : , // {bson#Binary} the chunk data itself\n *        }\n *        </code></pre>\n *\n * @see <a href=\"http://www.mongodb.org/display/DOCS/GridFS+Specification#GridFSSpecification-{{chunks}}\">MongoDB GridFS Chunk Object Structure</a>\n */\nChunk.prototype.buildMongoObject = function(callback) {\n  var mongoObject = {\n    files_id: this.file.fileId,\n    n: this.chunkNumber,\n    data: this.data\n  };\n  // If we are saving using a specific ObjectId\n  if (this.objectId != null) mongoObject._id = this.objectId;\n\n  callback(mongoObject);\n};\n\n/**\n * @return {number} the length of the data\n */\nChunk.prototype.length = function() {\n  return this.data.length();\n};\n\n/**\n * The position of the read/write head\n * @name position\n * @lends Chunk#\n * @field\n */\nObject.defineProperty(Chunk.prototype, 'position', {\n  enumerable: true,\n  get: function() {\n    return this.internalPosition;\n  },\n  set: function(value) {\n    this.internalPosition = value;\n  }\n});\n\n/**\n * The default chunk size\n * @constant\n */\nChunk.DEFAULT_CHUNK_SIZE = 1024 * 255;\n\nmodule.exports = Chunk;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/gridfs/chunk.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/gridfs/grid_store.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoDb/lib/gridfs/grid_store.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\n/**\n * @fileOverview GridFS is a tool for MongoDB to store files to the database.\n * Because of the restrictions of the object size the database can hold, a\n * facility to split a file into several chunks is needed. The {@link GridStore}\n * class offers a simplified api to interact with files while managing the\n * chunks of split files behind the scenes. More information about GridFS can be\n * found <a href=\"http://www.mongodb.org/display/DOCS/GridFS\">here</a>.\n *\n * @example\n * const MongoClient = require('mongodb').MongoClient;\n * const GridStore = require('mongodb').GridStore;\n * const ObjectID = require('mongodb').ObjectID;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   const db = client.db(dbName);\n *   const gridStore = new GridStore(db, null, \"w\");\n *   gridStore.open(function(err, gridStore) {\n *     gridStore.write(\"hello world!\", function(err, gridStore) {\n *       gridStore.close(function(err, result) {\n *         // Let's read the file using object Id\n *         GridStore.read(db, result._id, function(err, data) {\n *           test.equal('hello world!', data);\n *           client.close();\n *           test.done();\n *         });\n *       });\n *     });\n *   });\n * });\n */\nvar Chunk = __webpack_require__(/*! ./chunk */ \"./node_modules/mongoDb/lib/gridfs/chunk.js\"),\n  ObjectID = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").BSON.ObjectID,\n  ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference,\n  Buffer = __webpack_require__(/*! buffer */ \"buffer\").Buffer,\n  Collection = __webpack_require__(/*! ../collection */ \"./node_modules/mongoDb/lib/collection.js\"),\n  fs = __webpack_require__(/*! fs */ \"fs\"),\n  f = __webpack_require__(/*! util */ \"util\").format,\n  util = __webpack_require__(/*! util */ \"util\"),\n  Define = __webpack_require__(/*! ../metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  inherits = util.inherits,\n  Duplex = __webpack_require__(/*! stream */ \"stream\").Duplex,\n  shallowClone = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").shallowClone,\n  executeOperation = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation;\n\nvar REFERENCE_BY_FILENAME = 0,\n  REFERENCE_BY_ID = 1;\n\n/**\n * Namespace provided by the mongodb-core and node.js\n * @external Duplex\n */\n\n/**\n * Create a new GridStore instance\n *\n * Modes\n *  - **\"r\"** - read only. This is the default mode.\n *  - **\"w\"** - write in truncate mode. Existing data will be overwriten.\n *\n * @class\n * @param {Db} db A database instance to interact with.\n * @param {object} [id] optional unique id for this file\n * @param {string} [filename] optional filename for this file, no unique constrain on the field\n * @param {string} mode set the mode for this file.\n * @param {object} [options=null] Optional settings.\n * @param {(number|string)} [options.w=null] The write concern.\n * @param {number} [options.wtimeout=null] The write concern timeout.\n * @param {boolean} [options.j=false] Specify a journal write concern.\n * @param {boolean} [options.fsync=false] Specify a file sync write concern.\n * @param {string} [options.root=null] Root collection to use. Defaults to **{GridStore.DEFAULT_ROOT_COLLECTION}**.\n * @param {string} [options.content_type=null] MIME type of the file. Defaults to **{GridStore.DEFAULT_CONTENT_TYPE}**.\n * @param {number} [options.chunk_size=261120] Size for the chunk. Defaults to **{Chunk.DEFAULT_CHUNK_SIZE}**.\n * @param {object} [options.metadata=null] Arbitrary data the user wants to store.\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @property {number} chunkSize Get the gridstore chunk size.\n * @property {number} md5 The md5 checksum for this file.\n * @property {number} chunkNumber The current chunk number the gridstore has materialized into memory\n * @return {GridStore} a GridStore instance.\n * @deprecated Use GridFSBucket API instead\n */\nvar GridStore = function GridStore(db, id, filename, mode, options) {\n  if (!(this instanceof GridStore)) return new GridStore(db, id, filename, mode, options);\n  this.db = db;\n\n  // Handle options\n  if (typeof options === 'undefined') options = {};\n  // Handle mode\n  if (typeof mode === 'undefined') {\n    mode = filename;\n    filename = undefined;\n  } else if (typeof mode === 'object') {\n    options = mode;\n    mode = filename;\n    filename = undefined;\n  }\n\n  if (id && id._bsontype === 'ObjectID') {\n    this.referenceBy = REFERENCE_BY_ID;\n    this.fileId = id;\n    this.filename = filename;\n  } else if (typeof filename === 'undefined') {\n    this.referenceBy = REFERENCE_BY_FILENAME;\n    this.filename = id;\n    if (mode.indexOf('w') != null) {\n      this.fileId = new ObjectID();\n    }\n  } else {\n    this.referenceBy = REFERENCE_BY_ID;\n    this.fileId = id;\n    this.filename = filename;\n  }\n\n  // Set up the rest\n  this.mode = mode == null ? 'r' : mode;\n  this.options = options || {};\n\n  // Opened\n  this.isOpen = false;\n\n  // Set the root if overridden\n  this.root =\n    this.options['root'] == null ? GridStore.DEFAULT_ROOT_COLLECTION : this.options['root'];\n  this.position = 0;\n  this.readPreference =\n    this.options.readPreference || db.options.readPreference || ReadPreference.primary;\n  this.writeConcern = _getWriteConcern(db, this.options);\n  // Set default chunk size\n  this.internalChunkSize =\n    this.options['chunkSize'] == null ? Chunk.DEFAULT_CHUNK_SIZE : this.options['chunkSize'];\n\n  // Get the promiseLibrary\n  var promiseLibrary = this.options.promiseLibrary || Promise;\n\n  // Set the promiseLibrary\n  this.promiseLibrary = promiseLibrary;\n\n  Object.defineProperty(this, 'chunkSize', {\n    enumerable: true,\n    get: function() {\n      return this.internalChunkSize;\n    },\n    set: function(value) {\n      if (!(this.mode[0] === 'w' && this.position === 0 && this.uploadDate == null)) {\n        this.internalChunkSize = this.internalChunkSize;\n      } else {\n        this.internalChunkSize = value;\n      }\n    }\n  });\n\n  Object.defineProperty(this, 'md5', {\n    enumerable: true,\n    get: function() {\n      return this.internalMd5;\n    }\n  });\n\n  Object.defineProperty(this, 'chunkNumber', {\n    enumerable: true,\n    get: function() {\n      return this.currentChunk && this.currentChunk.chunkNumber\n        ? this.currentChunk.chunkNumber\n        : null;\n    }\n  });\n};\n\nvar define = (GridStore.define = new Define('Gridstore', GridStore, true));\n\n/**\n * The callback format for the Gridstore.open method\n * @callback GridStore~openCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {GridStore} gridStore The GridStore instance if the open method was successful.\n */\n\n/**\n * Opens the file from the database and initialize this object. Also creates a\n * new one if file does not exist.\n *\n * @method\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~openCallback} [callback] this will be called after executing this method\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.open = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  if (this.mode !== 'w' && this.mode !== 'w+' && this.mode !== 'r') {\n    throw MongoError.create({ message: 'Illegal mode ' + this.mode, driver: true });\n  }\n\n  return executeOperation(this.db.s.topology, open, [this, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar open = function(self, options, callback) {\n  // Get the write concern\n  var writeConcern = _getWriteConcern(self.db, self.options);\n\n  // If we are writing we need to ensure we have the right indexes for md5's\n  if (self.mode === 'w' || self.mode === 'w+') {\n    // Get files collection\n    var collection = self.collection();\n    // Put index on filename\n    collection.ensureIndex([['filename', 1]], writeConcern, function() {\n      // Get chunk collection\n      var chunkCollection = self.chunkCollection();\n      // Make an unique index for compatibility with mongo-cxx-driver:legacy\n      var chunkIndexOptions = shallowClone(writeConcern);\n      chunkIndexOptions.unique = true;\n      // Ensure index on chunk collection\n      chunkCollection.ensureIndex([['files_id', 1], ['n', 1]], chunkIndexOptions, function() {\n        // Open the connection\n        _open(self, writeConcern, function(err, r) {\n          if (err) return callback(err);\n          self.isOpen = true;\n          callback(err, r);\n        });\n      });\n    });\n  } else {\n    // Open the gridstore\n    _open(self, writeConcern, function(err, r) {\n      if (err) return callback(err);\n      self.isOpen = true;\n      callback(err, r);\n    });\n  }\n};\n\n// Push the definition for open\ndefine.classMethod('open', { callback: true, promise: true });\n\n/**\n * Verify if the file is at EOF.\n *\n * @method\n * @return {boolean} true if the read/write head is at the end of this file.\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.eof = function() {\n  return this.position === this.length ? true : false;\n};\n\ndefine.classMethod('eof', { callback: false, promise: false, returns: [Boolean] });\n\n/**\n * The callback result format.\n * @callback GridStore~resultCallback\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {object} result The result from the callback.\n */\n\n/**\n * Retrieves a single character from this file.\n *\n * @method\n * @param {GridStore~resultCallback} [callback] this gets called after this method is executed. Passes null to the first parameter and the character read to the second or null to the second if the read/write head is at the end of the file.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.getc = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.db.s.topology, getc, [this, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar getc = function(self, options, callback) {\n  if (self.eof()) {\n    callback(null, null);\n  } else if (self.currentChunk.eof()) {\n    nthChunk(self, self.currentChunk.chunkNumber + 1, function(err, chunk) {\n      self.currentChunk = chunk;\n      self.position = self.position + 1;\n      callback(err, self.currentChunk.getc());\n    });\n  } else {\n    self.position = self.position + 1;\n    callback(null, self.currentChunk.getc());\n  }\n};\n\ndefine.classMethod('getc', { callback: true, promise: true });\n\n/**\n * Writes a string to the file with a newline character appended at the end if\n * the given string does not have one.\n *\n * @method\n * @param {string} string the string to write.\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] this will be called after executing this method. The first parameter will contain null and the second one will contain a reference to this object.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.puts = function(string, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  var finalString = string.match(/\\n$/) == null ? string + '\\n' : string;\n  return executeOperation(\n    this.db.s.topology,\n    this.write.bind(this),\n    [finalString, options, callback],\n    { skipSessions: true }\n  );\n};\n\ndefine.classMethod('puts', { callback: true, promise: true });\n\n/**\n * Return a modified Readable stream including a possible transform method.\n *\n * @method\n * @return {GridStoreStream}\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.stream = function() {\n  return new GridStoreStream(this);\n};\n\ndefine.classMethod('stream', { callback: false, promise: false, returns: [GridStoreStream] });\n\n/**\n * Writes some data. This method will work properly only if initialized with mode \"w\" or \"w+\".\n *\n * @method\n * @param {(string|Buffer)} data the data to write.\n * @param {boolean} [close] closes this file after writing if set to true.\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] this will be called after executing this method. The first parameter will contain null and the second one will contain a reference to this object.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.write = function write(data, close, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(\n    this.db.s.topology,\n    _writeNormal,\n    [this, data, close, options, callback],\n    { skipSessions: true }\n  );\n};\n\ndefine.classMethod('write', { callback: true, promise: true });\n\n/**\n * Handles the destroy part of a stream\n *\n * @method\n * @result {null}\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.destroy = function destroy() {\n  // close and do not emit any more events. queued data is not sent.\n  if (!this.writable) return;\n  this.readable = false;\n  if (this.writable) {\n    this.writable = false;\n    this._q.length = 0;\n    this.emit('close');\n  }\n};\n\ndefine.classMethod('destroy', { callback: false, promise: false });\n\n/**\n * Stores a file from the file system to the GridFS database.\n *\n * @method\n * @param {(string|Buffer|FileHandle)} file the file to store.\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] this will be called after executing this method. The first parameter will contain null and the second one will contain a reference to this object.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.writeFile = function(file, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.db.s.topology, writeFile, [this, file, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar writeFile = function(self, file, options, callback) {\n  if (typeof file === 'string') {\n    fs.open(file, 'r', function(err, fd) {\n      if (err) return callback(err);\n      self.writeFile(fd, callback);\n    });\n    return;\n  }\n\n  self.open(function(err, self) {\n    if (err) return callback(err, self);\n\n    fs.fstat(file, function(err, stats) {\n      if (err) return callback(err, self);\n\n      var offset = 0;\n      var index = 0;\n\n      // Write a chunk\n      var writeChunk = function() {\n        // Allocate the buffer\n        var _buffer = new Buffer(self.chunkSize);\n        // Read the file\n        fs.read(file, _buffer, 0, _buffer.length, offset, function(err, bytesRead, data) {\n          if (err) return callback(err, self);\n\n          offset = offset + bytesRead;\n\n          // Create a new chunk for the data\n          var chunk = new Chunk(self, { n: index++ }, self.writeConcern);\n          chunk.write(data.slice(0, bytesRead), function(err, chunk) {\n            if (err) return callback(err, self);\n\n            chunk.save({}, function(err) {\n              if (err) return callback(err, self);\n\n              self.position = self.position + bytesRead;\n\n              // Point to current chunk\n              self.currentChunk = chunk;\n\n              if (offset >= stats.size) {\n                fs.close(file, function(err) {\n                  if (err) return callback(err);\n\n                  self.close(function(err) {\n                    if (err) return callback(err, self);\n                    return callback(null, self);\n                  });\n                });\n              } else {\n                return process.nextTick(writeChunk);\n              }\n            });\n          });\n        });\n      };\n\n      // Process the first write\n      process.nextTick(writeChunk);\n    });\n  });\n};\n\ndefine.classMethod('writeFile', { callback: true, promise: true });\n\n/**\n * Saves this file to the database. This will overwrite the old entry if it\n * already exists. This will work properly only if mode was initialized to\n * \"w\" or \"w+\".\n *\n * @method\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] this will be called after executing this method. The first parameter will contain null and the second one will contain a reference to this object.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.close = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.db.s.topology, close, [this, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar close = function(self, options, callback) {\n  if (self.mode[0] === 'w') {\n    // Set up options\n    options = Object.assign({}, self.writeConcern, options);\n\n    if (self.currentChunk != null && self.currentChunk.position > 0) {\n      self.currentChunk.save({}, function(err) {\n        if (err && typeof callback === 'function') return callback(err);\n\n        self.collection(function(err, files) {\n          if (err && typeof callback === 'function') return callback(err);\n\n          // Build the mongo object\n          if (self.uploadDate != null) {\n            buildMongoObject(self, function(err, mongoObject) {\n              if (err) {\n                if (typeof callback === 'function') return callback(err);\n                else throw err;\n              }\n\n              files.save(mongoObject, options, function(err) {\n                if (typeof callback === 'function') callback(err, mongoObject);\n              });\n            });\n          } else {\n            self.uploadDate = new Date();\n            buildMongoObject(self, function(err, mongoObject) {\n              if (err) {\n                if (typeof callback === 'function') return callback(err);\n                else throw err;\n              }\n\n              files.save(mongoObject, options, function(err) {\n                if (typeof callback === 'function') callback(err, mongoObject);\n              });\n            });\n          }\n        });\n      });\n    } else {\n      self.collection(function(err, files) {\n        if (err && typeof callback === 'function') return callback(err);\n\n        self.uploadDate = new Date();\n        buildMongoObject(self, function(err, mongoObject) {\n          if (err) {\n            if (typeof callback === 'function') return callback(err);\n            else throw err;\n          }\n\n          files.save(mongoObject, options, function(err) {\n            if (typeof callback === 'function') callback(err, mongoObject);\n          });\n        });\n      });\n    }\n  } else if (self.mode[0] === 'r') {\n    if (typeof callback === 'function') callback(null, null);\n  } else {\n    if (typeof callback === 'function')\n      callback(MongoError.create({ message: f('Illegal mode %s', self.mode), driver: true }));\n  }\n};\n\ndefine.classMethod('close', { callback: true, promise: true });\n\n/**\n * The collection callback format.\n * @callback GridStore~collectionCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Collection} collection The collection from the command execution.\n */\n\n/**\n * Retrieve this file's chunks collection.\n *\n * @method\n * @param {GridStore~collectionCallback} callback the command callback.\n * @return {Collection}\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.chunkCollection = function(callback) {\n  if (typeof callback === 'function') return this.db.collection(this.root + '.chunks', callback);\n  return this.db.collection(this.root + '.chunks');\n};\n\ndefine.classMethod('chunkCollection', { callback: true, promise: false, returns: [Collection] });\n\n/**\n * Deletes all the chunks of this file in the database.\n *\n * @method\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.unlink = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.db.s.topology, unlink, [this, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar unlink = function(self, options, callback) {\n  deleteChunks(self, function(err) {\n    if (err !== null) {\n      err.message = 'at deleteChunks: ' + err.message;\n      return callback(err);\n    }\n\n    self.collection(function(err, collection) {\n      if (err !== null) {\n        err.message = 'at collection: ' + err.message;\n        return callback(err);\n      }\n\n      collection.remove({ _id: self.fileId }, self.writeConcern, function(err) {\n        callback(err, self);\n      });\n    });\n  });\n};\n\ndefine.classMethod('unlink', { callback: true, promise: true });\n\n/**\n * Retrieves the file collection associated with this object.\n *\n * @method\n * @param {GridStore~collectionCallback} callback the command callback.\n * @return {Collection}\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.collection = function(callback) {\n  if (typeof callback === 'function') this.db.collection(this.root + '.files', callback);\n  return this.db.collection(this.root + '.files');\n};\n\ndefine.classMethod('collection', { callback: true, promise: false, returns: [Collection] });\n\n/**\n * The readlines callback format.\n * @callback GridStore~readlinesCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {string[]} strings The array of strings returned.\n */\n\n/**\n * Read the entire file as a list of strings splitting by the provided separator.\n *\n * @method\n * @param {string} [separator] The character to be recognized as the newline separator.\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~readlinesCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.readlines = function(separator, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 0);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  separator = args.length ? args.shift() : '\\n';\n  separator = separator || '\\n';\n  options = args.length ? args.shift() : {};\n\n  return executeOperation(this.db.s.topology, readlines, [this, separator, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar readlines = function(self, separator, options, callback) {\n  self.read(function(err, data) {\n    if (err) return callback(err);\n\n    var items = data.toString().split(separator);\n    items = items.length > 0 ? items.splice(0, items.length - 1) : [];\n    for (var i = 0; i < items.length; i++) {\n      items[i] = items[i] + separator;\n    }\n\n    callback(null, items);\n  });\n};\n\ndefine.classMethod('readlines', { callback: true, promise: true });\n\n/**\n * Deletes all the chunks of this file in the database if mode was set to \"w\" or\n * \"w+\" and resets the read/write head to the initial position.\n *\n * @method\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] this will be called after executing this method. The first parameter will contain null and the second one will contain a reference to this object.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.rewind = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  return executeOperation(this.db.s.topology, rewind, [this, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar rewind = function(self, options, callback) {\n  if (self.currentChunk.chunkNumber !== 0) {\n    if (self.mode[0] === 'w') {\n      deleteChunks(self, function(err) {\n        if (err) return callback(err);\n        self.currentChunk = new Chunk(self, { n: 0 }, self.writeConcern);\n        self.position = 0;\n        callback(null, self);\n      });\n    } else {\n      self.currentChunk(0, function(err, chunk) {\n        if (err) return callback(err);\n        self.currentChunk = chunk;\n        self.currentChunk.rewind();\n        self.position = 0;\n        callback(null, self);\n      });\n    }\n  } else {\n    self.currentChunk.rewind();\n    self.position = 0;\n    callback(null, self);\n  }\n};\n\ndefine.classMethod('rewind', { callback: true, promise: true });\n\n/**\n * The read callback format.\n * @callback GridStore~readCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {Buffer} data The data read from the GridStore object\n */\n\n/**\n * Retrieves the contents of this file and advances the read/write head. Works with Buffers only.\n *\n * There are 3 signatures for this method:\n *\n * (callback)\n * (length, callback)\n * (length, buffer, callback)\n *\n * @method\n * @param {number} [length] the number of characters to read. Reads all the characters from the read/write head to the EOF if not specified.\n * @param {(string|Buffer)} [buffer] a string to hold temporary data. This is used for storing the string data read so far when recursively calling this method.\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~readCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.read = function(length, buffer, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 0);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  length = args.length ? args.shift() : null;\n  buffer = args.length ? args.shift() : null;\n  options = args.length ? args.shift() : {};\n\n  return executeOperation(this.db.s.topology, read, [this, length, buffer, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar read = function(self, length, buffer, options, callback) {\n  // The data is a c-terminated string and thus the length - 1\n  var finalLength = length == null ? self.length - self.position : length;\n  var finalBuffer = buffer == null ? new Buffer(finalLength) : buffer;\n  // Add a index to buffer to keep track of writing position or apply current index\n  finalBuffer._index = buffer != null && buffer._index != null ? buffer._index : 0;\n\n  if (self.currentChunk.length() - self.currentChunk.position + finalBuffer._index >= finalLength) {\n    var slice = self.currentChunk.readSlice(finalLength - finalBuffer._index);\n    // Copy content to final buffer\n    slice.copy(finalBuffer, finalBuffer._index);\n    // Update internal position\n    self.position = self.position + finalBuffer.length;\n    // Check if we don't have a file at all\n    if (finalLength === 0 && finalBuffer.length === 0)\n      return callback(MongoError.create({ message: 'File does not exist', driver: true }), null);\n    // Else return data\n    return callback(null, finalBuffer);\n  }\n\n  // Read the next chunk\n  slice = self.currentChunk.readSlice(self.currentChunk.length() - self.currentChunk.position);\n  // Copy content to final buffer\n  slice.copy(finalBuffer, finalBuffer._index);\n  // Update index position\n  finalBuffer._index += slice.length;\n\n  // Load next chunk and read more\n  nthChunk(self, self.currentChunk.chunkNumber + 1, function(err, chunk) {\n    if (err) return callback(err);\n\n    if (chunk.length() > 0) {\n      self.currentChunk = chunk;\n      self.read(length, finalBuffer, callback);\n    } else {\n      if (finalBuffer._index > 0) {\n        callback(null, finalBuffer);\n      } else {\n        callback(\n          MongoError.create({\n            message: 'no chunks found for file, possibly corrupt',\n            driver: true\n          }),\n          null\n        );\n      }\n    }\n  });\n};\n\ndefine.classMethod('read', { callback: true, promise: true });\n\n/**\n * The tell callback format.\n * @callback GridStore~tellCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {number} position The current read position in the GridStore.\n */\n\n/**\n * Retrieves the position of the read/write head of this file.\n *\n * @method\n * @param {number} [length] the number of characters to read. Reads all the characters from the read/write head to the EOF if not specified.\n * @param {(string|Buffer)} [buffer] a string to hold temporary data. This is used for storing the string data read so far when recursively calling this method.\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~tellCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.tell = function(callback) {\n  var self = this;\n  // We provided a callback leg\n  if (typeof callback === 'function') return callback(null, this.position);\n  // Return promise\n  return new self.promiseLibrary(function(resolve) {\n    resolve(self.position);\n  });\n};\n\ndefine.classMethod('tell', { callback: true, promise: true });\n\n/**\n * The tell callback format.\n * @callback GridStore~gridStoreCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {GridStore} gridStore The gridStore.\n */\n\n/**\n * Moves the read/write head to a new location.\n *\n * There are 3 signatures for this method\n *\n * Seek Location Modes\n *  - **GridStore.IO_SEEK_SET**, **(default)** set the position from the start of the file.\n *  - **GridStore.IO_SEEK_CUR**, set the position from the current position in the file.\n *  - **GridStore.IO_SEEK_END**, set the position from the end of the file.\n *\n * @method\n * @param {number} [position] the position to seek to\n * @param {number} [seekLocation] seek mode. Use one of the Seek Location modes.\n * @param {object} [options] Optional settings\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~gridStoreCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.prototype.seek = function(position, seekLocation, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  seekLocation = args.length ? args.shift() : null;\n  options = args.length ? args.shift() : {};\n\n  return executeOperation(\n    this.db.s.topology,\n    seek,\n    [this, position, seekLocation, options, callback],\n    { skipSessions: true }\n  );\n};\n\nvar seek = function(self, position, seekLocation, options, callback) {\n  // Seek only supports read mode\n  if (self.mode !== 'r') {\n    return callback(\n      MongoError.create({ message: 'seek is only supported for mode r', driver: true })\n    );\n  }\n\n  var seekLocationFinal = seekLocation == null ? GridStore.IO_SEEK_SET : seekLocation;\n  var finalPosition = position;\n  var targetPosition = 0;\n\n  // Calculate the position\n  if (seekLocationFinal === GridStore.IO_SEEK_CUR) {\n    targetPosition = self.position + finalPosition;\n  } else if (seekLocationFinal === GridStore.IO_SEEK_END) {\n    targetPosition = self.length + finalPosition;\n  } else {\n    targetPosition = finalPosition;\n  }\n\n  // Get the chunk\n  var newChunkNumber = Math.floor(targetPosition / self.chunkSize);\n  var seekChunk = function() {\n    nthChunk(self, newChunkNumber, function(err, chunk) {\n      if (err) return callback(err, null);\n      if (chunk == null) return callback(new Error('no chunk found'));\n\n      // Set the current chunk\n      self.currentChunk = chunk;\n      self.position = targetPosition;\n      self.currentChunk.position = self.position % self.chunkSize;\n      callback(err, self);\n    });\n  };\n\n  seekChunk();\n};\n\ndefine.classMethod('seek', { callback: true, promise: true });\n\n/**\n * @ignore\n */\nvar _open = function(self, options, callback) {\n  var collection = self.collection();\n  // Create the query\n  var query =\n    self.referenceBy === REFERENCE_BY_ID ? { _id: self.fileId } : { filename: self.filename };\n  query = null == self.fileId && self.filename == null ? null : query;\n  options.readPreference = self.readPreference;\n\n  // Fetch the chunks\n  if (query != null) {\n    collection.findOne(query, options, function(err, doc) {\n      if (err) {\n        return error(err);\n      }\n\n      // Check if the collection for the files exists otherwise prepare the new one\n      if (doc != null) {\n        self.fileId = doc._id;\n        // Prefer a new filename over the existing one if this is a write\n        self.filename =\n          self.mode === 'r' || self.filename === undefined ? doc.filename : self.filename;\n        self.contentType = doc.contentType;\n        self.internalChunkSize = doc.chunkSize;\n        self.uploadDate = doc.uploadDate;\n        self.aliases = doc.aliases;\n        self.length = doc.length;\n        self.metadata = doc.metadata;\n        self.internalMd5 = doc.md5;\n      } else if (self.mode !== 'r') {\n        self.fileId = self.fileId == null ? new ObjectID() : self.fileId;\n        self.contentType = GridStore.DEFAULT_CONTENT_TYPE;\n        self.internalChunkSize =\n          self.internalChunkSize == null ? Chunk.DEFAULT_CHUNK_SIZE : self.internalChunkSize;\n        self.length = 0;\n      } else {\n        self.length = 0;\n        var txtId = self.fileId._bsontype === 'ObjectID' ? self.fileId.toHexString() : self.fileId;\n        return error(\n          MongoError.create({\n            message: f(\n              'file with id %s not opened for writing',\n              self.referenceBy === REFERENCE_BY_ID ? txtId : self.filename\n            ),\n            driver: true\n          }),\n          self\n        );\n      }\n\n      // Process the mode of the object\n      if (self.mode === 'r') {\n        nthChunk(self, 0, options, function(err, chunk) {\n          if (err) return error(err);\n          self.currentChunk = chunk;\n          self.position = 0;\n          callback(null, self);\n        });\n      } else if (self.mode === 'w' && doc) {\n        // Delete any existing chunks\n        deleteChunks(self, options, function(err) {\n          if (err) return error(err);\n          self.currentChunk = new Chunk(self, { n: 0 }, self.writeConcern);\n          self.contentType =\n            self.options['content_type'] == null ? self.contentType : self.options['content_type'];\n          self.internalChunkSize =\n            self.options['chunk_size'] == null\n              ? self.internalChunkSize\n              : self.options['chunk_size'];\n          self.metadata =\n            self.options['metadata'] == null ? self.metadata : self.options['metadata'];\n          self.aliases = self.options['aliases'] == null ? self.aliases : self.options['aliases'];\n          self.position = 0;\n          callback(null, self);\n        });\n      } else if (self.mode === 'w') {\n        self.currentChunk = new Chunk(self, { n: 0 }, self.writeConcern);\n        self.contentType =\n          self.options['content_type'] == null ? self.contentType : self.options['content_type'];\n        self.internalChunkSize =\n          self.options['chunk_size'] == null ? self.internalChunkSize : self.options['chunk_size'];\n        self.metadata = self.options['metadata'] == null ? self.metadata : self.options['metadata'];\n        self.aliases = self.options['aliases'] == null ? self.aliases : self.options['aliases'];\n        self.position = 0;\n        callback(null, self);\n      } else if (self.mode === 'w+') {\n        nthChunk(self, lastChunkNumber(self), options, function(err, chunk) {\n          if (err) return error(err);\n          // Set the current chunk\n          self.currentChunk = chunk == null ? new Chunk(self, { n: 0 }, self.writeConcern) : chunk;\n          self.currentChunk.position = self.currentChunk.data.length();\n          self.metadata =\n            self.options['metadata'] == null ? self.metadata : self.options['metadata'];\n          self.aliases = self.options['aliases'] == null ? self.aliases : self.options['aliases'];\n          self.position = self.length;\n          callback(null, self);\n        });\n      }\n    });\n  } else {\n    // Write only mode\n    self.fileId = null == self.fileId ? new ObjectID() : self.fileId;\n    self.contentType = GridStore.DEFAULT_CONTENT_TYPE;\n    self.internalChunkSize =\n      self.internalChunkSize == null ? Chunk.DEFAULT_CHUNK_SIZE : self.internalChunkSize;\n    self.length = 0;\n\n    // No file exists set up write mode\n    if (self.mode === 'w') {\n      // Delete any existing chunks\n      deleteChunks(self, options, function(err) {\n        if (err) return error(err);\n        self.currentChunk = new Chunk(self, { n: 0 }, self.writeConcern);\n        self.contentType =\n          self.options['content_type'] == null ? self.contentType : self.options['content_type'];\n        self.internalChunkSize =\n          self.options['chunk_size'] == null ? self.internalChunkSize : self.options['chunk_size'];\n        self.metadata = self.options['metadata'] == null ? self.metadata : self.options['metadata'];\n        self.aliases = self.options['aliases'] == null ? self.aliases : self.options['aliases'];\n        self.position = 0;\n        callback(null, self);\n      });\n    } else if (self.mode === 'w+') {\n      nthChunk(self, lastChunkNumber(self), options, function(err, chunk) {\n        if (err) return error(err);\n        // Set the current chunk\n        self.currentChunk = chunk == null ? new Chunk(self, { n: 0 }, self.writeConcern) : chunk;\n        self.currentChunk.position = self.currentChunk.data.length();\n        self.metadata = self.options['metadata'] == null ? self.metadata : self.options['metadata'];\n        self.aliases = self.options['aliases'] == null ? self.aliases : self.options['aliases'];\n        self.position = self.length;\n        callback(null, self);\n      });\n    }\n  }\n\n  // only pass error to callback once\n  function error(err) {\n    if (error.err) return;\n    callback((error.err = err));\n  }\n};\n\n/**\n * @ignore\n */\nvar writeBuffer = function(self, buffer, close, callback) {\n  if (typeof close === 'function') {\n    callback = close;\n    close = null;\n  }\n  var finalClose = typeof close === 'boolean' ? close : false;\n\n  if (self.mode !== 'w') {\n    callback(\n      MongoError.create({\n        message: f(\n          'file with id %s not opened for writing',\n          self.referenceBy === REFERENCE_BY_ID ? self.referenceBy : self.filename\n        ),\n        driver: true\n      }),\n      null\n    );\n  } else {\n    if (self.currentChunk.position + buffer.length >= self.chunkSize) {\n      // Write out the current Chunk and then keep writing until we have less data left than a chunkSize left\n      // to a new chunk (recursively)\n      var previousChunkNumber = self.currentChunk.chunkNumber;\n      var leftOverDataSize = self.chunkSize - self.currentChunk.position;\n      var firstChunkData = buffer.slice(0, leftOverDataSize);\n      var leftOverData = buffer.slice(leftOverDataSize);\n      // A list of chunks to write out\n      var chunksToWrite = [self.currentChunk.write(firstChunkData)];\n      // If we have more data left than the chunk size let's keep writing new chunks\n      while (leftOverData.length >= self.chunkSize) {\n        // Create a new chunk and write to it\n        var newChunk = new Chunk(self, { n: previousChunkNumber + 1 }, self.writeConcern);\n        firstChunkData = leftOverData.slice(0, self.chunkSize);\n        leftOverData = leftOverData.slice(self.chunkSize);\n        // Update chunk number\n        previousChunkNumber = previousChunkNumber + 1;\n        // Write data\n        newChunk.write(firstChunkData);\n        // Push chunk to save list\n        chunksToWrite.push(newChunk);\n      }\n\n      // Set current chunk with remaining data\n      self.currentChunk = new Chunk(self, { n: previousChunkNumber + 1 }, self.writeConcern);\n      // If we have left over data write it\n      if (leftOverData.length > 0) self.currentChunk.write(leftOverData);\n\n      // Update the position for the gridstore\n      self.position = self.position + buffer.length;\n      // Total number of chunks to write\n      var numberOfChunksToWrite = chunksToWrite.length;\n\n      for (var i = 0; i < chunksToWrite.length; i++) {\n        chunksToWrite[i].save({}, function(err) {\n          if (err) return callback(err);\n\n          numberOfChunksToWrite = numberOfChunksToWrite - 1;\n\n          if (numberOfChunksToWrite <= 0) {\n            // We care closing the file before returning\n            if (finalClose) {\n              return self.close(function(err) {\n                callback(err, self);\n              });\n            }\n\n            // Return normally\n            return callback(null, self);\n          }\n        });\n      }\n    } else {\n      // Update the position for the gridstore\n      self.position = self.position + buffer.length;\n      // We have less data than the chunk size just write it and callback\n      self.currentChunk.write(buffer);\n      // We care closing the file before returning\n      if (finalClose) {\n        return self.close(function(err) {\n          callback(err, self);\n        });\n      }\n      // Return normally\n      return callback(null, self);\n    }\n  }\n};\n\n/**\n * Creates a mongoDB object representation of this object.\n *\n *        <pre><code>\n *        {\n *          '_id' : , // {number} id for this file\n *          'filename' : , // {string} name for this file\n *          'contentType' : , // {string} mime type for this file\n *          'length' : , // {number} size of this file?\n *          'chunksize' : , // {number} chunk size used by this file\n *          'uploadDate' : , // {Date}\n *          'aliases' : , // {array of string}\n *          'metadata' : , // {string}\n *        }\n *        </code></pre>\n *\n * @ignore\n */\nvar buildMongoObject = function(self, callback) {\n  // Calcuate the length\n  var mongoObject = {\n    _id: self.fileId,\n    filename: self.filename,\n    contentType: self.contentType,\n    length: self.position ? self.position : 0,\n    chunkSize: self.chunkSize,\n    uploadDate: self.uploadDate,\n    aliases: self.aliases,\n    metadata: self.metadata\n  };\n\n  var md5Command = { filemd5: self.fileId, root: self.root };\n  self.db.command(md5Command, function(err, results) {\n    if (err) return callback(err);\n\n    mongoObject.md5 = results.md5;\n    callback(null, mongoObject);\n  });\n};\n\n/**\n * Gets the nth chunk of this file.\n * @ignore\n */\nvar nthChunk = function(self, chunkNumber, options, callback) {\n  if (typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n\n  options = options || self.writeConcern;\n  options.readPreference = self.readPreference;\n  // Get the nth chunk\n  self\n    .chunkCollection()\n    .findOne({ files_id: self.fileId, n: chunkNumber }, options, function(err, chunk) {\n      if (err) return callback(err);\n\n      var finalChunk = chunk == null ? {} : chunk;\n      callback(null, new Chunk(self, finalChunk, self.writeConcern));\n    });\n};\n\n/**\n * @ignore\n */\nvar lastChunkNumber = function(self) {\n  return Math.floor((self.length ? self.length - 1 : 0) / self.chunkSize);\n};\n\n/**\n * Deletes all the chunks of this file in the database.\n *\n * @ignore\n */\nvar deleteChunks = function(self, options, callback) {\n  if (typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n\n  options = options || self.writeConcern;\n\n  if (self.fileId != null) {\n    self.chunkCollection().remove({ files_id: self.fileId }, options, function(err) {\n      if (err) return callback(err, false);\n      callback(null, true);\n    });\n  } else {\n    callback(null, true);\n  }\n};\n\n/**\n * The collection to be used for holding the files and chunks collection.\n *\n * @classconstant DEFAULT_ROOT_COLLECTION\n */\nGridStore.DEFAULT_ROOT_COLLECTION = 'fs';\n\n/**\n * Default file mime type\n *\n * @classconstant DEFAULT_CONTENT_TYPE\n */\nGridStore.DEFAULT_CONTENT_TYPE = 'binary/octet-stream';\n\n/**\n * Seek mode where the given length is absolute.\n *\n * @classconstant IO_SEEK_SET\n */\nGridStore.IO_SEEK_SET = 0;\n\n/**\n * Seek mode where the given length is an offset to the current read/write head.\n *\n * @classconstant IO_SEEK_CUR\n */\nGridStore.IO_SEEK_CUR = 1;\n\n/**\n * Seek mode where the given length is an offset to the end of the file.\n *\n * @classconstant IO_SEEK_END\n */\nGridStore.IO_SEEK_END = 2;\n\n/**\n * Checks if a file exists in the database.\n *\n * @method\n * @static\n * @param {Db} db the database to query.\n * @param {string} name The name of the file to look for.\n * @param {string} [rootCollection] The root collection that holds the files and chunks collection. Defaults to **{GridStore.DEFAULT_ROOT_COLLECTION}**.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] result from exists.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.exist = function(db, fileIdObject, rootCollection, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 2);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  rootCollection = args.length ? args.shift() : null;\n  options = args.length ? args.shift() : {};\n  options = options || {};\n\n  return executeOperation(\n    db.s.topology,\n    exists,\n    [db, fileIdObject, rootCollection, options, callback],\n    { skipSessions: true }\n  );\n};\n\nvar exists = function(db, fileIdObject, rootCollection, options, callback) {\n  // Establish read preference\n  var readPreference = options.readPreference || ReadPreference.PRIMARY;\n  // Fetch collection\n  var rootCollectionFinal =\n    rootCollection != null ? rootCollection : GridStore.DEFAULT_ROOT_COLLECTION;\n  db.collection(rootCollectionFinal + '.files', function(err, collection) {\n    if (err) return callback(err);\n\n    // Build query\n    var query =\n      typeof fileIdObject === 'string' ||\n      Object.prototype.toString.call(fileIdObject) === '[object RegExp]'\n        ? { filename: fileIdObject }\n        : { _id: fileIdObject }; // Attempt to locate file\n\n    // We have a specific query\n    if (\n      fileIdObject != null &&\n      typeof fileIdObject === 'object' &&\n      Object.prototype.toString.call(fileIdObject) !== '[object RegExp]'\n    ) {\n      query = fileIdObject;\n    }\n\n    // Check if the entry exists\n    collection.findOne(query, { readPreference: readPreference }, function(err, item) {\n      if (err) return callback(err);\n      callback(null, item == null ? false : true);\n    });\n  });\n};\n\ndefine.staticMethod('exist', { callback: true, promise: true });\n\n/**\n * Gets the list of files stored in the GridFS.\n *\n * @method\n * @static\n * @param {Db} db the database to query.\n * @param {string} [rootCollection] The root collection that holds the files and chunks collection. Defaults to **{GridStore.DEFAULT_ROOT_COLLECTION}**.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] result from exists.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.list = function(db, rootCollection, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  rootCollection = args.length ? args.shift() : null;\n  options = args.length ? args.shift() : {};\n  options = options || {};\n\n  return executeOperation(db.s.topology, list, [db, rootCollection, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar list = function(db, rootCollection, options, callback) {\n  // Ensure we have correct values\n  if (rootCollection != null && typeof rootCollection === 'object') {\n    options = rootCollection;\n    rootCollection = null;\n  }\n\n  // Establish read preference\n  var readPreference = options.readPreference || ReadPreference.primary;\n  // Check if we are returning by id not filename\n  var byId = options['id'] != null ? options['id'] : false;\n  // Fetch item\n  var rootCollectionFinal =\n    rootCollection != null ? rootCollection : GridStore.DEFAULT_ROOT_COLLECTION;\n  var items = [];\n  db.collection(rootCollectionFinal + '.files', function(err, collection) {\n    if (err) return callback(err);\n\n    collection.find({}, { readPreference: readPreference }, function(err, cursor) {\n      if (err) return callback(err);\n\n      cursor.each(function(err, item) {\n        if (item != null) {\n          items.push(byId ? item._id : item.filename);\n        } else {\n          callback(err, items);\n        }\n      });\n    });\n  });\n};\n\ndefine.staticMethod('list', { callback: true, promise: true });\n\n/**\n * Reads the contents of a file.\n *\n * This method has the following signatures\n *\n * (db, name, callback)\n * (db, name, length, callback)\n * (db, name, length, offset, callback)\n * (db, name, length, offset, options, callback)\n *\n * @method\n * @static\n * @param {Db} db the database to query.\n * @param {string} name The name of the file.\n * @param {number} [length] The size of data to read.\n * @param {number} [offset] The offset from the head of the file of which to start reading from.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~readCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.read = function(db, name, length, offset, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 2);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  length = args.length ? args.shift() : null;\n  offset = args.length ? args.shift() : null;\n  options = args.length ? args.shift() : null;\n  options = options || {};\n\n  return executeOperation(\n    db.s.topology,\n    readStatic,\n    [db, name, length, offset, options, callback],\n    { skipSessions: true }\n  );\n};\n\nvar readStatic = function(db, name, length, offset, options, callback) {\n  new GridStore(db, name, 'r', options).open(function(err, gridStore) {\n    if (err) return callback(err);\n    // Make sure we are not reading out of bounds\n    if (offset && offset >= gridStore.length)\n      return callback('offset larger than size of file', null);\n    if (length && length > gridStore.length)\n      return callback('length is larger than the size of the file', null);\n    if (offset && length && offset + length > gridStore.length)\n      return callback('offset and length is larger than the size of the file', null);\n\n    if (offset != null) {\n      gridStore.seek(offset, function(err, gridStore) {\n        if (err) return callback(err);\n        gridStore.read(length, callback);\n      });\n    } else {\n      gridStore.read(length, callback);\n    }\n  });\n};\n\ndefine.staticMethod('read', { callback: true, promise: true });\n\n/**\n * Read the entire file as a list of strings splitting by the provided separator.\n *\n * @method\n * @static\n * @param {Db} db the database to query.\n * @param {(String|object)} name the name of the file.\n * @param {string} [separator] The character to be recognized as the newline separator.\n * @param {object} [options=null] Optional settings.\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~readlinesCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.readlines = function(db, name, separator, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 2);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  separator = args.length ? args.shift() : null;\n  options = args.length ? args.shift() : null;\n  options = options || {};\n\n  return executeOperation(\n    db.s.topology,\n    readlinesStatic,\n    [db, name, separator, options, callback],\n    { skipSessions: true }\n  );\n};\n\nvar readlinesStatic = function(db, name, separator, options, callback) {\n  var finalSeperator = separator == null ? '\\n' : separator;\n  new GridStore(db, name, 'r', options).open(function(err, gridStore) {\n    if (err) return callback(err);\n    gridStore.readlines(finalSeperator, callback);\n  });\n};\n\ndefine.staticMethod('readlines', { callback: true, promise: true });\n\n/**\n * Deletes the chunks and metadata information of a file from GridFS.\n *\n * @method\n * @static\n * @param {Db} db The database to query.\n * @param {(string|array)} names The name/names of the files to delete.\n * @param {object} [options=null] Optional settings.\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {ClientSession} [options.session] optional session to use for this operation\n * @param {GridStore~resultCallback} [callback] the command callback.\n * @return {Promise} returns Promise if no callback passed\n * @deprecated Use GridFSBucket API instead\n */\nGridStore.unlink = function(db, names, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 2);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() : {};\n  options = options || {};\n\n  return executeOperation(db.s.topology, unlinkStatic, [this, db, names, options, callback], {\n    skipSessions: true\n  });\n};\n\nvar unlinkStatic = function(self, db, names, options, callback) {\n  // Get the write concern\n  var writeConcern = _getWriteConcern(db, options);\n\n  // List of names\n  if (names.constructor === Array) {\n    var tc = 0;\n    for (var i = 0; i < names.length; i++) {\n      ++tc;\n      GridStore.unlink(db, names[i], options, function() {\n        if (--tc === 0) {\n          callback(null, self);\n        }\n      });\n    }\n  } else {\n    new GridStore(db, names, 'w', options).open(function(err, gridStore) {\n      if (err) return callback(err);\n      deleteChunks(gridStore, function(err) {\n        if (err) return callback(err);\n        gridStore.collection(function(err, collection) {\n          if (err) return callback(err);\n          collection.remove({ _id: gridStore.fileId }, writeConcern, function(err) {\n            callback(err, self);\n          });\n        });\n      });\n    });\n  }\n};\n\ndefine.staticMethod('unlink', { callback: true, promise: true });\n\n/**\n *  @ignore\n */\nvar _writeNormal = function(self, data, close, options, callback) {\n  // If we have a buffer write it using the writeBuffer method\n  if (Buffer.isBuffer(data)) {\n    return writeBuffer(self, data, close, callback);\n  } else {\n    return writeBuffer(self, new Buffer(data, 'binary'), close, callback);\n  }\n};\n\n/**\n * @ignore\n */\nvar _setWriteConcernHash = function(options) {\n  var finalOptions = {};\n  if (options.w != null) finalOptions.w = options.w;\n  if (options.journal === true) finalOptions.j = options.journal;\n  if (options.j === true) finalOptions.j = options.j;\n  if (options.fsync === true) finalOptions.fsync = options.fsync;\n  if (options.wtimeout != null) finalOptions.wtimeout = options.wtimeout;\n  return finalOptions;\n};\n\n/**\n * @ignore\n */\nvar _getWriteConcern = function(self, options) {\n  // Final options\n  var finalOptions = { w: 1 };\n  options = options || {};\n\n  // Local options verification\n  if (\n    options.w != null ||\n    typeof options.j === 'boolean' ||\n    typeof options.journal === 'boolean' ||\n    typeof options.fsync === 'boolean'\n  ) {\n    finalOptions = _setWriteConcernHash(options);\n  } else if (options.safe != null && typeof options.safe === 'object') {\n    finalOptions = _setWriteConcernHash(options.safe);\n  } else if (typeof options.safe === 'boolean') {\n    finalOptions = { w: options.safe ? 1 : 0 };\n  } else if (\n    self.options.w != null ||\n    typeof self.options.j === 'boolean' ||\n    typeof self.options.journal === 'boolean' ||\n    typeof self.options.fsync === 'boolean'\n  ) {\n    finalOptions = _setWriteConcernHash(self.options);\n  } else if (\n    self.safe &&\n    (self.safe.w != null ||\n      typeof self.safe.j === 'boolean' ||\n      typeof self.safe.journal === 'boolean' ||\n      typeof self.safe.fsync === 'boolean')\n  ) {\n    finalOptions = _setWriteConcernHash(self.safe);\n  } else if (typeof self.safe === 'boolean') {\n    finalOptions = { w: self.safe ? 1 : 0 };\n  }\n\n  // Ensure we don't have an invalid combination of write concerns\n  if (\n    finalOptions.w < 1 &&\n    (finalOptions.journal === true || finalOptions.j === true || finalOptions.fsync === true)\n  )\n    throw MongoError.create({\n      message: 'No acknowledgement using w < 1 cannot be combined with journal:true or fsync:true',\n      driver: true\n    });\n\n  // Return the options\n  return finalOptions;\n};\n\n/**\n * Create a new GridStoreStream instance (INTERNAL TYPE, do not instantiate directly)\n *\n * @class\n * @extends external:Duplex\n * @return {GridStoreStream} a GridStoreStream instance.\n * @deprecated Use GridFSBucket API instead\n */\nvar GridStoreStream = function(gs) {\n  // Initialize the duplex stream\n  Duplex.call(this);\n\n  // Get the gridstore\n  this.gs = gs;\n\n  // End called\n  this.endCalled = false;\n\n  // If we have a seek\n  this.totalBytesToRead = this.gs.length - this.gs.position;\n  this.seekPosition = this.gs.position;\n};\n\n//\n// Inherit duplex\ninherits(GridStoreStream, Duplex);\n\nGridStoreStream.prototype._pipe = GridStoreStream.prototype.pipe;\n\n// Set up override\nGridStoreStream.prototype.pipe = function(destination) {\n  var self = this;\n\n  // Only open gridstore if not already open\n  if (!self.gs.isOpen) {\n    self.gs.open(function(err) {\n      if (err) return self.emit('error', err);\n      self.totalBytesToRead = self.gs.length - self.gs.position;\n      self._pipe.apply(self, [destination]);\n    });\n  } else {\n    self.totalBytesToRead = self.gs.length - self.gs.position;\n    self._pipe.apply(self, [destination]);\n  }\n\n  return destination;\n};\n\n// Called by stream\nGridStoreStream.prototype._read = function() {\n  var self = this;\n\n  var read = function() {\n    // Read data\n    self.gs.read(length, function(err, buffer) {\n      if (err && !self.endCalled) return self.emit('error', err);\n\n      // Stream is closed\n      if (self.endCalled || buffer == null) return self.push(null);\n      // Remove bytes read\n      if (buffer.length <= self.totalBytesToRead) {\n        self.totalBytesToRead = self.totalBytesToRead - buffer.length;\n        self.push(buffer);\n      } else if (buffer.length > self.totalBytesToRead) {\n        self.totalBytesToRead = self.totalBytesToRead - buffer._index;\n        self.push(buffer.slice(0, buffer._index));\n      }\n\n      // Finished reading\n      if (self.totalBytesToRead <= 0) {\n        self.endCalled = true;\n      }\n    });\n  };\n\n  // Set read length\n  var length =\n    self.gs.length < self.gs.chunkSize ? self.gs.length - self.seekPosition : self.gs.chunkSize;\n  if (!self.gs.isOpen) {\n    self.gs.open(function(err) {\n      self.totalBytesToRead = self.gs.length - self.gs.position;\n      if (err) return self.emit('error', err);\n      read();\n    });\n  } else {\n    read();\n  }\n};\n\nGridStoreStream.prototype.destroy = function() {\n  this.pause();\n  this.endCalled = true;\n  this.gs.close();\n  this.emit('end');\n};\n\nGridStoreStream.prototype.write = function(chunk) {\n  var self = this;\n  if (self.endCalled)\n    return self.emit(\n      'error',\n      MongoError.create({ message: 'attempting to write to stream after end called', driver: true })\n    );\n  // Do we have to open the gridstore\n  if (!self.gs.isOpen) {\n    self.gs.open(function() {\n      self.gs.isOpen = true;\n      self.gs.write(chunk, function() {\n        process.nextTick(function() {\n          self.emit('drain');\n        });\n      });\n    });\n    return false;\n  } else {\n    self.gs.write(chunk, function() {\n      self.emit('drain');\n    });\n    return true;\n  }\n};\n\nGridStoreStream.prototype.end = function(chunk, encoding, callback) {\n  var self = this;\n  var args = Array.prototype.slice.call(arguments, 0);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  chunk = args.length ? args.shift() : null;\n  encoding = args.length ? args.shift() : null;\n  self.endCalled = true;\n\n  if (chunk) {\n    self.gs.write(chunk, function() {\n      self.gs.close(function() {\n        if (typeof callback === 'function') callback();\n        self.emit('end');\n      });\n    });\n  }\n\n  self.gs.close(function() {\n    if (typeof callback === 'function') callback();\n    self.emit('end');\n  });\n};\n\n/**\n * The read() method pulls some data out of the internal buffer and returns it. If there is no data available, then it will return null.\n * @function external:Duplex#read\n * @param {number} size Optional argument to specify how much data to read.\n * @return {(String | Buffer | null)}\n */\n\n/**\n * Call this function to cause the stream to return strings of the specified encoding instead of Buffer objects.\n * @function external:Duplex#setEncoding\n * @param {string} encoding The encoding to use.\n * @return {null}\n */\n\n/**\n * This method will cause the readable stream to resume emitting data events.\n * @function external:Duplex#resume\n * @return {null}\n */\n\n/**\n * This method will cause a stream in flowing-mode to stop emitting data events. Any data that becomes available will remain in the internal buffer.\n * @function external:Duplex#pause\n * @return {null}\n */\n\n/**\n * This method pulls all the data out of a readable stream, and writes it to the supplied destination, automatically managing the flow so that the destination is not overwhelmed by a fast readable stream.\n * @function external:Duplex#pipe\n * @param {Writable} destination The destination for writing data\n * @param {object} [options] Pipe options\n * @return {null}\n */\n\n/**\n * This method will remove the hooks set up for a previous pipe() call.\n * @function external:Duplex#unpipe\n * @param {Writable} [destination] The destination for writing data\n * @return {null}\n */\n\n/**\n * This is useful in certain cases where a stream is being consumed by a parser, which needs to \"un-consume\" some data that it has optimistically pulled out of the source, so that the stream can be passed on to some other party.\n * @function external:Duplex#unshift\n * @param {(Buffer|string)} chunk Chunk of data to unshift onto the read queue.\n * @return {null}\n */\n\n/**\n * Versions of Node prior to v0.10 had streams that did not implement the entire Streams API as it is today. (See \"Compatibility\" below for more information.)\n * @function external:Duplex#wrap\n * @param {Stream} stream An \"old style\" readable stream.\n * @return {null}\n */\n\n/**\n * This method writes some data to the underlying system, and calls the supplied callback once the data has been fully handled.\n * @function external:Duplex#write\n * @param {(string|Buffer)} chunk The data to write\n * @param {string} encoding The encoding, if chunk is a String\n * @param {function} callback Callback for when this chunk of data is flushed\n * @return {boolean}\n */\n\n/**\n * Call this method when no more data will be written to the stream. If supplied, the callback is attached as a listener on the finish event.\n * @function external:Duplex#end\n * @param {(string|Buffer)} chunk The data to write\n * @param {string} encoding The encoding, if chunk is a String\n * @param {function} callback Callback for when this chunk of data is flushed\n * @return {null}\n */\n\n/**\n * GridStoreStream stream data event, fired for each document in the cursor.\n *\n * @event GridStoreStream#data\n * @type {object}\n */\n\n/**\n * GridStoreStream stream end event\n *\n * @event GridStoreStream#end\n * @type {null}\n */\n\n/**\n * GridStoreStream stream close event\n *\n * @event GridStoreStream#close\n * @type {null}\n */\n\n/**\n * GridStoreStream stream readable event\n *\n * @event GridStoreStream#readable\n * @type {null}\n */\n\n/**\n * GridStoreStream stream drain event\n *\n * @event GridStoreStream#drain\n * @type {null}\n */\n\n/**\n * GridStoreStream stream finish event\n *\n * @event GridStoreStream#finish\n * @type {null}\n */\n\n/**\n * GridStoreStream stream pipe event\n *\n * @event GridStoreStream#pipe\n * @type {null}\n */\n\n/**\n * GridStoreStream stream unpipe event\n *\n * @event GridStoreStream#unpipe\n * @type {null}\n */\n\n/**\n * GridStoreStream stream error event\n *\n * @event GridStoreStream#error\n * @type {null}\n */\n\n/**\n * @ignore\n */\nmodule.exports = GridStore;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/gridfs/grid_store.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/metadata.js":
/*!**********************************************!*\
  !*** ./node_modules/mongoDb/lib/metadata.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar f = __webpack_require__(/*! util */ \"util\").format;\n\nvar Define = function(name, object, stream) {\n  this.name = name;\n  this.object = object;\n  this.stream = typeof stream === 'boolean' ? stream : false;\n  this.instrumentations = {};\n};\n\nDefine.prototype.classMethod = function(name, options) {\n  var keys = Object.keys(options).sort();\n  var key = generateKey(keys, options);\n\n  // Add a list of instrumentations\n  if (this.instrumentations[key] == null) {\n    this.instrumentations[key] = {\n      methods: [],\n      options: options\n    };\n  }\n\n  // Push to list of method for this instrumentation\n  this.instrumentations[key].methods.push(name);\n};\n\nvar generateKey = function(keys, options) {\n  var parts = [];\n  for (var i = 0; i < keys.length; i++) {\n    parts.push(f('%s=%s', keys[i], options[keys[i]]));\n  }\n\n  return parts.join();\n};\n\nDefine.prototype.staticMethod = function(name, options) {\n  options.static = true;\n  var keys = Object.keys(options).sort();\n  var key = generateKey(keys, options);\n\n  // Add a list of instrumentations\n  if (this.instrumentations[key] == null) {\n    this.instrumentations[key] = {\n      methods: [],\n      options: options\n    };\n  }\n\n  // Push to list of method for this instrumentation\n  this.instrumentations[key].methods.push(name);\n};\n\nDefine.prototype.generate = function() {\n  // Generate the return object\n  var object = {\n    name: this.name,\n    obj: this.object,\n    stream: this.stream,\n    instrumentations: []\n  };\n\n  for (var name in this.instrumentations) {\n    object.instrumentations.push(this.instrumentations[name]);\n  }\n\n  return object;\n};\n\nmodule.exports = Define;\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/metadata.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/mongo_client.js":
/*!**************************************************!*\
  !*** ./node_modules/mongoDb/lib/mongo_client.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process, Buffer) {\n\nvar parse = __webpack_require__(/*! ./url_parser */ \"./node_modules/mongoDb/lib/url_parser.js\"),\n  Server = __webpack_require__(/*! ./topologies/server */ \"./node_modules/mongoDb/lib/topologies/server.js\"),\n  Mongos = __webpack_require__(/*! ./topologies/mongos */ \"./node_modules/mongoDb/lib/topologies/mongos.js\"),\n  ReplSet = __webpack_require__(/*! ./topologies/replset */ \"./node_modules/mongoDb/lib/topologies/replset.js\"),\n  EventEmitter = __webpack_require__(/*! events */ \"events\").EventEmitter,\n  inherits = __webpack_require__(/*! util */ \"util\").inherits,\n  Define = __webpack_require__(/*! ./metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference,\n  Logger = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Logger,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  handleCallback = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").handleCallback,\n  Db = __webpack_require__(/*! ./db */ \"./node_modules/mongoDb/lib/db.js\"),\n  f = __webpack_require__(/*! util */ \"util\").format,\n  shallowClone = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").shallowClone,\n  authenticate = __webpack_require__(/*! ./authenticate */ \"./node_modules/mongoDb/lib/authenticate.js\"),\n  ServerSessionPool = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Sessions.ServerSessionPool,\n  executeOperation = __webpack_require__(/*! ./utils */ \"./node_modules/mongoDb/lib/utils.js\").executeOperation;\n\n/**\n * @fileOverview The **MongoClient** class is a class that allows for making Connections to MongoDB.\n *\n * @example\n * // Connect using a MongoClient instance\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * const mongoClient = new MongoClient(url);\n * mongoClient.connect(function(err, client) {\n *   const db = client.db(dbName);\n *   client.close();\n * });\n *\n * @example\n * // Connect using the MongoClient.connect static method\n * const MongoClient = require('mongodb').MongoClient;\n * const test = require('assert');\n * // Connection url\n * const url = 'mongodb://localhost:27017';\n * // Database Name\n * const dbName = 'test';\n * // Connect using MongoClient\n * MongoClient.connect(url, function(err, client) {\n *   const db = client.db(dbName);\n *   client.close();\n * });\n */\nvar validOptionNames = [\n  'poolSize',\n  'ssl',\n  'sslValidate',\n  'sslCA',\n  'sslCert',\n  'sslKey',\n  'sslPass',\n  'sslCRL',\n  'autoReconnect',\n  'noDelay',\n  'keepAlive',\n  'keepAliveInitialDelay',\n  'connectTimeoutMS',\n  'family',\n  'socketTimeoutMS',\n  'reconnectTries',\n  'reconnectInterval',\n  'ha',\n  'haInterval',\n  'replicaSet',\n  'secondaryAcceptableLatencyMS',\n  'acceptableLatencyMS',\n  'connectWithNoPrimary',\n  'authSource',\n  'w',\n  'wtimeout',\n  'j',\n  'forceServerObjectId',\n  'serializeFunctions',\n  'ignoreUndefined',\n  'raw',\n  'bufferMaxEntries',\n  'readPreference',\n  'pkFactory',\n  'promiseLibrary',\n  'readConcern',\n  'maxStalenessSeconds',\n  'loggerLevel',\n  'logger',\n  'promoteValues',\n  'promoteBuffers',\n  'promoteLongs',\n  'domainsEnabled',\n  'checkServerIdentity',\n  'validateOptions',\n  'appname',\n  'auth',\n  'user',\n  'password',\n  'authMechanism',\n  'compression',\n  'fsync',\n  'readPreferenceTags',\n  'numberOfRetries',\n  'auto_reconnect',\n  'minSize'\n];\n\nvar ignoreOptionNames = ['native_parser'];\nvar legacyOptionNames = ['server', 'replset', 'replSet', 'mongos', 'db'];\n\nfunction validOptions(options) {\n  var _validOptions = validOptionNames.concat(legacyOptionNames);\n\n  for (var name in options) {\n    if (ignoreOptionNames.indexOf(name) !== -1) {\n      continue;\n    }\n\n    if (_validOptions.indexOf(name) === -1 && options.validateOptions) {\n      return new MongoError(f('option %s is not supported', name));\n    } else if (_validOptions.indexOf(name) === -1) {\n      console.warn(f('the options [%s] is not supported', name));\n    }\n\n    if (legacyOptionNames.indexOf(name) !== -1) {\n      console.warn(\n        f(\n          'the server/replset/mongos options are deprecated, ' +\n            'all their options are supported at the top level of the options object [%s]',\n          validOptionNames\n        )\n      );\n    }\n  }\n}\n\n/**\n * Creates a new MongoClient instance\n * @class\n * @param {string} url The connection URI string\n * @param {object} [options] Optional settings\n * @param {number} [options.poolSize=5] The maximum size of the individual server pool\n * @param {boolean} [options.ssl=false] Enable SSL connection.\n * @param {boolean} [options.sslValidate=true] Validate mongod server certificate against Certificate Authority\n * @param {buffer} [options.sslCA=undefined] SSL Certificate store binary buffer\n * @param {buffer} [options.sslCert=undefined] SSL Certificate binary buffer\n * @param {buffer} [options.sslKey=undefined] SSL Key file binary buffer\n * @param {string} [options.sslPass=undefined] SSL Certificate pass phrase\n * @param {buffer} [options.sslCRL=undefined] SSL Certificate revocation list binary buffer\n * @param {boolean} [options.autoReconnect=true] Enable autoReconnect for single server instances\n * @param {boolean} [options.noDelay=true] TCP Connection no delay\n * @param {boolean} [options.keepAlive=true] TCP Connection keep alive enabled\n * @param {number} [options.keepAliveInitialDelay=30000] The number of milliseconds to wait before initiating keepAlive on the TCP socket\n * @param {number} [options.connectTimeoutMS=30000] TCP Connection timeout setting\n * @param {number} [options.family=null] Version of IP stack. Can be 4, 6 or null (default).\n * If null, will attempt to connect with IPv6, and will fall back to IPv4 on failure\n * @param {number} [options.socketTimeoutMS=360000] TCP Socket timeout setting\n * @param {number} [options.reconnectTries=30] Server attempt to reconnect #times\n * @param {number} [options.reconnectInterval=1000] Server will wait # milliseconds between retries\n * @param {boolean} [options.ha=true] Control if high availability monitoring runs for Replicaset or Mongos proxies\n * @param {number} [options.haInterval=10000] The High availability period for replicaset inquiry\n * @param {string} [options.replicaSet=undefined] The Replicaset set name\n * @param {number} [options.secondaryAcceptableLatencyMS=15] Cutoff latency point in MS for Replicaset member selection\n * @param {number} [options.acceptableLatencyMS=15] Cutoff latency point in MS for Mongos proxies selection\n * @param {boolean} [options.connectWithNoPrimary=false] Sets if the driver should connect even if no primary is available\n * @param {string} [options.authSource=undefined] Define the database to authenticate against\n * @param {(number|string)} [options.w=null] The write concern\n * @param {number} [options.wtimeout=null] The write concern timeout\n * @param {boolean} [options.j=false] Specify a journal write concern\n * @param {boolean} [options.forceServerObjectId=false] Force server to assign _id values instead of driver\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object\n * @param {Boolean} [options.ignoreUndefined=false] Specify if the BSON serializer should ignore undefined fields\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers\n * @param {number} [options.bufferMaxEntries=-1] Sets a cap on how many operations the driver will buffer up before giving up on getting a working connection, default is -1 which is unlimited\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST)\n * @param {object} [options.pkFactory=null] A primary key factory object for generation of custom _id keys\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {object} [options.readConcern=null] Specify a read concern for the collection (only MongoDB 3.2 or higher supported)\n * @param {string} [options.readConcern.level='local'] Specify a read concern level for the collection operations, one of [local|majority]. (only MongoDB 3.2 or higher supported)\n * @param {number} [options.maxStalenessSeconds=undefined] The max staleness to secondary reads (values under 10 seconds cannot be guaranteed)\n * @param {string} [options.loggerLevel=undefined] The logging level (error/warn/info/debug)\n * @param {object} [options.logger=undefined] Custom logger object\n * @param {boolean} [options.promoteValues=true] Promotes BSON values to native types where possible, set to false to only receive wrapper types\n * @param {boolean} [options.promoteBuffers=false] Promotes Binary BSON values to native Node Buffers\n * @param {boolean} [options.promoteLongs=true] Promotes long values to number if they fit inside the 53 bits resolution\n * @param {boolean} [options.domainsEnabled=false] Enable the wrapping of the callback in the current domain, disabled by default to avoid perf hit\n * @param {boolean|function} [options.checkServerIdentity=true] Ensure we check server identify during SSL, set to false to disable checking. Only works for Node 0.12.x or higher. You can pass in a boolean or your own checkServerIdentity override function\n * @param {object} [options.validateOptions=false] Validate MongoClient passed in options for correctness\n * @param {string} [options.appname=undefined] The name of the application that created this MongoClient instance. MongoDB 3.4 and newer will print this value in the server log upon establishing each connection. It is also recorded in the slow query log and profile collections\n * @param {string} [options.auth.user=undefined] The username for auth\n * @param {string} [options.auth.password=undefined] The password for auth\n * @param {string} [options.authMechanism=undefined] Mechanism for authentication: MDEFAULT, GSSAPI, PLAIN, MONGODB-X509, SCRAM-SHA-1 or MONGODB-CR\n * @param {object} [options.compression=null] Type of compression to use: snappy or zlib\n * @param {boolean} [options.fsync=false] Specify a file sync write concern\n * @param {array} [options.readPreferenceTags=null] Read preference tags\n * @param {number} [options.numberOfRetries=5] The number of retries for a tailable cursor\n * @param {boolean} [options.auto_reconnect=true] Enable auto reconnecting for single server instances\n * @param {MongoClient~connectCallback} [callback] The command result callback\n * @return {MongoClient} a MongoClient instance\n */\nfunction MongoClient(url, options) {\n  if (!(this instanceof MongoClient)) return new MongoClient();\n\n  // Set up event emitter\n  EventEmitter.call(this);\n\n  // The internal state\n  this.s = {\n    url: url,\n    options: options || {},\n    promiseLibrary: null,\n    dbCache: {},\n    sessions: []\n  };\n\n  // Get the promiseLibrary\n  var promiseLibrary = this.s.options.promiseLibrary || Promise;\n\n  // Add the promise to the internal state\n  this.s.promiseLibrary = promiseLibrary;\n}\n\n/**\n * @ignore\n */\ninherits(MongoClient, EventEmitter);\n\nvar define = (MongoClient.define = new Define('MongoClient', MongoClient, false));\n\n/**\n * The callback format for results\n * @callback MongoClient~connectCallback\n * @param {MongoError} error An error instance representing the error during the execution.\n * @param {MongoClient} client The connected client.\n */\n\n/**\n * Connect to MongoDB using a url as documented at\n *\n *  docs.mongodb.org/manual/reference/connection-string/\n *\n * Note that for replicasets the replicaSet query parameter is required in the 2.0 driver\n *\n * @method\n * @param {MongoClient~connectCallback} [callback] The command result callback\n * @return {Promise<MongoClient>} returns Promise if no callback passed\n */\nMongoClient.prototype.connect = function(callback) {\n  // Validate options object\n  var err = validOptions(this.s.options);\n\n  if (typeof callback === 'string') {\n    throw new TypeError('`connect` only accepts a callback');\n  }\n\n  return executeOperation(this, connectOp, [this, err, callback], {\n    skipSessions: true\n  });\n};\n\nconst connectOp = (self, err, callback) => {\n  // Did we have a validation error\n  if (err) return callback(err);\n  // Fallback to callback based connect\n  connect(self, self.s.url, self.s.options, function(err) {\n    if (err) return callback(err);\n    callback(null, self);\n  });\n};\n\ndefine.classMethod('close', { callback: true, promise: true, returns: [MongoClient] });\n\n/**\n * Logout user from server, fire off on all connections and remove all auth info\n * @method\n * @param {object} [options=null] Optional settings.\n * @param {string} [options.dbName=null] Logout against different database than current.\n * @param {Db~resultCallback} [callback] The command result callback\n * @return {Promise} returns Promise if no callback passed\n */\nMongoClient.prototype.logout = function(options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  // Establish the correct database name\n  var dbName = this.s.options.authSource ? this.s.options.authSource : this.s.options.dbName;\n\n  return executeOperation(this, logout, [this, dbName, callback], {\n    skipSessions: true\n  });\n};\n\nconst logout = (self, dbName, callback) => {\n  self.topology.logout(dbName, function(err) {\n    if (err) return callback(err);\n    callback(null, true);\n  });\n};\n\ndefine.classMethod('logout', { callback: true, promise: true });\n\n/**\n * Close the db and its underlying connections\n * @method\n * @param {boolean} force Force close, emitting no events\n * @param {Db~noResultCallback} [callback] The result callback\n * @return {Promise} returns Promise if no callback passed\n */\nMongoClient.prototype.close = function(force, callback) {\n  var self = this;\n  if (typeof force === 'function') (callback = force), (force = false);\n  // Close the topologu connection\n  this.topology.close(force);\n\n  // Emit close event\n  self.emit('close', self);\n\n  // Fire close event on any cached db instances\n  for (var name in this.s.dbCache) {\n    this.s.dbCache[name].emit('close');\n  }\n\n  // Remove listeners after emit\n  self.removeAllListeners('close');\n\n  // Callback after next event loop tick\n  if (typeof callback === 'function')\n    return process.nextTick(function() {\n      handleCallback(callback, null);\n    });\n\n  // Return dummy promise\n  return new this.s.promiseLibrary(function(resolve) {\n    resolve();\n  });\n};\n\ndefine.classMethod('close', { callback: true, promise: true });\n\n/**\n * Create a new Db instance sharing the current socket connections. Be aware that the new db instances are\n * related in a parent-child relationship to the original instance so that events are correctly emitted on child\n * db instances. Child db instances are cached so performing db('db1') twice will return the same instance.\n * You can control these behaviors with the options noListener and returnNonCachedInstance.\n *\n * @method\n * @param {string} dbName The name of the database we want to use.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.noListener=false] Do not make the db an event listener to the original connection.\n * @param {boolean} [options.returnNonCachedInstance=false] Control if you want to return a cached instance or have a new one created\n * @return {Db}\n */\nMongoClient.prototype.db = function(dbName, options) {\n  options = options || {};\n\n  // Default to db from connection string if not provided\n  if (!dbName) {\n    dbName = this.s.options.dbName;\n  }\n\n  // Copy the options and add out internal override of the not shared flag\n  var finalOptions = Object.assign({}, this.s.options, options);\n\n  // Do we have the db in the cache already\n  if (this.s.dbCache[dbName] && finalOptions.returnNonCachedInstance !== true) {\n    return this.s.dbCache[dbName];\n  }\n\n  // Add promiseLibrary\n  finalOptions.promiseLibrary = this.s.promiseLibrary;\n\n  // If no topology throw an error message\n  if (!this.topology) {\n    throw new MongoError('MongoClient must be connected before calling MongoClient.prototype.db');\n  }\n\n  // Return the db object\n  var db = new Db(dbName, this.topology, finalOptions);\n\n  // Add the db to the cache\n  this.s.dbCache[dbName] = db;\n  // Return the database\n  return db;\n};\n\n/**\n * Check if MongoClient is connected\n *\n * @method\n * @param {string} name The name of the database we want to use.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.noListener=false] Do not make the db an event listener to the original connection.\n * @param {boolean} [options.returnNonCachedInstance=false] Control if you want to return a cached instance or have a new one created\n * @return {boolean}\n */\nMongoClient.prototype.isConnected = function(options) {\n  options = options || {};\n\n  if (!this.topology) return false;\n  return this.topology.isConnected(options);\n};\n\n/**\n * Connect to MongoDB using a url as documented at\n *\n *  docs.mongodb.org/manual/reference/connection-string/\n *\n * Note that for replicasets the replicaSet query parameter is required in the 2.0 driver\n *\n * @method\n * @static\n * @param {string} url The connection URI string\n * @param {object} [options] Optional settings\n * @param {number} [options.poolSize=5] The maximum size of the individual server pool\n * @param {boolean} [options.ssl=false] Enable SSL connection.\n * @param {boolean} [options.sslValidate=true] Validate mongod server certificate against Certificate Authority\n * @param {buffer} [options.sslCA=undefined] SSL Certificate store binary buffer\n * @param {buffer} [options.sslCert=undefined] SSL Certificate binary buffer\n * @param {buffer} [options.sslKey=undefined] SSL Key file binary buffer\n * @param {string} [options.sslPass=undefined] SSL Certificate pass phrase\n * @param {buffer} [options.sslCRL=undefined] SSL Certificate revocation list binary buffer\n * @param {boolean} [options.autoReconnect=true] Enable autoReconnect for single server instances\n * @param {boolean} [options.noDelay=true] TCP Connection no delay\n * @param {boolean} [options.keepAlive=true] TCP Connection keep alive enabled\n * @param {boolean} [options.keepAliveInitialDelay=30000] The number of milliseconds to wait before initiating keepAlive on the TCP socket\n * @param {number} [options.connectTimeoutMS=30000] TCP Connection timeout setting\n * @param {number} [options.family=null] Version of IP stack. Can be 4, 6 or null (default).\n * If null, will attempt to connect with IPv6, and will fall back to IPv4 on failure\n * @param {number} [options.socketTimeoutMS=360000] TCP Socket timeout setting\n * @param {number} [options.reconnectTries=30] Server attempt to reconnect #times\n * @param {number} [options.reconnectInterval=1000] Server will wait # milliseconds between retries\n * @param {boolean} [options.ha=true] Control if high availability monitoring runs for Replicaset or Mongos proxies\n * @param {number} [options.haInterval=10000] The High availability period for replicaset inquiry\n * @param {string} [options.replicaSet=undefined] The Replicaset set name\n * @param {number} [options.secondaryAcceptableLatencyMS=15] Cutoff latency point in MS for Replicaset member selection\n * @param {number} [options.acceptableLatencyMS=15] Cutoff latency point in MS for Mongos proxies selection\n * @param {boolean} [options.connectWithNoPrimary=false] Sets if the driver should connect even if no primary is available\n * @param {string} [options.authSource=undefined] Define the database to authenticate against\n * @param {(number|string)} [options.w=null] The write concern\n * @param {number} [options.wtimeout=null] The write concern timeout\n * @param {boolean} [options.j=false] Specify a journal write concern\n * @param {boolean} [options.forceServerObjectId=false] Force server to assign _id values instead of driver\n * @param {boolean} [options.serializeFunctions=false] Serialize functions on any object\n * @param {Boolean} [options.ignoreUndefined=false] Specify if the BSON serializer should ignore undefined fields\n * @param {boolean} [options.raw=false] Return document results as raw BSON buffers\n * @param {number} [options.bufferMaxEntries=-1] Sets a cap on how many operations the driver will buffer up before giving up on getting a working connection, default is -1 which is unlimited\n * @param {(ReadPreference|string)} [options.readPreference=null] The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST)\n * @param {object} [options.pkFactory=null] A primary key factory object for generation of custom _id keys\n * @param {object} [options.promiseLibrary=null] A Promise library class the application wishes to use such as Bluebird, must be ES6 compatible\n * @param {object} [options.readConcern=null] Specify a read concern for the collection (only MongoDB 3.2 or higher supported)\n * @param {string} [options.readConcern.level='local'] Specify a read concern level for the collection operations, one of [local|majority]. (only MongoDB 3.2 or higher supported)\n * @param {number} [options.maxStalenessSeconds=undefined] The max staleness to secondary reads (values under 10 seconds cannot be guaranteed)\n * @param {string} [options.loggerLevel=undefined] The logging level (error/warn/info/debug)\n * @param {object} [options.logger=undefined] Custom logger object\n * @param {boolean} [options.promoteValues=true] Promotes BSON values to native types where possible, set to false to only receive wrapper types\n * @param {boolean} [options.promoteBuffers=false] Promotes Binary BSON values to native Node Buffers\n * @param {boolean} [options.promoteLongs=true] Promotes long values to number if they fit inside the 53 bits resolution\n * @param {boolean} [options.domainsEnabled=false] Enable the wrapping of the callback in the current domain, disabled by default to avoid perf hit\n * @param {boolean|function} [options.checkServerIdentity=true] Ensure we check server identify during SSL, set to false to disable checking. Only works for Node 0.12.x or higher. You can pass in a boolean or your own checkServerIdentity override function\n * @param {object} [options.validateOptions=false] Validate MongoClient passed in options for correctness\n * @param {string} [options.appname=undefined] The name of the application that created this MongoClient instance. MongoDB 3.4 and newer will print this value in the server log upon establishing each connection. It is also recorded in the slow query log and profile collections\n * @param {string} [options.auth.user=undefined] The username for auth\n * @param {string} [options.auth.password=undefined] The password for auth\n * @param {string} [options.authMechanism=undefined] Mechanism for authentication: MDEFAULT, GSSAPI, PLAIN, MONGODB-X509, SCRAM-SHA-1 or MONGODB-CR\n * @param {object} [options.compression=null] Type of compression to use: snappy or zlib\n * @param {boolean} [options.fsync=false] Specify a file sync write concern\n * @param {array} [options.readPreferenceTags=null] Read preference tags\n * @param {number} [options.numberOfRetries=5] The number of retries for a tailable cursor\n * @param {boolean} [options.auto_reconnect=true] Enable auto reconnecting for single server instances\n * @param {MongoClient~connectCallback} [callback] The command result callback\n * @return {Promise<MongoClient>} returns Promise if no callback passed\n */\nMongoClient.connect = function(url, options, callback) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  callback = typeof args[args.length - 1] === 'function' ? args.pop() : undefined;\n  options = args.length ? args.shift() : null;\n  options = options || {};\n\n  // Create client\n  var mongoClient = new MongoClient(url, options);\n  // Execute the connect method\n  return mongoClient.connect(callback);\n};\n\ndefine.staticMethod('connect', { callback: true, promise: true });\n\n/**\n * Starts a new session on the server\n *\n * @param {object} [options] optional settings for a driver session\n * @return {ClientSession} the newly established session\n */\nMongoClient.prototype.startSession = function(options) {\n  options = options || {};\n  if (!this.topology) {\n    throw new MongoError('Must connect to a server before calling this method');\n  }\n\n  if (!this.topology.hasSessionSupport()) {\n    throw new MongoError('Current topology does not support sessions');\n  }\n\n  return this.topology.startSession(options);\n};\n\nvar mergeOptions = function(target, source, flatten) {\n  for (var name in source) {\n    if (source[name] && typeof source[name] === 'object' && flatten) {\n      target = mergeOptions(target, source[name], flatten);\n    } else {\n      target[name] = source[name];\n    }\n  }\n\n  return target;\n};\n\nvar createUnifiedOptions = function(finalOptions, options) {\n  var childOptions = [\n    'mongos',\n    'server',\n    'db',\n    'replset',\n    'db_options',\n    'server_options',\n    'rs_options',\n    'mongos_options'\n  ];\n  var noMerge = ['readconcern', 'compression'];\n\n  for (var name in options) {\n    if (noMerge.indexOf(name.toLowerCase()) !== -1) {\n      finalOptions[name] = options[name];\n    } else if (childOptions.indexOf(name.toLowerCase()) !== -1) {\n      finalOptions = mergeOptions(finalOptions, options[name], false);\n    } else {\n      if (\n        options[name] &&\n        typeof options[name] === 'object' &&\n        !Buffer.isBuffer(options[name]) &&\n        !Array.isArray(options[name])\n      ) {\n        finalOptions = mergeOptions(finalOptions, options[name], true);\n      } else {\n        finalOptions[name] = options[name];\n      }\n    }\n  }\n\n  return finalOptions;\n};\n\nfunction translateOptions(options) {\n  // If we have a readPreference passed in by the db options\n  if (typeof options.readPreference === 'string' || typeof options.read_preference === 'string') {\n    options.readPreference = new ReadPreference(options.readPreference || options.read_preference);\n  }\n\n  // Do we have readPreference tags, add them\n  if (options.readPreference && (options.readPreferenceTags || options.read_preference_tags)) {\n    options.readPreference.tags = options.readPreferenceTags || options.read_preference_tags;\n  }\n\n  // Do we have maxStalenessSeconds\n  if (options.maxStalenessSeconds) {\n    options.readPreference.maxStalenessSeconds = options.maxStalenessSeconds;\n  }\n\n  // Set the socket and connection timeouts\n  if (options.socketTimeoutMS == null) options.socketTimeoutMS = 360000;\n  if (options.connectTimeoutMS == null) options.connectTimeoutMS = 30000;\n\n  // Create server instances\n  return options.servers.map(function(serverObj) {\n    return serverObj.domain_socket\n      ? new Server(serverObj.domain_socket, 27017, options)\n      : new Server(serverObj.host, serverObj.port, options);\n  });\n}\n\nvar events = [\n  'timeout',\n  'close',\n  'serverOpening',\n  'serverDescriptionChanged',\n  'serverHeartbeatStarted',\n  'serverHeartbeatSucceeded',\n  'serverHeartbeatFailed',\n  'serverClosed',\n  'topologyOpening',\n  'topologyClosed',\n  'topologyDescriptionChanged',\n  'joined',\n  'left',\n  'ping',\n  'ha',\n  'all',\n  'fullsetup'\n];\n\n//\n// Collect all events in order from SDAM\n//\nfunction collectEvents(self, topology) {\n  var collectedEvents = [];\n\n  if (self instanceof MongoClient) {\n    events.forEach(function(event) {\n      topology.on(event, function(object1, object2) {\n        collectedEvents.push({\n          event: event,\n          object1: object1,\n          object2: object2\n        });\n      });\n    });\n  }\n\n  return collectedEvents;\n}\n\n//\n// Clear out all event\n//\nfunction clearAllEvents(topology) {\n  events.forEach(function(event) {\n    topology.removeAllListeners(event);\n  });\n}\n\n//\n// Replay any events due to single server connection switching to Mongos\n//\nfunction replayEvents(self, events) {\n  for (var i = 0; i < events.length; i++) {\n    self.emit(events[i].event, events[i].object1, events[i].object2);\n  }\n}\n\nfunction relayEvents(self, topology) {\n  var events = [\n    'serverOpening',\n    'serverDescriptionChanged',\n    'serverHeartbeatStarted',\n    'serverHeartbeatSucceeded',\n    'serverHeartbeatFailed',\n    'serverClosed',\n    'topologyOpening',\n    'topologyClosed',\n    'topologyDescriptionChanged',\n    'joined',\n    'left',\n    'ping',\n    'ha'\n  ];\n  events.forEach(function(event) {\n    topology.on(event, function(object1, object2) {\n      self.emit(event, object1, object2);\n    });\n  });\n}\n\nfunction assignTopology(client, topology) {\n  client.topology = topology;\n  topology.s.sessionPool = new ServerSessionPool(topology.s.coreTopology);\n}\n\nfunction createServer(self, options, callback) {\n  // Pass in the promise library\n  options.promiseLibrary = self.s.promiseLibrary;\n\n  // Set default options\n  var servers = translateOptions(options);\n\n  // Propagate the events to the client\n  var collectedEvents = collectEvents(self, servers[0]);\n\n  // Connect to topology\n  servers[0].connect(function(err, topology) {\n    if (err) return callback(err);\n    // Clear out all the collected event listeners\n    clearAllEvents(servers[0]);\n    // Relay all the events\n    relayEvents(self, servers[0]);\n    // Add listeners\n    addListeners(self, servers[0]);\n    // Check if we are really speaking to a mongos\n    var ismaster = topology.lastIsMaster();\n\n    // Set the topology\n    assignTopology(self, topology);\n\n    // Do we actually have a mongos\n    if (ismaster && ismaster.msg === 'isdbgrid') {\n      // Destroy the current connection\n      topology.close();\n      // Create mongos connection instead\n      return createMongos(self, options, callback);\n    }\n\n    // Fire all the events\n    replayEvents(self, collectedEvents);\n    // Otherwise callback\n    callback(err, topology);\n  });\n}\n\nfunction createReplicaset(self, options, callback) {\n  // Pass in the promise library\n  options.promiseLibrary = self.s.promiseLibrary;\n\n  // Set default options\n  var servers = translateOptions(options);\n\n  // Create the topology\n  var topology = new ReplSet(servers, options);\n\n  // Add listeners\n  addListeners(self, topology);\n\n  // Propagate the events to the client\n  relayEvents(self, topology);\n\n  // Open the connection\n  topology.connect(options, function(err, topology) {\n    if (err) return callback(err);\n\n    assignTopology(self, topology);\n    callback(null, topology);\n  });\n}\n\nfunction createMongos(self, options, callback) {\n  // Pass in the promise library\n  options.promiseLibrary = self.s.promiseLibrary;\n\n  // Set default options\n  var servers = translateOptions(options);\n\n  // Create the topology\n  var topology = new Mongos(servers, options);\n\n  // Add listeners\n  addListeners(self, topology);\n\n  // Propagate the events to the client\n  relayEvents(self, topology);\n\n  // Open the connection\n  topology.connect(options, function(err, topology) {\n    if (err) return callback(err);\n\n    assignTopology(self, topology);\n    callback(null, topology);\n  });\n}\n\nfunction createListener(self, event) {\n  return function(v1, v2) {\n    if (event === 'open' || event === 'fullsetup' || event === 'all' || event === 'reconnect') {\n      return self.emit(event, self);\n    }\n\n    self.emit(event, v1, v2);\n  };\n}\n\nfunction addListeners(self, topology) {\n  topology.on('authenticated', createListener(self, 'authenticated'));\n  topology.on('error', createListener(self, 'error'));\n  topology.on('timeout', createListener(self, 'timeout'));\n  topology.on('close', createListener(self, 'close'));\n  topology.on('parseError', createListener(self, 'parseError'));\n  topology.once('open', createListener(self, 'open'));\n  topology.once('fullsetup', createListener(self, 'fullsetup'));\n  topology.once('all', createListener(self, 'all'));\n  topology.on('reconnect', createListener(self, 'reconnect'));\n}\n\nfunction connectHandler(client, options, callback) {\n  return function(err, topology) {\n    if (err) {\n      return process.nextTick(function() {\n        try {\n          callback(err, null);\n        } catch (err) {\n          if (topology) topology.close();\n          throw err;\n        }\n      });\n    }\n\n    // No authentication just reconnect\n    if (!options.auth) {\n      return process.nextTick(function() {\n        try {\n          callback(err, topology);\n        } catch (err) {\n          if (topology) topology.close();\n          throw err;\n        }\n      });\n    }\n\n    // Authenticate\n    authenticate(client, options.user, options.password, options, function(err, success) {\n      if (success) {\n        process.nextTick(function() {\n          try {\n            callback(null, topology);\n          } catch (err) {\n            if (topology) topology.close();\n            throw err;\n          }\n        });\n      } else {\n        if (topology) topology.close();\n        process.nextTick(function() {\n          try {\n            callback(err ? err : new Error('Could not authenticate user ' + options.auth[0]), null);\n          } catch (err) {\n            if (topology) topology.close();\n            throw err;\n          }\n        });\n      }\n    });\n  };\n}\n\n/*\n * Connect using MongoClient\n */\nvar connect = function(self, url, options, callback) {\n  options = options || {};\n  options = shallowClone(options);\n\n  // If callback is null throw an exception\n  if (callback == null) {\n    throw new Error('no callback function provided');\n  }\n\n  // Get a logger for MongoClient\n  var logger = Logger('MongoClient', options);\n\n  // Did we pass in a Server/ReplSet/Mongos\n  if (url instanceof Server || url instanceof ReplSet || url instanceof Mongos) {\n    // Set the topology\n    assignTopology(self, url);\n\n    // Add listeners\n    addListeners(self, url);\n    // Connect\n    return url.connect(\n      options,\n      connectHandler(self, options, function(err, topology) {\n        if (err) return connectCallback(err, topology);\n        if (options.user || options.password || options.authMechanism) {\n          return authenticate(self, options.user, options.password, options, function(err) {\n            if (err) return connectCallback(err, topology);\n            connectCallback(err, topology);\n          });\n        }\n\n        connectCallback(err, topology);\n      })\n    );\n  }\n\n  parse(url, options, function(err, object) {\n    // Do not attempt to connect if parsing error\n    if (err) return callback(err);\n\n    // Parse the string\n    var _finalOptions = createUnifiedOptions({}, object);\n    _finalOptions = mergeOptions(_finalOptions, object, false);\n    _finalOptions = createUnifiedOptions(_finalOptions, options);\n\n    // Check if we have connection and socket timeout set\n    if (_finalOptions.socketTimeoutMS == null) _finalOptions.socketTimeoutMS = 360000;\n    if (_finalOptions.connectTimeoutMS == null) _finalOptions.connectTimeoutMS = 30000;\n\n    if (_finalOptions.db_options && _finalOptions.db_options.auth) {\n      delete _finalOptions.db_options.auth;\n    }\n\n    // Store the merged options object\n    self.s.options = _finalOptions;\n\n    // Failure modes\n    if (object.servers.length === 0) {\n      return callback(new Error('connection string must contain at least one seed host'));\n    }\n\n    // Do we have a replicaset then skip discovery and go straight to connectivity\n    if (_finalOptions.replicaSet || _finalOptions.rs_name) {\n      return createReplicaset(\n        self,\n        _finalOptions,\n        connectHandler(self, _finalOptions, connectCallback)\n      );\n    } else if (object.servers.length > 1) {\n      return createMongos(\n        self,\n        _finalOptions,\n        connectHandler(self, _finalOptions, connectCallback)\n      );\n    } else {\n      return createServer(\n        self,\n        _finalOptions,\n        connectHandler(self, _finalOptions, connectCallback)\n      );\n    }\n  });\n\n  function connectCallback(err, topology) {\n    if (err && err.message === 'no mongos proxies found in seed list') {\n      if (logger.isWarn()) {\n        logger.warn(\n          f(\n            'seed list contains no mongos proxies, replicaset connections requires the parameter replicaSet to be supplied in the URI or options object, mongodb://server:port/db?replicaSet=name'\n          )\n        );\n      }\n\n      // Return a more specific error message for MongoClient.connect\n      return callback(\n        new MongoError(\n          'seed list contains no mongos proxies, replicaset connections requires the parameter replicaSet to be supplied in the URI or options object, mongodb://server:port/db?replicaSet=name'\n        )\n      );\n    }\n\n    // Return the error and db instance\n    callback(err, topology);\n  }\n};\n\nmodule.exports = MongoClient;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\"), __webpack_require__(/*! ./../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/mongo_client.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/topologies/mongos.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoDb/lib/topologies/mongos.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nvar ServerCapabilities = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").ServerCapabilities,\n  TopologyBase = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").TopologyBase,\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  CMongos = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Mongos,\n  Cursor = __webpack_require__(/*! ../cursor */ \"./node_modules/mongoDb/lib/cursor.js\"),\n  AggregationCursor = __webpack_require__(/*! ../aggregation_cursor */ \"./node_modules/mongoDb/lib/aggregation_cursor.js\"),\n  CommandCursor = __webpack_require__(/*! ../command_cursor */ \"./node_modules/mongoDb/lib/command_cursor.js\"),\n  Define = __webpack_require__(/*! ../metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  Server = __webpack_require__(/*! ./server */ \"./node_modules/mongoDb/lib/topologies/server.js\"),\n  Store = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").Store,\n  MAX_JS_INT = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").MAX_JS_INT,\n  translateOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").translateOptions,\n  filterOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").filterOptions,\n  mergeOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").mergeOptions;\n\n/**\n * @fileOverview The **Mongos** class is a class that represents a Mongos Proxy topology and is\n * used to construct connections.\n *\n * **Mongos Should not be used, use MongoClient.connect**\n */\n\n// Allowed parameters\nvar legalOptionNames = [\n  'ha',\n  'haInterval',\n  'acceptableLatencyMS',\n  'poolSize',\n  'ssl',\n  'checkServerIdentity',\n  'sslValidate',\n  'sslCA',\n  'sslCRL',\n  'sslCert',\n  'ciphers',\n  'ecdhCurve',\n  'sslKey',\n  'sslPass',\n  'socketOptions',\n  'bufferMaxEntries',\n  'store',\n  'auto_reconnect',\n  'autoReconnect',\n  'emitError',\n  'keepAlive',\n  'keepAliveInitialDelay',\n  'noDelay',\n  'connectTimeoutMS',\n  'socketTimeoutMS',\n  'loggerLevel',\n  'logger',\n  'reconnectTries',\n  'appname',\n  'domainsEnabled',\n  'servername',\n  'promoteLongs',\n  'promoteValues',\n  'promoteBuffers',\n  'promiseLibrary'\n];\n\n/**\n * Creates a new Mongos instance\n * @class\n * @deprecated\n * @param {Server[]} servers A seedlist of servers participating in the replicaset.\n * @param {object} [options=null] Optional settings.\n * @param {booelan} [options.ha=true] Turn on high availability monitoring.\n * @param {number} [options.haInterval=5000] Time between each replicaset status check.\n * @param {number} [options.poolSize=5] Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.\n * @param {number} [options.acceptableLatencyMS=15] Cutoff latency point in MS for MongoS proxy selection\n * @param {boolean} [options.ssl=false] Use ssl connection (needs to have a mongod server with ssl support)\n * @param {boolean|function} [options.checkServerIdentity=true] Ensure we check server identify during SSL, set to false to disable checking. Only works for Node 0.12.x or higher. You can pass in a boolean or your own checkServerIdentity override function.\n * @param {object} [options.sslValidate=true] Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {array} [options.sslCA=null] Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {array} [options.sslCRL=null] Array of revocation certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {string} [options.ciphers=null] Passed directly through to tls.createSecureContext. See https://nodejs.org/dist/latest-v9.x/docs/api/tls.html#tls_tls_createsecurecontext_options for more info.\n * @param {string} [options.ecdhCurve=null] Passed directly through to tls.createSecureContext. See https://nodejs.org/dist/latest-v9.x/docs/api/tls.html#tls_tls_createsecurecontext_options for more info.\n * @param {(Buffer|string)} [options.sslCert=null] String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {(Buffer|string)} [options.sslKey=null] String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {(Buffer|string)} [options.sslPass=null] String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {string} [options.servername=null] String containing the server name requested via TLS SNI.\n * @param {object} [options.socketOptions=null] Socket options\n * @param {boolean} [options.socketOptions.noDelay=true] TCP Socket NoDelay option.\n * @param {boolean} [options.socketOptions.keepAlive=true] TCP Connection keep alive enabled\n * @param {number} [options.socketOptions.keepAliveInitialDelay=30000] The number of milliseconds to wait before initiating keepAlive on the TCP socket\n * @param {number} [options.socketOptions.connectTimeoutMS=0] TCP Connection timeout setting\n * @param {number} [options.socketOptions.socketTimeoutMS=0] TCP Socket timeout setting\n * @param {boolean} [options.domainsEnabled=false] Enable the wrapping of the callback in the current domain, disabled by default to avoid perf hit.\n * @fires Mongos#connect\n * @fires Mongos#ha\n * @fires Mongos#joined\n * @fires Mongos#left\n * @fires Mongos#fullsetup\n * @fires Mongos#open\n * @fires Mongos#close\n * @fires Mongos#error\n * @fires Mongos#timeout\n * @fires Mongos#parseError\n * @property {string} parserType the parser type used (c++ or js).\n * @return {Mongos} a Mongos instance.\n */\nclass Mongos extends TopologyBase {\n  constructor(servers, options) {\n    super();\n\n    options = options || {};\n    var self = this;\n\n    // Filter the options\n    options = filterOptions(options, legalOptionNames);\n\n    // Ensure all the instances are Server\n    for (var i = 0; i < servers.length; i++) {\n      if (!(servers[i] instanceof Server)) {\n        throw MongoError.create({\n          message: 'all seed list instances must be of the Server type',\n          driver: true\n        });\n      }\n    }\n\n    // Stored options\n    var storeOptions = {\n      force: false,\n      bufferMaxEntries:\n        typeof options.bufferMaxEntries === 'number' ? options.bufferMaxEntries : MAX_JS_INT\n    };\n\n    // Shared global store\n    var store = options.store || new Store(self, storeOptions);\n\n    // Build seed list\n    var seedlist = servers.map(function(x) {\n      return { host: x.host, port: x.port };\n    });\n\n    // Get the reconnect option\n    var reconnect = typeof options.auto_reconnect === 'boolean' ? options.auto_reconnect : true;\n    reconnect = typeof options.autoReconnect === 'boolean' ? options.autoReconnect : reconnect;\n\n    // Clone options\n    var clonedOptions = mergeOptions(\n      {},\n      {\n        disconnectHandler: store,\n        cursorFactory: Cursor,\n        reconnect: reconnect,\n        emitError: typeof options.emitError === 'boolean' ? options.emitError : true,\n        size: typeof options.poolSize === 'number' ? options.poolSize : 5\n      }\n    );\n\n    // Translate any SSL options and other connectivity options\n    clonedOptions = translateOptions(clonedOptions, options);\n\n    // Socket options\n    var socketOptions =\n      options.socketOptions && Object.keys(options.socketOptions).length > 0\n        ? options.socketOptions\n        : options;\n\n    // Translate all the options to the mongodb-core ones\n    clonedOptions = translateOptions(clonedOptions, socketOptions);\n\n    // Build default client information\n    clonedOptions.clientInfo = this.clientInfo;\n    // Do we have an application specific string\n    if (options.appname) {\n      clonedOptions.clientInfo.application = { name: options.appname };\n    }\n\n    // Internal state\n    this.s = {\n      // Create the Mongos\n      coreTopology: new CMongos(seedlist, clonedOptions),\n      // Server capabilities\n      sCapabilities: null,\n      // Debug turned on\n      debug: clonedOptions.debug,\n      // Store option defaults\n      storeOptions: storeOptions,\n      // Cloned options\n      clonedOptions: clonedOptions,\n      // Actual store of callbacks\n      store: store,\n      // Options\n      options: options,\n      // Server Session Pool\n      sessionPool: null,\n      // Active client sessions\n      sessions: [],\n      // Promise library\n      promiseLibrary: options.promiseLibrary || Promise\n    };\n  }\n\n  // Connect\n  connect(_options, callback) {\n    var self = this;\n    if ('function' === typeof _options) (callback = _options), (_options = {});\n    if (_options == null) _options = {};\n    if (!('function' === typeof callback)) callback = null;\n    _options = Object.assign({}, this.s.clonedOptions, _options);\n    self.s.options = _options;\n\n    // Update bufferMaxEntries\n    self.s.storeOptions.bufferMaxEntries =\n      typeof _options.bufferMaxEntries === 'number' ? _options.bufferMaxEntries : -1;\n\n    // Error handler\n    var connectErrorHandler = function() {\n      return function(err) {\n        // Remove all event handlers\n        var events = ['timeout', 'error', 'close'];\n        events.forEach(function(e) {\n          self.removeListener(e, connectErrorHandler);\n        });\n\n        self.s.coreTopology.removeListener('connect', connectErrorHandler);\n        // Force close the topology\n        self.close(true);\n\n        // Try to callback\n        try {\n          callback(err);\n        } catch (err) {\n          process.nextTick(function() {\n            throw err;\n          });\n        }\n      };\n    };\n\n    // Actual handler\n    var errorHandler = function(event) {\n      return function(err) {\n        if (event !== 'error') {\n          self.emit(event, err);\n        }\n      };\n    };\n\n    // Error handler\n    var reconnectHandler = function() {\n      self.emit('reconnect');\n      self.s.store.execute();\n    };\n\n    // relay the event\n    var relay = function(event) {\n      return function(t, server) {\n        self.emit(event, t, server);\n      };\n    };\n\n    // Connect handler\n    var connectHandler = function() {\n      // Clear out all the current handlers left over\n      var events = ['timeout', 'error', 'close', 'fullsetup'];\n      events.forEach(function(e) {\n        self.s.coreTopology.removeAllListeners(e);\n      });\n\n      // Set up listeners\n      self.s.coreTopology.once('timeout', errorHandler('timeout'));\n      self.s.coreTopology.once('error', errorHandler('error'));\n      self.s.coreTopology.once('close', errorHandler('close'));\n\n      // Set up serverConfig listeners\n      self.s.coreTopology.on('fullsetup', function() {\n        self.emit('fullsetup', self);\n      });\n\n      // Emit open event\n      self.emit('open', null, self);\n\n      // Return correctly\n      try {\n        callback(null, self);\n      } catch (err) {\n        process.nextTick(function() {\n          throw err;\n        });\n      }\n    };\n\n    // Clear out all the current handlers left over\n    var events = [\n      'timeout',\n      'error',\n      'close',\n      'serverOpening',\n      'serverDescriptionChanged',\n      'serverHeartbeatStarted',\n      'serverHeartbeatSucceeded',\n      'serverHeartbeatFailed',\n      'serverClosed',\n      'topologyOpening',\n      'topologyClosed',\n      'topologyDescriptionChanged'\n    ];\n    events.forEach(function(e) {\n      self.s.coreTopology.removeAllListeners(e);\n    });\n\n    // Set up SDAM listeners\n    self.s.coreTopology.on('serverDescriptionChanged', relay('serverDescriptionChanged'));\n    self.s.coreTopology.on('serverHeartbeatStarted', relay('serverHeartbeatStarted'));\n    self.s.coreTopology.on('serverHeartbeatSucceeded', relay('serverHeartbeatSucceeded'));\n    self.s.coreTopology.on('serverHeartbeatFailed', relay('serverHeartbeatFailed'));\n    self.s.coreTopology.on('serverOpening', relay('serverOpening'));\n    self.s.coreTopology.on('serverClosed', relay('serverClosed'));\n    self.s.coreTopology.on('topologyOpening', relay('topologyOpening'));\n    self.s.coreTopology.on('topologyClosed', relay('topologyClosed'));\n    self.s.coreTopology.on('topologyDescriptionChanged', relay('topologyDescriptionChanged'));\n\n    // Set up listeners\n    self.s.coreTopology.once('timeout', connectErrorHandler('timeout'));\n    self.s.coreTopology.once('error', connectErrorHandler('error'));\n    self.s.coreTopology.once('close', connectErrorHandler('close'));\n    self.s.coreTopology.once('connect', connectHandler);\n    // Join and leave events\n    self.s.coreTopology.on('joined', relay('joined'));\n    self.s.coreTopology.on('left', relay('left'));\n\n    // Reconnect server\n    self.s.coreTopology.on('reconnect', reconnectHandler);\n\n    // Start connection\n    self.s.coreTopology.connect(_options);\n  }\n}\n\nObject.defineProperty(Mongos.prototype, 'haInterval', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.s.haInterval;\n  }\n});\n\nconst define = (Mongos.define = new Define('Mongos', Mongos, false));\ndefine.classMethod('capabilities', {\n  callback: false,\n  promise: false,\n  returns: [ServerCapabilities]\n});\n\ndefine.classMethod('command', { callback: true, promise: false });\ndefine.classMethod('insert', { callback: true, promise: false });\ndefine.classMethod('update', { callback: true, promise: false });\ndefine.classMethod('remove', { callback: true, promise: false });\ndefine.classMethod('isConnected', { callback: false, promise: false, returns: [Boolean] });\ndefine.classMethod('isDestroyed', { callback: false, promise: false, returns: [Boolean] });\ndefine.classMethod('cursor', {\n  callback: false,\n  promise: false,\n  returns: [Cursor, AggregationCursor, CommandCursor]\n});\n\ndefine.classMethod('close', { callback: false, promise: false });\ndefine.classMethod('auth', { callback: true, promise: false });\ndefine.classMethod('logout', { callback: true, promise: false });\ndefine.classMethod('connections', { callback: false, promise: false, returns: [Array] });\n\n/**\n * A mongos connect event, used to verify that the connection is up and running\n *\n * @event Mongos#connect\n * @type {Mongos}\n */\n\n/**\n * The mongos high availability event\n *\n * @event Mongos#ha\n * @type {function}\n * @param {string} type The stage in the high availability event (start|end)\n * @param {boolean} data.norepeat This is a repeating high availability process or a single execution only\n * @param {number} data.id The id for this high availability request\n * @param {object} data.state An object containing the information about the current replicaset\n */\n\n/**\n * A server member left the mongos set\n *\n * @event Mongos#left\n * @type {function}\n * @param {string} type The type of member that left (primary|secondary|arbiter)\n * @param {Server} server The server object that left\n */\n\n/**\n * A server member joined the mongos set\n *\n * @event Mongos#joined\n * @type {function}\n * @param {string} type The type of member that joined (primary|secondary|arbiter)\n * @param {Server} server The server object that joined\n */\n\n/**\n * Mongos fullsetup event, emitted when all proxies in the topology have been connected to.\n *\n * @event Mongos#fullsetup\n * @type {Mongos}\n */\n\n/**\n * Mongos open event, emitted when mongos can start processing commands.\n *\n * @event Mongos#open\n * @type {Mongos}\n */\n\n/**\n * Mongos close event\n *\n * @event Mongos#close\n * @type {object}\n */\n\n/**\n * Mongos error event, emitted if there is an error listener.\n *\n * @event Mongos#error\n * @type {MongoError}\n */\n\n/**\n * Mongos timeout event\n *\n * @event Mongos#timeout\n * @type {object}\n */\n\n/**\n * Mongos parseError event\n *\n * @event Mongos#parseError\n * @type {object}\n */\n\nmodule.exports = Mongos;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/topologies/mongos.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/topologies/replset.js":
/*!********************************************************!*\
  !*** ./node_modules/mongoDb/lib/topologies/replset.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nvar Server = __webpack_require__(/*! ./server */ \"./node_modules/mongoDb/lib/topologies/server.js\"),\n  Cursor = __webpack_require__(/*! ../cursor */ \"./node_modules/mongoDb/lib/cursor.js\"),\n  AggregationCursor = __webpack_require__(/*! ../aggregation_cursor */ \"./node_modules/mongoDb/lib/aggregation_cursor.js\"),\n  CommandCursor = __webpack_require__(/*! ../command_cursor */ \"./node_modules/mongoDb/lib/command_cursor.js\"),\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  ServerCapabilities = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").ServerCapabilities,\n  TopologyBase = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").TopologyBase,\n  Store = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").Store,\n  Define = __webpack_require__(/*! ../metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  CReplSet = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReplSet,\n  MAX_JS_INT = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").MAX_JS_INT,\n  translateOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").translateOptions,\n  filterOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").filterOptions,\n  mergeOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").mergeOptions;\n\n/**\n * @fileOverview The **ReplSet** class is a class that represents a Replicaset topology and is\n * used to construct connections.\n *\n * **ReplSet Should not be used, use MongoClient.connect**\n */\n\n// Allowed parameters\nvar legalOptionNames = [\n  'ha',\n  'haInterval',\n  'replicaSet',\n  'rs_name',\n  'secondaryAcceptableLatencyMS',\n  'connectWithNoPrimary',\n  'poolSize',\n  'ssl',\n  'checkServerIdentity',\n  'sslValidate',\n  'sslCA',\n  'sslCert',\n  'ciphers',\n  'ecdhCurve',\n  'sslCRL',\n  'sslKey',\n  'sslPass',\n  'socketOptions',\n  'bufferMaxEntries',\n  'store',\n  'auto_reconnect',\n  'autoReconnect',\n  'emitError',\n  'keepAlive',\n  'keepAliveInitialDelay',\n  'noDelay',\n  'connectTimeoutMS',\n  'socketTimeoutMS',\n  'strategy',\n  'debug',\n  'family',\n  'loggerLevel',\n  'logger',\n  'reconnectTries',\n  'appname',\n  'domainsEnabled',\n  'servername',\n  'promoteLongs',\n  'promoteValues',\n  'promoteBuffers',\n  'maxStalenessSeconds',\n  'promiseLibrary',\n  'minSize'\n];\n\n/**\n * Creates a new ReplSet instance\n * @class\n * @deprecated\n * @param {Server[]} servers A seedlist of servers participating in the replicaset.\n * @param {object} [options=null] Optional settings.\n * @param {boolean} [options.ha=true] Turn on high availability monitoring.\n * @param {number} [options.haInterval=10000] Time between each replicaset status check.\n * @param {string} [options.replicaSet] The name of the replicaset to connect to.\n * @param {number} [options.secondaryAcceptableLatencyMS=15] Sets the range of servers to pick when using NEAREST (lowest ping ms + the latency fence, ex: range of 1 to (1 + 15) ms)\n * @param {boolean} [options.connectWithNoPrimary=false] Sets if the driver should connect even if no primary is available\n * @param {number} [options.poolSize=5] Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.\n * @param {boolean} [options.ssl=false] Use ssl connection (needs to have a mongod server with ssl support)\n * @param {boolean|function} [options.checkServerIdentity=true] Ensure we check server identify during SSL, set to false to disable checking. Only works for Node 0.12.x or higher. You can pass in a boolean or your own checkServerIdentity override function.\n * @param {object} [options.sslValidate=true] Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {array} [options.sslCA=null] Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {array} [options.sslCRL=null] Array of revocation certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {(Buffer|string)} [options.sslCert=null] String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher.\n * @param {string} [options.ciphers=null] Passed directly through to tls.createSecureContext. See https://nodejs.org/dist/latest-v9.x/docs/api/tls.html#tls_tls_createsecurecontext_options for more info.\n * @param {string} [options.ecdhCurve=null] Passed directly through to tls.createSecureContext. See https://nodejs.org/dist/latest-v9.x/docs/api/tls.html#tls_tls_createsecurecontext_options for more info.\n * @param {(Buffer|string)} [options.sslKey=null] String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {(Buffer|string)} [options.sslPass=null] String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {string} [options.servername=null] String containing the server name requested via TLS SNI.\n * @param {object} [options.socketOptions=null] Socket options\n * @param {boolean} [options.socketOptions.noDelay=true] TCP Socket NoDelay option.\n * @param {boolean} [options.socketOptions.keepAlive=true] TCP Connection keep alive enabled\n * @param {number} [options.socketOptions.keepAliveInitialDelay=30000] The number of milliseconds to wait before initiating keepAlive on the TCP socket\n * @param {number} [options.socketOptions.connectTimeoutMS=10000] TCP Connection timeout setting\n * @param {number} [options.socketOptions.socketTimeoutMS=0] TCP Socket timeout setting\n * @param {boolean} [options.domainsEnabled=false] Enable the wrapping of the callback in the current domain, disabled by default to avoid perf hit.\n * @param {number} [options.maxStalenessSeconds=undefined] The max staleness to secondary reads (values under 10 seconds cannot be guaranteed);\n * @fires ReplSet#connect\n * @fires ReplSet#ha\n * @fires ReplSet#joined\n * @fires ReplSet#left\n * @fires ReplSet#fullsetup\n * @fires ReplSet#open\n * @fires ReplSet#close\n * @fires ReplSet#error\n * @fires ReplSet#timeout\n * @fires ReplSet#parseError\n * @property {string} parserType the parser type used (c++ or js).\n * @return {ReplSet} a ReplSet instance.\n */\nclass ReplSet extends TopologyBase {\n  constructor(servers, options) {\n    super();\n\n    options = options || {};\n    var self = this;\n\n    // Filter the options\n    options = filterOptions(options, legalOptionNames);\n\n    // Ensure all the instances are Server\n    for (var i = 0; i < servers.length; i++) {\n      if (!(servers[i] instanceof Server)) {\n        throw MongoError.create({\n          message: 'all seed list instances must be of the Server type',\n          driver: true\n        });\n      }\n    }\n\n    // Stored options\n    var storeOptions = {\n      force: false,\n      bufferMaxEntries:\n        typeof options.bufferMaxEntries === 'number' ? options.bufferMaxEntries : MAX_JS_INT\n    };\n\n    // Shared global store\n    var store = options.store || new Store(self, storeOptions);\n\n    // Build seed list\n    var seedlist = servers.map(function(x) {\n      return { host: x.host, port: x.port };\n    });\n\n    // Clone options\n    var clonedOptions = mergeOptions(\n      {},\n      {\n        disconnectHandler: store,\n        cursorFactory: Cursor,\n        reconnect: false,\n        emitError: typeof options.emitError === 'boolean' ? options.emitError : true,\n        size: typeof options.poolSize === 'number' ? options.poolSize : 5\n      }\n    );\n\n    // Translate any SSL options and other connectivity options\n    clonedOptions = translateOptions(clonedOptions, options);\n\n    // Socket options\n    var socketOptions =\n      options.socketOptions && Object.keys(options.socketOptions).length > 0\n        ? options.socketOptions\n        : options;\n\n    // Translate all the options to the mongodb-core ones\n    clonedOptions = translateOptions(clonedOptions, socketOptions);\n\n    // Build default client information\n    clonedOptions.clientInfo = this.clientInfo;\n    // Do we have an application specific string\n    if (options.appname) {\n      clonedOptions.clientInfo.application = { name: options.appname };\n    }\n\n    // Create the ReplSet\n    var coreTopology = new CReplSet(seedlist, clonedOptions);\n\n    // Listen to reconnect event\n    coreTopology.on('reconnect', function() {\n      self.emit('reconnect');\n      store.execute();\n    });\n\n    // Internal state\n    this.s = {\n      // Replicaset\n      coreTopology: coreTopology,\n      // Server capabilities\n      sCapabilities: null,\n      // Debug tag\n      tag: options.tag,\n      // Store options\n      storeOptions: storeOptions,\n      // Cloned options\n      clonedOptions: clonedOptions,\n      // Store\n      store: store,\n      // Options\n      options: options,\n      // Server Session Pool\n      sessionPool: null,\n      // Active client sessions\n      sessions: [],\n      // Promise library\n      promiseLibrary: options.promiseLibrary || Promise\n    };\n\n    // Debug\n    if (clonedOptions.debug) {\n      // Last ismaster\n      Object.defineProperty(this, 'replset', {\n        enumerable: true,\n        get: function() {\n          return coreTopology;\n        }\n      });\n    }\n  }\n\n  // Connect method\n  connect(_options, callback) {\n    var self = this;\n    if ('function' === typeof _options) (callback = _options), (_options = {});\n    if (_options == null) _options = {};\n    if (!('function' === typeof callback)) callback = null;\n    _options = Object.assign({}, this.s.clonedOptions, _options);\n    self.s.options = _options;\n\n    // Update bufferMaxEntries\n    self.s.storeOptions.bufferMaxEntries =\n      typeof _options.bufferMaxEntries === 'number' ? _options.bufferMaxEntries : -1;\n\n    // Actual handler\n    var errorHandler = function(event) {\n      return function(err) {\n        if (event !== 'error') {\n          self.emit(event, err);\n        }\n      };\n    };\n\n    // Clear out all the current handlers left over\n    var events = [\n      'timeout',\n      'error',\n      'close',\n      'serverOpening',\n      'serverDescriptionChanged',\n      'serverHeartbeatStarted',\n      'serverHeartbeatSucceeded',\n      'serverHeartbeatFailed',\n      'serverClosed',\n      'topologyOpening',\n      'topologyClosed',\n      'topologyDescriptionChanged',\n      'joined',\n      'left',\n      'ping',\n      'ha'\n    ];\n    events.forEach(function(e) {\n      self.s.coreTopology.removeAllListeners(e);\n    });\n\n    // relay the event\n    var relay = function(event) {\n      return function(t, server) {\n        self.emit(event, t, server);\n      };\n    };\n\n    // Replset events relay\n    var replsetRelay = function(event) {\n      return function(t, server) {\n        self.emit(event, t, server.lastIsMaster(), server);\n      };\n    };\n\n    // Relay ha\n    var relayHa = function(t, state) {\n      self.emit('ha', t, state);\n\n      if (t === 'start') {\n        self.emit('ha_connect', t, state);\n      } else if (t === 'end') {\n        self.emit('ha_ismaster', t, state);\n      }\n    };\n\n    // Set up serverConfig listeners\n    self.s.coreTopology.on('joined', replsetRelay('joined'));\n    self.s.coreTopology.on('left', relay('left'));\n    self.s.coreTopology.on('ping', relay('ping'));\n    self.s.coreTopology.on('ha', relayHa);\n\n    // Set up SDAM listeners\n    self.s.coreTopology.on('serverDescriptionChanged', relay('serverDescriptionChanged'));\n    self.s.coreTopology.on('serverHeartbeatStarted', relay('serverHeartbeatStarted'));\n    self.s.coreTopology.on('serverHeartbeatSucceeded', relay('serverHeartbeatSucceeded'));\n    self.s.coreTopology.on('serverHeartbeatFailed', relay('serverHeartbeatFailed'));\n    self.s.coreTopology.on('serverOpening', relay('serverOpening'));\n    self.s.coreTopology.on('serverClosed', relay('serverClosed'));\n    self.s.coreTopology.on('topologyOpening', relay('topologyOpening'));\n    self.s.coreTopology.on('topologyClosed', relay('topologyClosed'));\n    self.s.coreTopology.on('topologyDescriptionChanged', relay('topologyDescriptionChanged'));\n\n    self.s.coreTopology.on('fullsetup', function() {\n      self.emit('fullsetup', self, self);\n    });\n\n    self.s.coreTopology.on('all', function() {\n      self.emit('all', null, self);\n    });\n\n    // Connect handler\n    var connectHandler = function() {\n      // Set up listeners\n      self.s.coreTopology.once('timeout', errorHandler('timeout'));\n      self.s.coreTopology.once('error', errorHandler('error'));\n      self.s.coreTopology.once('close', errorHandler('close'));\n\n      // Emit open event\n      self.emit('open', null, self);\n\n      // Return correctly\n      try {\n        callback(null, self);\n      } catch (err) {\n        process.nextTick(function() {\n          throw err;\n        });\n      }\n    };\n\n    // Error handler\n    var connectErrorHandler = function() {\n      return function(err) {\n        ['timeout', 'error', 'close'].forEach(function(e) {\n          self.s.coreTopology.removeListener(e, connectErrorHandler);\n        });\n\n        self.s.coreTopology.removeListener('connect', connectErrorHandler);\n        // Destroy the replset\n        self.s.coreTopology.destroy();\n\n        // Try to callback\n        try {\n          callback(err);\n        } catch (err) {\n          if (!self.s.coreTopology.isConnected())\n            process.nextTick(function() {\n              throw err;\n            });\n        }\n      };\n    };\n\n    // Set up listeners\n    self.s.coreTopology.once('timeout', connectErrorHandler('timeout'));\n    self.s.coreTopology.once('error', connectErrorHandler('error'));\n    self.s.coreTopology.once('close', connectErrorHandler('close'));\n    self.s.coreTopology.once('connect', connectHandler);\n\n    // Start connection\n    self.s.coreTopology.connect(_options);\n  }\n\n  close(forceClosed) {\n    super.close(forceClosed);\n\n    ['timeout', 'error', 'close', 'joined', 'left'].forEach(e => this.removeAllListeners(e));\n  }\n}\n\nObject.defineProperty(ReplSet.prototype, 'haInterval', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.s.haInterval;\n  }\n});\n\nconst define = (ReplSet.define = new Define('ReplSet', ReplSet, false));\ndefine.classMethod('capabilities', {\n  callback: false,\n  promise: false,\n  returns: [ServerCapabilities]\n});\n\ndefine.classMethod('command', { callback: true, promise: false });\ndefine.classMethod('insert', { callback: true, promise: false });\ndefine.classMethod('update', { callback: true, promise: false });\ndefine.classMethod('remove', { callback: true, promise: false });\ndefine.classMethod('isConnected', { callback: false, promise: false, returns: [Boolean] });\ndefine.classMethod('cursor', {\n  callback: false,\n  promise: false,\n  returns: [Cursor, AggregationCursor, CommandCursor]\n});\n\ndefine.classMethod('close', { callback: false, promise: false });\ndefine.classMethod('auth', { callback: true, promise: false });\ndefine.classMethod('logout', { callback: true, promise: false });\ndefine.classMethod('connections', { callback: false, promise: false, returns: [Array] });\n\n/**\n * A replset connect event, used to verify that the connection is up and running\n *\n * @event ReplSet#connect\n * @type {ReplSet}\n */\n\n/**\n * The replset high availability event\n *\n * @event ReplSet#ha\n * @type {function}\n * @param {string} type The stage in the high availability event (start|end)\n * @param {boolean} data.norepeat This is a repeating high availability process or a single execution only\n * @param {number} data.id The id for this high availability request\n * @param {object} data.state An object containing the information about the current replicaset\n */\n\n/**\n * A server member left the replicaset\n *\n * @event ReplSet#left\n * @type {function}\n * @param {string} type The type of member that left (primary|secondary|arbiter)\n * @param {Server} server The server object that left\n */\n\n/**\n * A server member joined the replicaset\n *\n * @event ReplSet#joined\n * @type {function}\n * @param {string} type The type of member that joined (primary|secondary|arbiter)\n * @param {Server} server The server object that joined\n */\n\n/**\n * ReplSet open event, emitted when replicaset can start processing commands.\n *\n * @event ReplSet#open\n * @type {Replset}\n */\n\n/**\n * ReplSet fullsetup event, emitted when all servers in the topology have been connected to.\n *\n * @event ReplSet#fullsetup\n * @type {Replset}\n */\n\n/**\n * ReplSet close event\n *\n * @event ReplSet#close\n * @type {object}\n */\n\n/**\n * ReplSet error event, emitted if there is an error listener.\n *\n * @event ReplSet#error\n * @type {MongoError}\n */\n\n/**\n * ReplSet timeout event\n *\n * @event ReplSet#timeout\n * @type {object}\n */\n\n/**\n * ReplSet parseError event\n *\n * @event ReplSet#parseError\n * @type {object}\n */\n\nmodule.exports = ReplSet;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/topologies/replset.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/topologies/server.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongoDb/lib/topologies/server.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nvar CServer = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Server,\n  Cursor = __webpack_require__(/*! ../cursor */ \"./node_modules/mongoDb/lib/cursor.js\"),\n  AggregationCursor = __webpack_require__(/*! ../aggregation_cursor */ \"./node_modules/mongoDb/lib/aggregation_cursor.js\"),\n  CommandCursor = __webpack_require__(/*! ../command_cursor */ \"./node_modules/mongoDb/lib/command_cursor.js\"),\n  ServerCapabilities = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").ServerCapabilities,\n  TopologyBase = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").TopologyBase,\n  Store = __webpack_require__(/*! ./topology_base */ \"./node_modules/mongoDb/lib/topologies/topology_base.js\").Store,\n  Define = __webpack_require__(/*! ../metadata */ \"./node_modules/mongoDb/lib/metadata.js\"),\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  MAX_JS_INT = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").MAX_JS_INT,\n  translateOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").translateOptions,\n  filterOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").filterOptions,\n  mergeOptions = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").mergeOptions;\n\n/**\n * @fileOverview The **Server** class is a class that represents a single server topology and is\n * used to construct connections.\n *\n * **Server Should not be used, use MongoClient.connect**\n */\n\n// Allowed parameters\nvar legalOptionNames = [\n  'ha',\n  'haInterval',\n  'acceptableLatencyMS',\n  'poolSize',\n  'ssl',\n  'checkServerIdentity',\n  'sslValidate',\n  'sslCA',\n  'sslCRL',\n  'sslCert',\n  'ciphers',\n  'ecdhCurve',\n  'sslKey',\n  'sslPass',\n  'socketOptions',\n  'bufferMaxEntries',\n  'store',\n  'auto_reconnect',\n  'autoReconnect',\n  'emitError',\n  'keepAlive',\n  'keepAliveInitialDelay',\n  'noDelay',\n  'connectTimeoutMS',\n  'socketTimeoutMS',\n  'family',\n  'loggerLevel',\n  'logger',\n  'reconnectTries',\n  'reconnectInterval',\n  'monitoring',\n  'appname',\n  'domainsEnabled',\n  'servername',\n  'promoteLongs',\n  'promoteValues',\n  'promoteBuffers',\n  'compression',\n  'promiseLibrary'\n];\n\n/**\n * Creates a new Server instance\n * @class\n * @deprecated\n * @param {string} host The host for the server, can be either an IP4, IP6 or domain socket style host.\n * @param {number} [port] The server port if IP4.\n * @param {object} [options=null] Optional settings.\n * @param {number} [options.poolSize=5] Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.\n * @param {boolean} [options.ssl=false] Use ssl connection (needs to have a mongod server with ssl support)\n * @param {object} [options.sslValidate=true] Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {boolean|function} [options.checkServerIdentity=true] Ensure we check server identify during SSL, set to false to disable checking. Only works for Node 0.12.x or higher. You can pass in a boolean or your own checkServerIdentity override function.\n * @param {array} [options.sslCA=null] Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {array} [options.sslCRL=null] Array of revocation certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {(Buffer|string)} [options.sslCert=null] String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {string} [options.ciphers=null] Passed directly through to tls.createSecureContext. See https://nodejs.org/dist/latest-v9.x/docs/api/tls.html#tls_tls_createsecurecontext_options for more info.\n * @param {string} [options.ecdhCurve=null] Passed directly through to tls.createSecureContext. See https://nodejs.org/dist/latest-v9.x/docs/api/tls.html#tls_tls_createsecurecontext_options for more info.\n * @param {(Buffer|string)} [options.sslKey=null] String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {(Buffer|string)} [options.sslPass=null] String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher)\n * @param {string} [options.servername=null] String containing the server name requested via TLS SNI.\n * @param {object} [options.socketOptions=null] Socket options\n * @param {boolean} [options.socketOptions.autoReconnect=true] Reconnect on error.\n * @param {boolean} [options.socketOptions.noDelay=true] TCP Socket NoDelay option.\n * @param {boolean} [options.socketOptions.keepAlive=true] TCP Connection keep alive enabled\n * @param {number} [options.socketOptions.keepAliveInitialDelay=30000] The number of milliseconds to wait before initiating keepAlive on the TCP socket\n * @param {number} [options.socketOptions.connectTimeoutMS=0] TCP Connection timeout setting\n * @param {number} [options.socketOptions.socketTimeoutMS=0] TCP Socket timeout setting\n * @param {number} [options.reconnectTries=30] Server attempt to reconnect #times\n * @param {number} [options.reconnectInterval=1000] Server will wait # milliseconds between retries\n * @param {number} [options.monitoring=true] Triggers the server instance to call ismaster\n * @param {number} [options.haInterval=10000] The interval of calling ismaster when monitoring is enabled.\n * @param {boolean} [options.domainsEnabled=false] Enable the wrapping of the callback in the current domain, disabled by default to avoid perf hit.\n * @fires Server#connect\n * @fires Server#close\n * @fires Server#error\n * @fires Server#timeout\n * @fires Server#parseError\n * @fires Server#reconnect\n * @property {string} parserType the parser type used (c++ or js).\n * @return {Server} a Server instance.\n */\nclass Server extends TopologyBase {\n  constructor(host, port, options) {\n    super();\n    var self = this;\n\n    // Filter the options\n    options = filterOptions(options, legalOptionNames);\n\n    // Promise library\n    const promiseLibrary = options.promiseLibrary;\n\n    // Stored options\n    var storeOptions = {\n      force: false,\n      bufferMaxEntries:\n        typeof options.bufferMaxEntries === 'number' ? options.bufferMaxEntries : MAX_JS_INT\n    };\n\n    // Shared global store\n    var store = options.store || new Store(self, storeOptions);\n\n    // Detect if we have a socket connection\n    if (host.indexOf('/') !== -1) {\n      if (port != null && typeof port === 'object') {\n        options = port;\n        port = null;\n      }\n    } else if (port == null) {\n      throw MongoError.create({ message: 'port must be specified', driver: true });\n    }\n\n    // Get the reconnect option\n    var reconnect = typeof options.auto_reconnect === 'boolean' ? options.auto_reconnect : true;\n    reconnect = typeof options.autoReconnect === 'boolean' ? options.autoReconnect : reconnect;\n\n    // Clone options\n    var clonedOptions = mergeOptions(\n      {},\n      {\n        host: host,\n        port: port,\n        disconnectHandler: store,\n        cursorFactory: Cursor,\n        reconnect: reconnect,\n        emitError: typeof options.emitError === 'boolean' ? options.emitError : true,\n        size: typeof options.poolSize === 'number' ? options.poolSize : 5\n      }\n    );\n\n    // Translate any SSL options and other connectivity options\n    clonedOptions = translateOptions(clonedOptions, options);\n\n    // Socket options\n    var socketOptions =\n      options.socketOptions && Object.keys(options.socketOptions).length > 0\n        ? options.socketOptions\n        : options;\n\n    // Translate all the options to the mongodb-core ones\n    clonedOptions = translateOptions(clonedOptions, socketOptions);\n\n    // Build default client information\n    clonedOptions.clientInfo = this.clientInfo;\n    // Do we have an application specific string\n    if (options.appname) {\n      clonedOptions.clientInfo.application = { name: options.appname };\n    }\n\n    // Define the internal properties\n    this.s = {\n      // Create an instance of a server instance from mongodb-core\n      coreTopology: new CServer(clonedOptions),\n      // Server capabilities\n      sCapabilities: null,\n      // Cloned options\n      clonedOptions: clonedOptions,\n      // Reconnect\n      reconnect: clonedOptions.reconnect,\n      // Emit error\n      emitError: clonedOptions.emitError,\n      // Pool size\n      poolSize: clonedOptions.size,\n      // Store Options\n      storeOptions: storeOptions,\n      // Store\n      store: store,\n      // Host\n      host: host,\n      // Port\n      port: port,\n      // Options\n      options: options,\n      // Server Session Pool\n      sessionPool: null,\n      // Active client sessions\n      sessions: [],\n      // Promise library\n      promiseLibrary: promiseLibrary || Promise\n    };\n  }\n\n  // Connect\n  connect(_options, callback) {\n    var self = this;\n    if ('function' === typeof _options) (callback = _options), (_options = {});\n    if (_options == null) _options = this.s.clonedOptions;\n    if (!('function' === typeof callback)) callback = null;\n    _options = Object.assign({}, this.s.clonedOptions, _options);\n    self.s.options = _options;\n\n    // Update bufferMaxEntries\n    self.s.storeOptions.bufferMaxEntries =\n      typeof _options.bufferMaxEntries === 'number' ? _options.bufferMaxEntries : -1;\n\n    // Error handler\n    var connectErrorHandler = function() {\n      return function(err) {\n        // Remove all event handlers\n        var events = ['timeout', 'error', 'close'];\n        events.forEach(function(e) {\n          self.s.coreTopology.removeListener(e, connectHandlers[e]);\n        });\n\n        self.s.coreTopology.removeListener('connect', connectErrorHandler);\n\n        // Try to callback\n        try {\n          callback(err);\n        } catch (err) {\n          process.nextTick(function() {\n            throw err;\n          });\n        }\n      };\n    };\n\n    // Actual handler\n    var errorHandler = function(event) {\n      return function(err) {\n        if (event !== 'error') {\n          self.emit(event, err);\n        }\n      };\n    };\n\n    // Error handler\n    var reconnectHandler = function() {\n      self.emit('reconnect', self);\n      self.s.store.execute();\n    };\n\n    // Reconnect failed\n    var reconnectFailedHandler = function(err) {\n      self.emit('reconnectFailed', err);\n      self.s.store.flush(err);\n    };\n\n    // Destroy called on topology, perform cleanup\n    var destroyHandler = function() {\n      self.s.store.flush();\n    };\n\n    // relay the event\n    var relay = function(event) {\n      return function(t, server) {\n        self.emit(event, t, server);\n      };\n    };\n\n    // Connect handler\n    var connectHandler = function() {\n      // Clear out all the current handlers left over\n      ['timeout', 'error', 'close', 'destroy'].forEach(function(e) {\n        self.s.coreTopology.removeAllListeners(e);\n      });\n\n      // Set up listeners\n      self.s.coreTopology.on('timeout', errorHandler('timeout'));\n      self.s.coreTopology.once('error', errorHandler('error'));\n      self.s.coreTopology.on('close', errorHandler('close'));\n      // Only called on destroy\n      self.s.coreTopology.on('destroy', destroyHandler);\n\n      // Emit open event\n      self.emit('open', null, self);\n\n      // Return correctly\n      try {\n        callback(null, self);\n      } catch (err) {\n        console.log(err.stack);\n        process.nextTick(function() {\n          throw err;\n        });\n      }\n    };\n\n    // Set up listeners\n    var connectHandlers = {\n      timeout: connectErrorHandler('timeout'),\n      error: connectErrorHandler('error'),\n      close: connectErrorHandler('close')\n    };\n\n    // Clear out all the current handlers left over\n    [\n      'timeout',\n      'error',\n      'close',\n      'serverOpening',\n      'serverDescriptionChanged',\n      'serverHeartbeatStarted',\n      'serverHeartbeatSucceeded',\n      'serverHeartbeatFailed',\n      'serverClosed',\n      'topologyOpening',\n      'topologyClosed',\n      'topologyDescriptionChanged'\n    ].forEach(function(e) {\n      self.s.coreTopology.removeAllListeners(e);\n    });\n\n    // Add the event handlers\n    self.s.coreTopology.once('timeout', connectHandlers.timeout);\n    self.s.coreTopology.once('error', connectHandlers.error);\n    self.s.coreTopology.once('close', connectHandlers.close);\n    self.s.coreTopology.once('connect', connectHandler);\n    // Reconnect server\n    self.s.coreTopology.on('reconnect', reconnectHandler);\n    self.s.coreTopology.on('reconnectFailed', reconnectFailedHandler);\n\n    // Set up SDAM listeners\n    self.s.coreTopology.on('serverDescriptionChanged', relay('serverDescriptionChanged'));\n    self.s.coreTopology.on('serverHeartbeatStarted', relay('serverHeartbeatStarted'));\n    self.s.coreTopology.on('serverHeartbeatSucceeded', relay('serverHeartbeatSucceeded'));\n    self.s.coreTopology.on('serverHeartbeatFailed', relay('serverHeartbeatFailed'));\n    self.s.coreTopology.on('serverOpening', relay('serverOpening'));\n    self.s.coreTopology.on('serverClosed', relay('serverClosed'));\n    self.s.coreTopology.on('topologyOpening', relay('topologyOpening'));\n    self.s.coreTopology.on('topologyClosed', relay('topologyClosed'));\n    self.s.coreTopology.on('topologyDescriptionChanged', relay('topologyDescriptionChanged'));\n    self.s.coreTopology.on('attemptReconnect', relay('attemptReconnect'));\n    self.s.coreTopology.on('monitoring', relay('monitoring'));\n\n    // Start connection\n    self.s.coreTopology.connect(_options);\n  }\n}\n\nObject.defineProperty(Server.prototype, 'poolSize', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.connections().length;\n  }\n});\n\nObject.defineProperty(Server.prototype, 'autoReconnect', {\n  enumerable: true,\n  get: function() {\n    return this.s.reconnect;\n  }\n});\n\nObject.defineProperty(Server.prototype, 'host', {\n  enumerable: true,\n  get: function() {\n    return this.s.host;\n  }\n});\n\nObject.defineProperty(Server.prototype, 'port', {\n  enumerable: true,\n  get: function() {\n    return this.s.port;\n  }\n});\n\nconst define = (Server.define = new Define('Server', Server, false));\ndefine.classMethod('capabilities', {\n  callback: false,\n  promise: false,\n  returns: [ServerCapabilities]\n});\n\ndefine.classMethod('command', { callback: true, promise: false });\ndefine.classMethod('insert', { callback: true, promise: false });\ndefine.classMethod('update', { callback: true, promise: false });\ndefine.classMethod('remove', { callback: true, promise: false });\ndefine.classMethod('isConnected', { callback: false, promise: false, returns: [Boolean] });\ndefine.classMethod('isDestroyed', { callback: false, promise: false, returns: [Boolean] });\ndefine.classMethod('cursor', {\n  callback: false,\n  promise: false,\n  returns: [Cursor, AggregationCursor, CommandCursor]\n});\n\ndefine.classMethod('close', { callback: false, promise: false });\ndefine.classMethod('auth', { callback: true, promise: false });\ndefine.classMethod('logout', { callback: true, promise: false });\ndefine.classMethod('connections', { callback: false, promise: false, returns: [Array] });\n\n/**\n * Server connect event\n *\n * @event Server#connect\n * @type {object}\n */\n\n/**\n * Server close event\n *\n * @event Server#close\n * @type {object}\n */\n\n/**\n * Server reconnect event\n *\n * @event Server#reconnect\n * @type {object}\n */\n\n/**\n * Server error event\n *\n * @event Server#error\n * @type {MongoError}\n */\n\n/**\n * Server timeout event\n *\n * @event Server#timeout\n * @type {object}\n */\n\n/**\n * Server parseError event\n *\n * @event Server#parseError\n * @type {object}\n */\n\nmodule.exports = Server;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/topologies/server.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/topologies/topology_base.js":
/*!**************************************************************!*\
  !*** ./node_modules/mongoDb/lib/topologies/topology_base.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nconst EventEmitter = __webpack_require__(/*! events */ \"events\"),\n  MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  f = __webpack_require__(/*! util */ \"util\").format,\n  os = __webpack_require__(/*! os */ \"os\"),\n  translateReadPreference = __webpack_require__(/*! ../utils */ \"./node_modules/mongoDb/lib/utils.js\").translateReadPreference,\n  ClientSession = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Sessions.ClientSession;\n\n// The store of ops\nvar Store = function(topology, storeOptions) {\n  var self = this;\n  var storedOps = [];\n  storeOptions = storeOptions || { force: false, bufferMaxEntries: -1 };\n\n  // Internal state\n  this.s = {\n    storedOps: storedOps,\n    storeOptions: storeOptions,\n    topology: topology\n  };\n\n  Object.defineProperty(this, 'length', {\n    enumerable: true,\n    get: function() {\n      return self.s.storedOps.length;\n    }\n  });\n};\n\nStore.prototype.add = function(opType, ns, ops, options, callback) {\n  if (this.s.storeOptions.force) {\n    return callback(MongoError.create({ message: 'db closed by application', driver: true }));\n  }\n\n  if (this.s.storeOptions.bufferMaxEntries === 0) {\n    return callback(\n      MongoError.create({\n        message: f(\n          'no connection available for operation and number of stored operation > %s',\n          this.s.storeOptions.bufferMaxEntries\n        ),\n        driver: true\n      })\n    );\n  }\n\n  if (\n    this.s.storeOptions.bufferMaxEntries > 0 &&\n    this.s.storedOps.length > this.s.storeOptions.bufferMaxEntries\n  ) {\n    while (this.s.storedOps.length > 0) {\n      var op = this.s.storedOps.shift();\n      op.c(\n        MongoError.create({\n          message: f(\n            'no connection available for operation and number of stored operation > %s',\n            this.s.storeOptions.bufferMaxEntries\n          ),\n          driver: true\n        })\n      );\n    }\n\n    return;\n  }\n\n  this.s.storedOps.push({ t: opType, n: ns, o: ops, op: options, c: callback });\n};\n\nStore.prototype.addObjectAndMethod = function(opType, object, method, params, callback) {\n  if (this.s.storeOptions.force) {\n    return callback(MongoError.create({ message: 'db closed by application', driver: true }));\n  }\n\n  if (this.s.storeOptions.bufferMaxEntries === 0) {\n    return callback(\n      MongoError.create({\n        message: f(\n          'no connection available for operation and number of stored operation > %s',\n          this.s.storeOptions.bufferMaxEntries\n        ),\n        driver: true\n      })\n    );\n  }\n\n  if (\n    this.s.storeOptions.bufferMaxEntries > 0 &&\n    this.s.storedOps.length > this.s.storeOptions.bufferMaxEntries\n  ) {\n    while (this.s.storedOps.length > 0) {\n      var op = this.s.storedOps.shift();\n      op.c(\n        MongoError.create({\n          message: f(\n            'no connection available for operation and number of stored operation > %s',\n            this.s.storeOptions.bufferMaxEntries\n          ),\n          driver: true\n        })\n      );\n    }\n\n    return;\n  }\n\n  this.s.storedOps.push({ t: opType, m: method, o: object, p: params, c: callback });\n};\n\nStore.prototype.flush = function(err) {\n  while (this.s.storedOps.length > 0) {\n    this.s.storedOps\n      .shift()\n      .c(\n        err ||\n          MongoError.create({ message: f('no connection available for operation'), driver: true })\n      );\n  }\n};\n\nvar primaryOptions = ['primary', 'primaryPreferred', 'nearest', 'secondaryPreferred'];\nvar secondaryOptions = ['secondary', 'secondaryPreferred'];\n\nStore.prototype.execute = function(options) {\n  options = options || {};\n  // Get current ops\n  var ops = this.s.storedOps;\n  // Reset the ops\n  this.s.storedOps = [];\n\n  // Unpack options\n  var executePrimary = typeof options.executePrimary === 'boolean' ? options.executePrimary : true;\n  var executeSecondary =\n    typeof options.executeSecondary === 'boolean' ? options.executeSecondary : true;\n\n  // Execute all the stored ops\n  while (ops.length > 0) {\n    var op = ops.shift();\n\n    if (op.t === 'cursor') {\n      if (executePrimary && executeSecondary) {\n        op.o[op.m].apply(op.o, op.p);\n      } else if (\n        executePrimary &&\n        op.o.options &&\n        op.o.options.readPreference &&\n        primaryOptions.indexOf(op.o.options.readPreference.mode) !== -1\n      ) {\n        op.o[op.m].apply(op.o, op.p);\n      } else if (\n        !executePrimary &&\n        executeSecondary &&\n        op.o.options &&\n        op.o.options.readPreference &&\n        secondaryOptions.indexOf(op.o.options.readPreference.mode) !== -1\n      ) {\n        op.o[op.m].apply(op.o, op.p);\n      }\n    } else if (op.t === 'auth') {\n      this.s.topology[op.t].apply(this.s.topology, op.o);\n    } else {\n      if (executePrimary && executeSecondary) {\n        this.s.topology[op.t](op.n, op.o, op.op, op.c);\n      } else if (\n        executePrimary &&\n        op.op &&\n        op.op.readPreference &&\n        primaryOptions.indexOf(op.op.readPreference.mode) !== -1\n      ) {\n        this.s.topology[op.t](op.n, op.o, op.op, op.c);\n      } else if (\n        !executePrimary &&\n        executeSecondary &&\n        op.op &&\n        op.op.readPreference &&\n        secondaryOptions.indexOf(op.op.readPreference.mode) !== -1\n      ) {\n        this.s.topology[op.t](op.n, op.o, op.op, op.c);\n      }\n    }\n  }\n};\n\nStore.prototype.all = function() {\n  return this.s.storedOps;\n};\n\n// Server capabilities\nvar ServerCapabilities = function(ismaster) {\n  var setup_get_property = function(object, name, value) {\n    Object.defineProperty(object, name, {\n      enumerable: true,\n      get: function() {\n        return value;\n      }\n    });\n  };\n\n  // Capabilities\n  var aggregationCursor = false;\n  var writeCommands = false;\n  var textSearch = false;\n  var authCommands = false;\n  var listCollections = false;\n  var listIndexes = false;\n  var maxNumberOfDocsInBatch = ismaster.maxWriteBatchSize || 1000;\n  var commandsTakeWriteConcern = false;\n  var commandsTakeCollation = false;\n\n  if (ismaster.minWireVersion >= 0) {\n    textSearch = true;\n  }\n\n  if (ismaster.maxWireVersion >= 1) {\n    aggregationCursor = true;\n    authCommands = true;\n  }\n\n  if (ismaster.maxWireVersion >= 2) {\n    writeCommands = true;\n  }\n\n  if (ismaster.maxWireVersion >= 3) {\n    listCollections = true;\n    listIndexes = true;\n  }\n\n  if (ismaster.maxWireVersion >= 5) {\n    commandsTakeWriteConcern = true;\n    commandsTakeCollation = true;\n  }\n\n  // If no min or max wire version set to 0\n  if (ismaster.minWireVersion == null) {\n    ismaster.minWireVersion = 0;\n  }\n\n  if (ismaster.maxWireVersion == null) {\n    ismaster.maxWireVersion = 0;\n  }\n\n  // Map up read only parameters\n  setup_get_property(this, 'hasAggregationCursor', aggregationCursor);\n  setup_get_property(this, 'hasWriteCommands', writeCommands);\n  setup_get_property(this, 'hasTextSearch', textSearch);\n  setup_get_property(this, 'hasAuthCommands', authCommands);\n  setup_get_property(this, 'hasListCollectionsCommand', listCollections);\n  setup_get_property(this, 'hasListIndexesCommand', listIndexes);\n  setup_get_property(this, 'minWireVersion', ismaster.minWireVersion);\n  setup_get_property(this, 'maxWireVersion', ismaster.maxWireVersion);\n  setup_get_property(this, 'maxNumberOfDocsInBatch', maxNumberOfDocsInBatch);\n  setup_get_property(this, 'commandsTakeWriteConcern', commandsTakeWriteConcern);\n  setup_get_property(this, 'commandsTakeCollation', commandsTakeCollation);\n};\n\n// Get package.json variable\nconst driverVersion = __webpack_require__(/*! ../../package.json */ \"./node_modules/mongoDb/package.json\").version,\n  nodejsversion = f('Node.js %s, %s', process.version, os.endianness()),\n  type = os.type(),\n  name = process.platform,\n  architecture = process.arch,\n  release = os.release();\n\nclass TopologyBase extends EventEmitter {\n  constructor() {\n    super();\n\n    // Build default client information\n    this.clientInfo = {\n      driver: {\n        name: 'nodejs',\n        version: driverVersion\n      },\n      os: {\n        type: type,\n        name: name,\n        architecture: architecture,\n        version: release\n      },\n      platform: nodejsversion\n    };\n\n    this.setMaxListeners(Infinity);\n  }\n\n  // Sessions related methods\n  hasSessionSupport() {\n    return this.logicalSessionTimeoutMinutes != null;\n  }\n\n  startSession(options) {\n    const session = new ClientSession(this, this.s.sessionPool, options);\n    session.once('ended', () => {\n      this.s.sessions = this.s.sessions.filter(s => !s.equals(session));\n    });\n\n    this.s.sessions.push(session);\n    return session;\n  }\n\n  endSessions(sessions, callback) {\n    return this.s.coreTopology.endSessions(sessions, callback);\n  }\n\n  // Server capabilities\n  capabilities() {\n    if (this.s.sCapabilities) return this.s.sCapabilities;\n    if (this.s.coreTopology.lastIsMaster() == null) return null;\n    this.s.sCapabilities = new ServerCapabilities(this.s.coreTopology.lastIsMaster());\n    return this.s.sCapabilities;\n  }\n\n  // Command\n  command(ns, cmd, options, callback) {\n    this.s.coreTopology.command(ns, cmd, translateReadPreference(options), callback);\n  }\n\n  // Insert\n  insert(ns, ops, options, callback) {\n    this.s.coreTopology.insert(ns, ops, options, callback);\n  }\n\n  // Update\n  update(ns, ops, options, callback) {\n    this.s.coreTopology.update(ns, ops, options, callback);\n  }\n\n  // Remove\n  remove(ns, ops, options, callback) {\n    this.s.coreTopology.remove(ns, ops, options, callback);\n  }\n\n  // IsConnected\n  isConnected(options) {\n    options = options || {};\n    options = translateReadPreference(options);\n\n    return this.s.coreTopology.isConnected(options);\n  }\n\n  // IsDestroyed\n  isDestroyed() {\n    return this.s.coreTopology.isDestroyed();\n  }\n\n  // Cursor\n  cursor(ns, cmd, options) {\n    options = options || {};\n    options = translateReadPreference(options);\n    options.disconnectHandler = this.s.store;\n    options.topology = this;\n\n    return this.s.coreTopology.cursor(ns, cmd, options);\n  }\n\n  lastIsMaster() {\n    return this.s.coreTopology.lastIsMaster();\n  }\n\n  getServer(options) {\n    return this.s.coreTopology.getServer(options);\n  }\n\n  getConnection(options) {\n    return this.s.coreTopology.getConnection(options);\n  }\n\n  /**\n   * Unref all sockets\n   * @method\n   */\n  unref() {\n    return this.s.coreTopology.unref();\n  }\n\n  auth() {\n    var args = Array.prototype.slice.call(arguments, 0);\n    this.s.coreTopology.auth.apply(this.s.coreTopology, args);\n  }\n\n  logout() {\n    var args = Array.prototype.slice.call(arguments, 0);\n    this.s.coreTopology.logout.apply(this.s.coreTopology, args);\n  }\n\n  /**\n   * All raw connections\n   * @method\n   * @return {array}\n   */\n  connections() {\n    return this.s.coreTopology.connections();\n  }\n\n  close(forceClosed) {\n    // If we have sessions, we want to send a single `endSessions` command for them,\n    // and then individually clean them up.  They will be removed from the internal state\n    // when they emit their `ended` events.\n    if (this.s.sessions.length) {\n      this.endSessions(this.s.sessions.map(session => session.id));\n      this.s.sessions.forEach(session => session.endSession({ skipCommand: true }));\n    }\n\n    if (this.s.sessionPool) {\n      this.s.sessionPool.endAllPooledSessions();\n    }\n\n    this.s.coreTopology.destroy({\n      force: typeof forceClosed === 'boolean' ? forceClosed : false\n    });\n\n    // We need to wash out all stored processes\n    if (forceClosed === true) {\n      this.s.storeOptions.force = forceClosed;\n      this.s.store.flush();\n    }\n  }\n}\n\n// Properties\nObject.defineProperty(TopologyBase.prototype, 'isMasterDoc', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.lastIsMaster();\n  }\n});\n\nObject.defineProperty(TopologyBase.prototype, 'bson', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.s.bson;\n  }\n});\n\nObject.defineProperty(TopologyBase.prototype, 'parserType', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.parserType;\n  }\n});\n\nObject.defineProperty(TopologyBase.prototype, 'logicalSessionTimeoutMinutes', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.logicalSessionTimeoutMinutes;\n  }\n});\n\nObject.defineProperty(TopologyBase.prototype, 'type', {\n  enumerable: true,\n  get: function() {\n    return this.s.coreTopology.type;\n  }\n});\n\nexports.Store = Store;\nexports.ServerCapabilities = ServerCapabilities;\nexports.TopologyBase = TopologyBase;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/topologies/topology_base.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/url_parser.js":
/*!************************************************!*\
  !*** ./node_modules/mongoDb/lib/url_parser.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nconst ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference,\n  parser = __webpack_require__(/*! url */ \"url\"),\n  f = __webpack_require__(/*! util */ \"util\").format,\n  Logger = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").Logger,\n  dns = __webpack_require__(/*! dns */ \"dns\");\n\nmodule.exports = function(url, options, callback) {\n  if (typeof options === 'function') (callback = options), (options = {});\n  options = options || {};\n\n  let result;\n  try {\n    result = parser.parse(url, true);\n  } catch (e) {\n    return callback(new Error('URL malformed, cannot be parsed'));\n  }\n\n  if (result.protocol !== 'mongodb:' && result.protocol !== 'mongodb+srv:') {\n    return callback(new Error('Invalid schema, expected `mongodb` or `mongodb+srv`'));\n  }\n\n  if (result.protocol === 'mongodb:') {\n    return parseHandler(url, options, callback);\n  }\n\n  // Otherwise parse this as an SRV record\n  if (result.hostname.split('.').length < 3) {\n    return callback(new Error('URI does not have hostname, domain name and tld'));\n  }\n\n  result.domainLength = result.hostname.split('.').length;\n\n  if (result.pathname && result.pathname.match(',')) {\n    return callback(new Error('Invalid URI, cannot contain multiple hostnames'));\n  }\n\n  if (result.port) {\n    return callback(new Error('Ports not accepted with `mongodb+srv` URIs'));\n  }\n\n  let srvAddress = `_mongodb._tcp.${result.host}`;\n  dns.resolveSrv(srvAddress, function(err, addresses) {\n    if (err) return callback(err);\n\n    if (addresses.length === 0) {\n      return callback(new Error('No addresses found at host'));\n    }\n\n    for (let i = 0; i < addresses.length; i++) {\n      if (!matchesParentDomain(addresses[i].name, result.hostname, result.domainLength)) {\n        return callback(new Error('Server record does not share hostname with parent URI'));\n      }\n    }\n\n    let base = result.auth ? `mongodb://${result.auth}@` : `mongodb://`;\n    let connectionStrings = addresses.map(function(address, i) {\n      if (i === 0) return `${base}${address.name}:${address.port}`;\n      else return `${address.name}:${address.port}`;\n    });\n\n    let connectionString = connectionStrings.join(',') + '/';\n    let connectionStringOptions = [];\n\n    // Default to SSL true\n    if (!options.ssl && !result.search) {\n      connectionStringOptions.push('ssl=true');\n    } else if (!options.ssl && result.search && !result.search.match('ssl')) {\n      connectionStringOptions.push('ssl=true');\n    }\n\n    // Keep original uri options\n    if (result.search) {\n      connectionStringOptions.push(result.search.replace('?', ''));\n    }\n\n    dns.resolveTxt(result.host, function(err, record) {\n      if (err && err.code !== 'ENODATA') return callback(err);\n      if (err && err.code === 'ENODATA') record = null;\n\n      if (record) {\n        if (record.length > 1) {\n          return callback(new Error('Multiple text records not allowed'));\n        }\n\n        record = record[0];\n        if (record.length > 1) record = record.join('');\n        else record = record[0];\n\n        if (!record.includes('authSource') && !record.includes('replicaSet')) {\n          return callback(new Error('Text record must only set `authSource` or `replicaSet`'));\n        }\n\n        connectionStringOptions.push(record);\n      }\n\n      // Add any options to the connection string\n      if (connectionStringOptions.length) {\n        connectionString += `?${connectionStringOptions.join('&')}`;\n      }\n\n      parseHandler(connectionString, options, callback);\n    });\n  });\n};\n\nfunction matchesParentDomain(srvAddress, parentDomain) {\n  let regex = /^.*?\\./;\n  let srv = `.${srvAddress.replace(regex, '')}`;\n  let parent = `.${parentDomain.replace(regex, '')}`;\n  if (srv.endsWith(parent)) return true;\n  else return false;\n}\n\nfunction parseHandler(address, options, callback) {\n  let result, err;\n  try {\n    result = parseConnectionString(address, options);\n  } catch (e) {\n    err = e;\n  }\n\n  return err ? callback(err, null) : callback(null, result);\n}\n\nfunction parseConnectionString(url, options) {\n  // Variables\n  let connection_part = '';\n  let auth_part = '';\n  let query_string_part = '';\n  let dbName = 'admin';\n\n  // Url parser result\n  let result = parser.parse(url, true);\n  if ((result.hostname == null || result.hostname === '') && url.indexOf('.sock') === -1) {\n    throw new Error('No hostname or hostnames provided in connection string');\n  }\n\n  if (result.port === '0') {\n    throw new Error('Invalid port (zero) with hostname');\n  }\n\n  if (!isNaN(parseInt(result.port, 10)) && parseInt(result.port, 10) > 65535) {\n    throw new Error('Invalid port (larger than 65535) with hostname');\n  }\n\n  if (\n    result.path &&\n    result.path.length > 0 &&\n    result.path[0] !== '/' &&\n    url.indexOf('.sock') === -1\n  ) {\n    throw new Error('Missing delimiting slash between hosts and options');\n  }\n\n  if (result.query) {\n    for (let name in result.query) {\n      if (name.indexOf('::') !== -1) {\n        throw new Error('Double colon in host identifier');\n      }\n\n      if (result.query[name] === '') {\n        throw new Error('Query parameter ' + name + ' is an incomplete value pair');\n      }\n    }\n  }\n\n  if (result.auth) {\n    let parts = result.auth.split(':');\n    if (url.indexOf(result.auth) !== -1 && parts.length > 2) {\n      throw new Error('Username with password containing an unescaped colon');\n    }\n\n    if (url.indexOf(result.auth) !== -1 && result.auth.indexOf('@') !== -1) {\n      throw new Error('Username containing an unescaped at-sign');\n    }\n  }\n\n  // Remove query\n  let clean = url.split('?').shift();\n\n  // Extract the list of hosts\n  let strings = clean.split(',');\n  let hosts = [];\n\n  for (let i = 0; i < strings.length; i++) {\n    let hostString = strings[i];\n\n    if (hostString.indexOf('mongodb') !== -1) {\n      if (hostString.indexOf('@') !== -1) {\n        hosts.push(hostString.split('@').pop());\n      } else {\n        hosts.push(hostString.substr('mongodb://'.length));\n      }\n    } else if (hostString.indexOf('/') !== -1) {\n      hosts.push(hostString.split('/').shift());\n    } else if (hostString.indexOf('/') === -1) {\n      hosts.push(hostString.trim());\n    }\n  }\n\n  for (let i = 0; i < hosts.length; i++) {\n    let r = parser.parse(f('mongodb://%s', hosts[i].trim()));\n    if (r.path && r.path.indexOf(':') !== -1) {\n      // Not connecting to a socket so check for an extra slash in the hostname.\n      // Using String#split as perf is better than match.\n      if (r.path.split('/').length > 1 && r.path.indexOf('::') === -1) {\n        throw new Error('Slash in host identifier');\n      } else {\n        throw new Error('Double colon in host identifier');\n      }\n    }\n  }\n\n  // If we have a ? mark cut the query elements off\n  if (url.indexOf('?') !== -1) {\n    query_string_part = url.substr(url.indexOf('?') + 1);\n    connection_part = url.substring('mongodb://'.length, url.indexOf('?'));\n  } else {\n    connection_part = url.substring('mongodb://'.length);\n  }\n\n  // Check if we have auth params\n  if (connection_part.indexOf('@') !== -1) {\n    auth_part = connection_part.split('@')[0];\n    connection_part = connection_part.split('@')[1];\n  }\n\n  // Check there is not more than one unescaped slash\n  if (connection_part.split('/').length > 2) {\n    throw new Error(\n      \"Unsupported host '\" +\n        connection_part.split('?')[0] +\n        \"', hosts must be URL encoded and contain at most one unencoded slash\"\n    );\n  }\n\n  // Check if the connection string has a db\n  if (connection_part.indexOf('.sock') !== -1) {\n    if (connection_part.indexOf('.sock/') !== -1) {\n      dbName = connection_part.split('.sock/')[1];\n      // Check if multiple database names provided, or just an illegal trailing backslash\n      if (dbName.indexOf('/') !== -1) {\n        if (dbName.split('/').length === 2 && dbName.split('/')[1].length === 0) {\n          throw new Error('Illegal trailing backslash after database name');\n        }\n        throw new Error('More than 1 database name in URL');\n      }\n      connection_part = connection_part.split(\n        '/',\n        connection_part.indexOf('.sock') + '.sock'.length\n      );\n    }\n  } else if (connection_part.indexOf('/') !== -1) {\n    // Check if multiple database names provided, or just an illegal trailing backslash\n    if (connection_part.split('/').length > 2) {\n      if (connection_part.split('/')[2].length === 0) {\n        throw new Error('Illegal trailing backslash after database name');\n      }\n      throw new Error('More than 1 database name in URL');\n    }\n    dbName = connection_part.split('/')[1];\n    connection_part = connection_part.split('/')[0];\n  }\n\n  // URI decode the host information\n  connection_part = decodeURIComponent(connection_part);\n\n  // Result object\n  let object = {};\n\n  // Pick apart the authentication part of the string\n  let authPart = auth_part || '';\n  let auth = authPart.split(':', 2);\n\n  // Decode the authentication URI components and verify integrity\n  let user = decodeURIComponent(auth[0]);\n  if (auth[0] !== encodeURIComponent(user)) {\n    throw new Error('Username contains an illegal unescaped character');\n  }\n  auth[0] = user;\n\n  if (auth[1]) {\n    let pass = decodeURIComponent(auth[1]);\n    if (auth[1] !== encodeURIComponent(pass)) {\n      throw new Error('Password contains an illegal unescaped character');\n    }\n    auth[1] = pass;\n  }\n\n  // Add auth to final object if we have 2 elements\n  if (auth.length === 2) object.auth = { user: auth[0], password: auth[1] };\n  // if user provided auth options, use that\n  if (options && options.auth != null) object.auth = options.auth;\n\n  // Variables used for temporary storage\n  let hostPart;\n  let urlOptions;\n  let servers;\n  let compression;\n  let serverOptions = { socketOptions: {} };\n  let dbOptions = { read_preference_tags: [] };\n  let replSetServersOptions = { socketOptions: {} };\n  let mongosOptions = { socketOptions: {} };\n  // Add server options to final object\n  object.server_options = serverOptions;\n  object.db_options = dbOptions;\n  object.rs_options = replSetServersOptions;\n  object.mongos_options = mongosOptions;\n\n  // Let's check if we are using a domain socket\n  if (url.match(/\\.sock/)) {\n    // Split out the socket part\n    let domainSocket = url.substring(\n      url.indexOf('mongodb://') + 'mongodb://'.length,\n      url.lastIndexOf('.sock') + '.sock'.length\n    );\n    // Clean out any auth stuff if any\n    if (domainSocket.indexOf('@') !== -1) domainSocket = domainSocket.split('@')[1];\n    domainSocket = decodeURIComponent(domainSocket);\n    servers = [{ domain_socket: domainSocket }];\n  } else {\n    // Split up the db\n    hostPart = connection_part;\n    // Deduplicate servers\n    let deduplicatedServers = {};\n\n    // Parse all server results\n    servers = hostPart\n      .split(',')\n      .map(function(h) {\n        let _host, _port, ipv6match;\n        //check if it matches [IPv6]:port, where the port number is optional\n        if ((ipv6match = /\\[([^\\]]+)\\](?::(.+))?/.exec(h))) {\n          _host = ipv6match[1];\n          _port = parseInt(ipv6match[2], 10) || 27017;\n        } else {\n          //otherwise assume it's IPv4, or plain hostname\n          let hostPort = h.split(':', 2);\n          _host = hostPort[0] || 'localhost';\n          _port = hostPort[1] != null ? parseInt(hostPort[1], 10) : 27017;\n          // Check for localhost?safe=true style case\n          if (_host.indexOf('?') !== -1) _host = _host.split(/\\?/)[0];\n        }\n\n        // No entry returned for duplicate servr\n        if (deduplicatedServers[_host + '_' + _port]) return null;\n        deduplicatedServers[_host + '_' + _port] = 1;\n\n        // Return the mapped object\n        return { host: _host, port: _port };\n      })\n      .filter(function(x) {\n        return x != null;\n      });\n  }\n\n  // Get the db name\n  object.dbName = dbName || 'admin';\n  // Split up all the options\n  urlOptions = (query_string_part || '').split(/[&;]/);\n  // Ugh, we have to figure out which options go to which constructor manually.\n  urlOptions.forEach(function(opt) {\n    if (!opt) return;\n    var splitOpt = opt.split('='),\n      name = splitOpt[0],\n      value = splitOpt[1];\n\n    // Options implementations\n    switch (name) {\n      case 'slaveOk':\n      case 'slave_ok':\n        serverOptions.slave_ok = value === 'true';\n        dbOptions.slaveOk = value === 'true';\n        break;\n      case 'maxPoolSize':\n      case 'poolSize':\n        serverOptions.poolSize = parseInt(value, 10);\n        replSetServersOptions.poolSize = parseInt(value, 10);\n        break;\n      case 'appname':\n        object.appname = decodeURIComponent(value);\n        break;\n      case 'autoReconnect':\n      case 'auto_reconnect':\n        serverOptions.auto_reconnect = value === 'true';\n        break;\n      case 'ssl':\n        if (value === 'prefer') {\n          serverOptions.ssl = value;\n          replSetServersOptions.ssl = value;\n          mongosOptions.ssl = value;\n          break;\n        }\n        serverOptions.ssl = value === 'true';\n        replSetServersOptions.ssl = value === 'true';\n        mongosOptions.ssl = value === 'true';\n        break;\n      case 'sslValidate':\n        serverOptions.sslValidate = value === 'true';\n        replSetServersOptions.sslValidate = value === 'true';\n        mongosOptions.sslValidate = value === 'true';\n        break;\n      case 'replicaSet':\n      case 'rs_name':\n        replSetServersOptions.rs_name = value;\n        break;\n      case 'reconnectWait':\n        replSetServersOptions.reconnectWait = parseInt(value, 10);\n        break;\n      case 'retries':\n        replSetServersOptions.retries = parseInt(value, 10);\n        break;\n      case 'readSecondary':\n      case 'read_secondary':\n        replSetServersOptions.read_secondary = value === 'true';\n        break;\n      case 'fsync':\n        dbOptions.fsync = value === 'true';\n        break;\n      case 'journal':\n        dbOptions.j = value === 'true';\n        break;\n      case 'safe':\n        dbOptions.safe = value === 'true';\n        break;\n      case 'nativeParser':\n      case 'native_parser':\n        dbOptions.native_parser = value === 'true';\n        break;\n      case 'readConcernLevel':\n        dbOptions.readConcern = { level: value };\n        break;\n      case 'connectTimeoutMS':\n        serverOptions.socketOptions.connectTimeoutMS = parseInt(value, 10);\n        replSetServersOptions.socketOptions.connectTimeoutMS = parseInt(value, 10);\n        mongosOptions.socketOptions.connectTimeoutMS = parseInt(value, 10);\n        break;\n      case 'socketTimeoutMS':\n        serverOptions.socketOptions.socketTimeoutMS = parseInt(value, 10);\n        replSetServersOptions.socketOptions.socketTimeoutMS = parseInt(value, 10);\n        mongosOptions.socketOptions.socketTimeoutMS = parseInt(value, 10);\n        break;\n      case 'w':\n        dbOptions.w = parseInt(value, 10);\n        if (isNaN(dbOptions.w)) dbOptions.w = value;\n        break;\n      case 'authSource':\n        dbOptions.authSource = value;\n        break;\n      case 'gssapiServiceName':\n        dbOptions.gssapiServiceName = value;\n        break;\n      case 'authMechanism':\n        if (value === 'GSSAPI') {\n          // If no password provided decode only the principal\n          if (object.auth == null) {\n            let urlDecodeAuthPart = decodeURIComponent(authPart);\n            if (urlDecodeAuthPart.indexOf('@') === -1)\n              throw new Error('GSSAPI requires a provided principal');\n            object.auth = { user: urlDecodeAuthPart, password: null };\n          } else {\n            object.auth.user = decodeURIComponent(object.auth.user);\n          }\n        } else if (value === 'MONGODB-X509') {\n          object.auth = { user: decodeURIComponent(authPart) };\n        }\n\n        // Only support GSSAPI or MONGODB-CR for now\n        if (\n          value !== 'GSSAPI' &&\n          value !== 'MONGODB-X509' &&\n          value !== 'MONGODB-CR' &&\n          value !== 'DEFAULT' &&\n          value !== 'SCRAM-SHA-1' &&\n          value !== 'PLAIN'\n        )\n          throw new Error(\n            'Only DEFAULT, GSSAPI, PLAIN, MONGODB-X509, SCRAM-SHA-1 or MONGODB-CR is supported by authMechanism'\n          );\n\n        // Authentication mechanism\n        dbOptions.authMechanism = value;\n        break;\n      case 'authMechanismProperties':\n        {\n          // Split up into key, value pairs\n          let values = value.split(',');\n          let o = {};\n          // For each value split into key, value\n          values.forEach(function(x) {\n            let v = x.split(':');\n            o[v[0]] = v[1];\n          });\n\n          // Set all authMechanismProperties\n          dbOptions.authMechanismProperties = o;\n          // Set the service name value\n          if (typeof o.SERVICE_NAME === 'string') dbOptions.gssapiServiceName = o.SERVICE_NAME;\n          if (typeof o.SERVICE_REALM === 'string') dbOptions.gssapiServiceRealm = o.SERVICE_REALM;\n          if (typeof o.CANONICALIZE_HOST_NAME === 'string')\n            dbOptions.gssapiCanonicalizeHostName =\n              o.CANONICALIZE_HOST_NAME === 'true' ? true : false;\n        }\n        break;\n      case 'wtimeoutMS':\n        dbOptions.wtimeout = parseInt(value, 10);\n        break;\n      case 'readPreference':\n        if (!ReadPreference.isValid(value))\n          throw new Error(\n            'readPreference must be either primary/primaryPreferred/secondary/secondaryPreferred/nearest'\n          );\n        dbOptions.readPreference = value;\n        break;\n      case 'maxStalenessSeconds':\n        dbOptions.maxStalenessSeconds = parseInt(value, 10);\n        break;\n      case 'readPreferenceTags':\n        {\n          // Decode the value\n          value = decodeURIComponent(value);\n          // Contains the tag object\n          let tagObject = {};\n          if (value == null || value === '') {\n            dbOptions.read_preference_tags.push(tagObject);\n            break;\n          }\n\n          // Split up the tags\n          let tags = value.split(/,/);\n          for (let i = 0; i < tags.length; i++) {\n            let parts = tags[i].trim().split(/:/);\n            tagObject[parts[0]] = parts[1];\n          }\n\n          // Set the preferences tags\n          dbOptions.read_preference_tags.push(tagObject);\n        }\n        break;\n      case 'compressors':\n        {\n          compression = serverOptions.compression || {};\n          let compressors = value.split(',');\n          if (\n            !compressors.every(function(compressor) {\n              return compressor === 'snappy' || compressor === 'zlib';\n            })\n          ) {\n            throw new Error('Compressors must be at least one of snappy or zlib');\n          }\n\n          compression.compressors = compressors;\n          serverOptions.compression = compression;\n        }\n        break;\n      case 'zlibCompressionLevel':\n        {\n          compression = serverOptions.compression || {};\n          let zlibCompressionLevel = parseInt(value, 10);\n          if (zlibCompressionLevel < -1 || zlibCompressionLevel > 9) {\n            throw new Error('zlibCompressionLevel must be an integer between -1 and 9');\n          }\n\n          compression.zlibCompressionLevel = zlibCompressionLevel;\n          serverOptions.compression = compression;\n        }\n        break;\n      case 'retryWrites':\n        dbOptions.retryWrites = value === 'true';\n        break;\n      case 'minSize':\n        dbOptions.minSize = parseInt(value, 10);\n        break;\n      default:\n        {\n          let logger = Logger('URL Parser');\n          logger.warn(`${name} is not supported as a connection string option`);\n        }\n        break;\n    }\n  });\n\n  // No tags: should be null (not [])\n  if (dbOptions.read_preference_tags.length === 0) {\n    dbOptions.read_preference_tags = null;\n  }\n\n  // Validate if there are an invalid write concern combinations\n  if (\n    (dbOptions.w === -1 || dbOptions.w === 0) &&\n    (dbOptions.journal === true || dbOptions.fsync === true || dbOptions.safe === true)\n  )\n    throw new Error('w set to -1 or 0 cannot be combined with safe/w/journal/fsync');\n\n  // If no read preference set it to primary\n  if (!dbOptions.readPreference) {\n    dbOptions.readPreference = 'primary';\n  }\n\n  // make sure that user-provided options are applied with priority\n  dbOptions = Object.assign(dbOptions, options);\n\n  // Add servers to result\n  object.servers = servers;\n\n  // Returned parsed object\n  return object;\n}\n\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/url_parser.js?");

/***/ }),

/***/ "./node_modules/mongoDb/lib/utils.js":
/*!*******************************************!*\
  !*** ./node_modules/mongoDb/lib/utils.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nvar MongoError = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").MongoError,\n  ReadPreference = __webpack_require__(/*! mongodb-core */ \"mongodb-core\").ReadPreference;\n\nvar shallowClone = function(obj) {\n  var copy = {};\n  for (var name in obj) copy[name] = obj[name];\n  return copy;\n};\n\n// Figure out the read preference\nvar translateReadPreference = function(options) {\n  var r = null;\n  if (options.readPreference) {\n    r = options.readPreference;\n  } else {\n    return options;\n  }\n\n  if (typeof r === 'string') {\n    options.readPreference = new ReadPreference(r);\n  } else if (r && !(r instanceof ReadPreference) && typeof r === 'object') {\n    const mode = r.mode || r.preference;\n    if (mode && typeof mode === 'string') {\n      options.readPreference = new ReadPreference(mode, r.tags, {\n        maxStalenessSeconds: r.maxStalenessSeconds\n      });\n    }\n  } else if (!(r instanceof ReadPreference)) {\n    throw new TypeError('Invalid read preference: ' + r);\n  }\n\n  return options;\n};\n\n// Set simple property\nvar getSingleProperty = function(obj, name, value) {\n  Object.defineProperty(obj, name, {\n    enumerable: true,\n    get: function() {\n      return value;\n    }\n  });\n};\n\nvar formatSortValue = (exports.formatSortValue = function(sortDirection) {\n  var value = ('' + sortDirection).toLowerCase();\n\n  switch (value) {\n    case 'ascending':\n    case 'asc':\n    case '1':\n      return 1;\n    case 'descending':\n    case 'desc':\n    case '-1':\n      return -1;\n    default:\n      throw new Error(\n        'Illegal sort clause, must be of the form ' +\n          \"[['field1', '(ascending|descending)'], \" +\n          \"['field2', '(ascending|descending)']]\"\n      );\n  }\n});\n\nvar formattedOrderClause = (exports.formattedOrderClause = function(sortValue) {\n  var orderBy = {};\n  if (sortValue == null) return null;\n  if (Array.isArray(sortValue)) {\n    if (sortValue.length === 0) {\n      return null;\n    }\n\n    for (var i = 0; i < sortValue.length; i++) {\n      if (sortValue[i].constructor === String) {\n        orderBy[sortValue[i]] = 1;\n      } else {\n        orderBy[sortValue[i][0]] = formatSortValue(sortValue[i][1]);\n      }\n    }\n  } else if (sortValue != null && typeof sortValue === 'object') {\n    orderBy = sortValue;\n  } else if (typeof sortValue === 'string') {\n    orderBy[sortValue] = 1;\n  } else {\n    throw new Error(\n      'Illegal sort clause, must be of the form ' +\n        \"[['field1', '(ascending|descending)'], ['field2', '(ascending|descending)']]\"\n    );\n  }\n\n  return orderBy;\n});\n\nvar checkCollectionName = function checkCollectionName(collectionName) {\n  if ('string' !== typeof collectionName) {\n    throw new MongoError('collection name must be a String');\n  }\n\n  if (!collectionName || collectionName.indexOf('..') !== -1) {\n    throw new MongoError('collection names cannot be empty');\n  }\n\n  if (\n    collectionName.indexOf('$') !== -1 &&\n    collectionName.match(/((^\\$cmd)|(oplog\\.\\$main))/) == null\n  ) {\n    throw new MongoError(\"collection names must not contain '$'\");\n  }\n\n  if (collectionName.match(/^\\.|\\.$/) != null) {\n    throw new MongoError(\"collection names must not start or end with '.'\");\n  }\n\n  // Validate that we are not passing 0x00 in the colletion name\n  if (collectionName.indexOf('\\x00') !== -1) {\n    throw new MongoError('collection names cannot contain a null character');\n  }\n};\n\nvar handleCallback = function(callback, err, value1, value2) {\n  try {\n    if (callback == null) return;\n\n    if (callback) {\n      return value2 ? callback(err, value1, value2) : callback(err, value1);\n    }\n  } catch (err) {\n    process.nextTick(function() {\n      throw err;\n    });\n    return false;\n  }\n\n  return true;\n};\n\n/**\n * Wrap a Mongo error document in an Error instance\n * @ignore\n * @api private\n */\nvar toError = function(error) {\n  if (error instanceof Error) return error;\n\n  var msg = error.err || error.errmsg || error.errMessage || error;\n  var e = MongoError.create({ message: msg, driver: true });\n\n  // Get all object keys\n  var keys = typeof error === 'object' ? Object.keys(error) : [];\n\n  for (var i = 0; i < keys.length; i++) {\n    try {\n      e[keys[i]] = error[keys[i]];\n    } catch (err) {\n      // continue\n    }\n  }\n\n  return e;\n};\n\n/**\n * @ignore\n */\nvar normalizeHintField = function normalizeHintField(hint) {\n  var finalHint = null;\n\n  if (typeof hint === 'string') {\n    finalHint = hint;\n  } else if (Array.isArray(hint)) {\n    finalHint = {};\n\n    hint.forEach(function(param) {\n      finalHint[param] = 1;\n    });\n  } else if (hint != null && typeof hint === 'object') {\n    finalHint = {};\n    for (var name in hint) {\n      finalHint[name] = hint[name];\n    }\n  }\n\n  return finalHint;\n};\n\n/**\n * Create index name based on field spec\n *\n * @ignore\n * @api private\n */\nvar parseIndexOptions = function(fieldOrSpec) {\n  var fieldHash = {};\n  var indexes = [];\n  var keys;\n\n  // Get all the fields accordingly\n  if ('string' === typeof fieldOrSpec) {\n    // 'type'\n    indexes.push(fieldOrSpec + '_' + 1);\n    fieldHash[fieldOrSpec] = 1;\n  } else if (Array.isArray(fieldOrSpec)) {\n    fieldOrSpec.forEach(function(f) {\n      if ('string' === typeof f) {\n        // [{location:'2d'}, 'type']\n        indexes.push(f + '_' + 1);\n        fieldHash[f] = 1;\n      } else if (Array.isArray(f)) {\n        // [['location', '2d'],['type', 1]]\n        indexes.push(f[0] + '_' + (f[1] || 1));\n        fieldHash[f[0]] = f[1] || 1;\n      } else if (isObject(f)) {\n        // [{location:'2d'}, {type:1}]\n        keys = Object.keys(f);\n        keys.forEach(function(k) {\n          indexes.push(k + '_' + f[k]);\n          fieldHash[k] = f[k];\n        });\n      } else {\n        // undefined (ignore)\n      }\n    });\n  } else if (isObject(fieldOrSpec)) {\n    // {location:'2d', type:1}\n    keys = Object.keys(fieldOrSpec);\n    keys.forEach(function(key) {\n      indexes.push(key + '_' + fieldOrSpec[key]);\n      fieldHash[key] = fieldOrSpec[key];\n    });\n  }\n\n  return {\n    name: indexes.join('_'),\n    keys: keys,\n    fieldHash: fieldHash\n  };\n};\n\nvar isObject = (exports.isObject = function(arg) {\n  return '[object Object]' === Object.prototype.toString.call(arg);\n});\n\nvar debugOptions = function(debugFields, options) {\n  var finaloptions = {};\n  debugFields.forEach(function(n) {\n    finaloptions[n] = options[n];\n  });\n\n  return finaloptions;\n};\n\nvar decorateCommand = function(command, options, exclude) {\n  for (var name in options) {\n    if (exclude[name] == null) command[name] = options[name];\n  }\n\n  return command;\n};\n\nvar mergeOptions = function(target, source) {\n  for (var name in source) {\n    target[name] = source[name];\n  }\n\n  return target;\n};\n\n// Merge options with translation\nvar translateOptions = function(target, source) {\n  var translations = {\n    // SSL translation options\n    sslCA: 'ca',\n    sslCRL: 'crl',\n    sslValidate: 'rejectUnauthorized',\n    sslKey: 'key',\n    sslCert: 'cert',\n    sslPass: 'passphrase',\n    // SocketTimeout translation options\n    socketTimeoutMS: 'socketTimeout',\n    connectTimeoutMS: 'connectionTimeout',\n    // Replicaset options\n    replicaSet: 'setName',\n    rs_name: 'setName',\n    secondaryAcceptableLatencyMS: 'acceptableLatency',\n    connectWithNoPrimary: 'secondaryOnlyConnectionAllowed',\n    // Mongos options\n    acceptableLatencyMS: 'localThresholdMS'\n  };\n\n  for (var name in source) {\n    if (translations[name]) {\n      target[translations[name]] = source[name];\n    } else {\n      target[name] = source[name];\n    }\n  }\n\n  return target;\n};\n\nvar filterOptions = function(options, names) {\n  var filterOptions = {};\n\n  for (var name in options) {\n    if (names.indexOf(name) !== -1) filterOptions[name] = options[name];\n  }\n\n  // Filtered options\n  return filterOptions;\n};\n\n// Write concern keys\nvar writeConcernKeys = ['w', 'j', 'wtimeout', 'fsync'];\n\n// Merge the write concern options\nvar mergeOptionsAndWriteConcern = function(targetOptions, sourceOptions, keys, mergeWriteConcern) {\n  // Mix in any allowed options\n  for (var i = 0; i < keys.length; i++) {\n    if (!targetOptions[keys[i]] && sourceOptions[keys[i]] !== undefined) {\n      targetOptions[keys[i]] = sourceOptions[keys[i]];\n    }\n  }\n\n  // No merging of write concern\n  if (!mergeWriteConcern) return targetOptions;\n\n  // Found no write Concern options\n  var found = false;\n  for (i = 0; i < writeConcernKeys.length; i++) {\n    if (targetOptions[writeConcernKeys[i]]) {\n      found = true;\n      break;\n    }\n  }\n\n  if (!found) {\n    for (i = 0; i < writeConcernKeys.length; i++) {\n      if (sourceOptions[writeConcernKeys[i]]) {\n        targetOptions[writeConcernKeys[i]] = sourceOptions[writeConcernKeys[i]];\n      }\n    }\n  }\n\n  return targetOptions;\n};\n\n/**\n * Executes the given operation with provided arguments.\n *\n * This method reduces large amounts of duplication in the entire codebase by providing\n * a single point for determining whether callbacks or promises should be used. Additionally\n * it allows for a single point of entry to provide features such as implicit sessions, which\n * are required by the Driver Sessions specification in the event that a ClientSession is\n * not provided\n *\n * @param {object} topology The topology to execute this operation on\n * @param {function} operation The operation to execute\n * @param {array} args Arguments to apply the provided operation\n * @param {object} [options] Options that modify the behavior of the method\n * @param {function]} [options.resultMutator] Allows for the result of the operation to be changed for custom return types\n */\nconst executeOperation = (topology, operation, args, options) => {\n  if (topology == null) {\n    throw new TypeError('This method requires a valid topology instance');\n  }\n\n  if (!Array.isArray(args)) {\n    throw new TypeError('This method requires an array of arguments to apply');\n  }\n\n  options = options || {};\n  const Promise = topology.s.promiseLibrary;\n  let resultMutator = options.resultMutator;\n  let callback = args[args.length - 1];\n\n  // The driver sessions spec mandates that we implicitly create sessions for operations\n  // that are not explicitly provided with a session.\n  let session, opOptions;\n  if (!options.skipSessions && topology.hasSessionSupport()) {\n    opOptions = args[args.length - 2];\n    if (opOptions == null || opOptions.session == null) {\n      session = topology.startSession();\n      const optionsIndex = args.length - 2;\n      args[optionsIndex] = Object.assign({}, args[optionsIndex], { session: session });\n    } else if (opOptions.session && opOptions.session.hasEnded) {\n      throw new MongoError('Use of expired sessions is not permitted');\n    }\n  }\n\n  const makeExecuteCallback = (resolve, reject) =>\n    function executeCallback(err, result) {\n      if (session && !options.returnsCursor) {\n        session.endSession(() => {\n          delete opOptions.session;\n          if (err) return reject(err);\n          if (resultMutator) return resolve(resultMutator(result));\n          resolve(result);\n        });\n      } else {\n        if (err) return reject(err);\n        if (resultMutator) return resolve(resultMutator(result));\n        resolve(result);\n      }\n    };\n\n  // Execute using callback\n  if (typeof callback === 'function') {\n    callback = args.pop();\n    const handler = makeExecuteCallback(\n      result => callback(null, result),\n      err => callback(err, null)\n    );\n    args.push(handler);\n\n    try {\n      return operation.apply(null, args);\n    } catch (e) {\n      handler(e);\n      throw e;\n    }\n  }\n\n  // Return a Promise\n  if (args[args.length - 1] != null) {\n    throw new TypeError('final argument to `executeOperation` must be a callback');\n  }\n\n  return new Promise(function(resolve, reject) {\n    const handler = makeExecuteCallback(resolve, reject);\n    args[args.length - 1] = handler;\n\n    try {\n      return operation.apply(null, args);\n    } catch (e) {\n      handler(e);\n    }\n  });\n};\n\nexports.filterOptions = filterOptions;\nexports.mergeOptions = mergeOptions;\nexports.translateOptions = translateOptions;\nexports.shallowClone = shallowClone;\nexports.getSingleProperty = getSingleProperty;\nexports.checkCollectionName = checkCollectionName;\nexports.toError = toError;\nexports.formattedOrderClause = formattedOrderClause;\nexports.parseIndexOptions = parseIndexOptions;\nexports.normalizeHintField = normalizeHintField;\nexports.handleCallback = handleCallback;\nexports.decorateCommand = decorateCommand;\nexports.isObject = isObject;\nexports.debugOptions = debugOptions;\nexports.MAX_JS_INT = 0x20000000000000;\nexports.mergeOptionsAndWriteConcern = mergeOptionsAndWriteConcern;\nexports.translateReadPreference = translateReadPreference;\nexports.executeOperation = executeOperation;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/mongoDb/lib/utils.js?");

/***/ }),

/***/ "./node_modules/mongoDb/package.json":
/*!*******************************************!*\
  !*** ./node_modules/mongoDb/package.json ***!
  \*******************************************/
/*! exports provided: _from, _id, _inBundle, _integrity, _location, _phantomChildren, _requested, _requiredBy, _resolved, _shasum, _spec, _where, author, bugs, bundleDependencies, dependencies, deprecated, description, devDependencies, engines, homepage, keywords, license, main, name, repository, scripts, version, default */
/***/ (function(module) {

eval("module.exports = {\"_from\":\"mongodb@3.0.4\",\"_id\":\"mongodb@3.0.4\",\"_inBundle\":false,\"_integrity\":\"sha512-90YIIs7A4ko4kCGafxxXj3foexCAlJBC0YLwwIKgSLoE7Vni2IqUMz6HSsZ3zbXOfR1KWtxfnc0RyAMAY/ViLg==\",\"_location\":\"/mongodb\",\"_phantomChildren\":{},\"_requested\":{\"type\":\"version\",\"registry\":true,\"raw\":\"mongodb@3.0.4\",\"name\":\"mongodb\",\"escapedName\":\"mongodb\",\"rawSpec\":\"3.0.4\",\"saveSpec\":null,\"fetchSpec\":\"3.0.4\"},\"_requiredBy\":[\"/mongoose\"],\"_resolved\":\"https://registry.npmjs.org/mongodb/-/mongodb-3.0.4.tgz\",\"_shasum\":\"ee0c0f7bc565edc5f40ee2d23170e522a8ad2286\",\"_spec\":\"mongodb@3.0.4\",\"_where\":\"/Users/tocausan/github/naive-chain/node_modules/mongoose\",\"author\":{\"name\":\"Christian Kvalheim\"},\"bugs\":{\"url\":\"https://github.com/mongodb/node-mongodb-native/issues\"},\"bundleDependencies\":false,\"dependencies\":{\"mongodb-core\":\"3.0.4\"},\"deprecated\":false,\"description\":\"The official MongoDB driver for Node.js\",\"devDependencies\":{\"betterbenchmarks\":\"^0.1.0\",\"bluebird\":\"3.5.0\",\"bson\":\"^1.0.4\",\"chai\":\"^4.1.1\",\"co\":\"4.6.0\",\"conventional-changelog-cli\":\"^1.3.5\",\"coveralls\":\"^2.11.6\",\"eslint\":\"^4.5.0\",\"eslint-plugin-prettier\":\"^2.2.0\",\"istanbul\":\"^0.4.5\",\"jsdoc\":\"3.5.4\",\"mongodb-extended-json\":\"^1.10.0\",\"mongodb-mock-server\":\"^1.0.0\",\"mongodb-test-runner\":\"^1.1.18\",\"prettier\":\"^1.5.3\",\"semver\":\"5.4.1\",\"sinon\":\"^4.3.0\",\"worker-farm\":\"^1.5.0\"},\"engines\":{\"node\":\">=4\"},\"homepage\":\"https://github.com/mongodb/node-mongodb-native\",\"keywords\":[\"mongodb\",\"driver\",\"official\"],\"license\":\"Apache-2.0\",\"main\":\"index.js\",\"name\":\"mongodb\",\"repository\":{\"type\":\"git\",\"url\":\"git+ssh://git@github.com/mongodb/node-mongodb-native.git\"},\"scripts\":{\"changelog\":\"conventional-changelog -p angular -i HISTORY.md -s\",\"coverage\":\"istanbul cover mongodb-test-runner -- -t 60000  test/unit test/functional\",\"format\":\"prettier --print-width 100 --tab-width 2 --single-quote --write 'test/**/*.js' 'lib/**/*.js'\",\"lint\":\"eslint lib test\",\"test\":\"npm run lint && mongodb-test-runner -t 60000 test/unit test/functional\"},\"version\":\"3.0.4\"};\n\n//# sourceURL=webpack:///./node_modules/mongoDb/package.json?");

/***/ }),

/***/ "./node_modules/process/browser.js":
/*!*****************************************!*\
  !*** ./node_modules/process/browser.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n//# sourceURL=webpack:///./node_modules/process/browser.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var g;\r\n\r\n// This works in non-strict mode\r\ng = (function() {\r\n\treturn this;\r\n})();\r\n\r\ntry {\r\n\t// This works if eval is allowed (see CSP)\r\n\tg = g || Function(\"return this\")() || (1, eval)(\"this\");\r\n} catch (e) {\r\n\t// This works if the window reference is available\r\n\tif (typeof window === \"object\") g = window;\r\n}\r\n\r\n// g can still be undefined, but nothing to do about it...\r\n// We return undefined, instead of nothing here, so it's\r\n// easier to handle this case. if(!global) { ...}\r\n\r\nmodule.exports = g;\r\n\n\n//# sourceURL=webpack:///(webpack)/buildin/global.js?");

/***/ }),

/***/ "./routes/blockRoutes.ts":
/*!*******************************!*\
  !*** ./routes/blockRoutes.ts ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar errorRoutes_1 = __webpack_require__(/*! ./errorRoutes */ \"./routes/errorRoutes.ts\");\nvar services_1 = __webpack_require__(/*! ../services */ \"./services/index.ts\");\nexports.BlockRoutes = {\n    getAllBlocks: function (req, res) {\n        services_1.BlockServices.getAllBlocks()\n            .then(function (blocks) {\n            res.json(blocks);\n        });\n    },\n    getOneBlock: function (req, res) {\n        services_1.BlockServices.getOneBlock(req.params.hash).then(function (block) {\n            res.json(block);\n        }, function (e) { return errorRoutes_1.ErrorRoutes.handler(e, req, res); });\n    },\n    createOneBlock: function (req, res) {\n        console.log(req.body.block);\n        services_1.BlockServices.createOneBlock(req.body.block).then(function (block) {\n            console.log(block);\n            res.json(block);\n        }, function (e) { return errorRoutes_1.ErrorRoutes.handler(e, req, res); });\n    },\n    validateOneBlock: function (req, res) {\n        services_1.BlockServices.validateBlock(req.body).then(function (block) {\n            res.json(block);\n        }, function (e) { return errorRoutes_1.ErrorRoutes.handler(e, req, res); });\n    }\n};\n\n\n//# sourceURL=webpack:///./routes/blockRoutes.ts?");

/***/ }),

/***/ "./routes/chainRoutes.ts":
/*!*******************************!*\
  !*** ./routes/chainRoutes.ts ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar errorRoutes_1 = __webpack_require__(/*! ./errorRoutes */ \"./routes/errorRoutes.ts\");\nvar services_1 = __webpack_require__(/*! ../services */ \"./services/index.ts\");\nexports.ChainRoutes = {\n    checkChain: function (req, res) {\n        services_1.ChainServices.checkChain().then(function (check) {\n            res.json(check);\n        }, function (e) { return errorRoutes_1.ErrorRoutes.handler(e, req, res); });\n    }\n};\n\n\n//# sourceURL=webpack:///./routes/chainRoutes.ts?");

/***/ }),

/***/ "./routes/deviceRoutes.ts":
/*!********************************!*\
  !*** ./routes/deviceRoutes.ts ***!
  \********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar errorRoutes_1 = __webpack_require__(/*! ./errorRoutes */ \"./routes/errorRoutes.ts\");\nvar services_1 = __webpack_require__(/*! ../services */ \"./services/index.ts\");\nexports.DeviceRoutes = {\n    isConnected: function (req, res) {\n        return services_1.DeviceServices.isConnected().then(function (result) {\n            return res.json(result);\n        }, function (e) { return errorRoutes_1.ErrorRoutes.handler(e, req, res); });\n    },\n    init: function (req, res) {\n        return services_1.DeviceServices.init(req)\n            .then(function (result) {\n            return res.json(result);\n        }, function (e) { return errorRoutes_1.ErrorRoutes.handler(e, req, res); });\n    }\n};\n\n\n//# sourceURL=webpack:///./routes/deviceRoutes.ts?");

/***/ }),

/***/ "./routes/errorRoutes.ts":
/*!*******************************!*\
  !*** ./routes/errorRoutes.ts ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar _ = __webpack_require__(/*! lodash */ \"lodash\");\nvar models_1 = __webpack_require__(/*! ../models */ \"./models/index.ts\");\nvar Error_1 = __webpack_require__(/*! ../models/Error */ \"./models/Error.ts\");\nexports.ErrorRoutes = {\n    _404: function (req, res) {\n        var e = new Error_1.ErrorApi('Not Found');\n        e.status = 404;\n        return res.json(e);\n    },\n    handler: function (err, req, res) {\n        var e = new Error_1.ErrorApi();\n        e.status = !_.isNil(err.status) ? err.status : 500;\n        e.message = !_.isNil(err.message) ? err.message : err;\n        e.stack = !_.isNil(err.stack) && req.app.get('env') === 'development' ? err.stack : {};\n        models_1.Debug.error(err);\n        return res.json(e);\n    }\n};\n\n\n//# sourceURL=webpack:///./routes/errorRoutes.ts?");

/***/ }),

/***/ "./routes/index.ts":
/*!*************************!*\
  !*** ./routes/index.ts ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar express_1 = __webpack_require__(/*! express */ \"express\");\nvar errorRoutes_1 = __webpack_require__(/*! ./errorRoutes */ \"./routes/errorRoutes.ts\");\nvar deviceRoutes_1 = __webpack_require__(/*! ./deviceRoutes */ \"./routes/deviceRoutes.ts\");\nvar blockRoutes_1 = __webpack_require__(/*! ./blockRoutes */ \"./routes/blockRoutes.ts\");\nvar chainRoutes_1 = __webpack_require__(/*! ./chainRoutes */ \"./routes/chainRoutes.ts\");\nvar corsMiddleware_1 = __webpack_require__(/*! ./middlewares/corsMiddleware */ \"./routes/middlewares/corsMiddleware.ts\");\nexports.Routes = express_1.Router()\n    .use('/', [corsMiddleware_1.Middleware.cors])\n    .get('/', function (req, res) {\n    res.sendFile('views/index/index.html');\n})\n    .get('/api', function (req, res) {\n    return res.json({\n        app: 'naive-chain API',\n        routes: [\n            '/api/device/connected',\n            '/api/device/init',\n            '/api/block/all',\n            '/api/block/one/:hash',\n            '/api/block/create',\n            '/api/block/validate',\n            '/api/chain/check'\n        ]\n    });\n})\n    .post('/api/device/connected', deviceRoutes_1.DeviceRoutes.isConnected)\n    .post('/api/device/init', deviceRoutes_1.DeviceRoutes.init)\n    .post('/api/block/all', blockRoutes_1.BlockRoutes.getAllBlocks)\n    .post('/api/block/one/:hash', blockRoutes_1.BlockRoutes.getOneBlock)\n    .post('/api/block/create', blockRoutes_1.BlockRoutes.createOneBlock)\n    .post('/api/block/validate', blockRoutes_1.BlockRoutes.validateOneBlock)\n    .post('/api/chain/check', chainRoutes_1.ChainRoutes.checkChain)\n    .use(errorRoutes_1.ErrorRoutes._404)\n    .use(errorRoutes_1.ErrorRoutes.handler);\n\n\n//# sourceURL=webpack:///./routes/index.ts?");

/***/ }),

/***/ "./routes/middlewares/corsMiddleware.ts":
/*!**********************************************!*\
  !*** ./routes/middlewares/corsMiddleware.ts ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Middleware = {\n    cors: function (req, res, next) {\n        res.header(\"Access-Control-Allow-Origin\", \"*\");\n        res.header('Access-Control-Allow-Methods', 'GET, PUT, POST, DELETE, OPTIONS');\n        res.header(\"Access-Control-Allow-Headers\", \"Origin, X-Requested-With, Content-Type, Accept\");\n        next();\n    }\n};\n\n\n//# sourceURL=webpack:///./routes/middlewares/corsMiddleware.ts?");

/***/ }),

/***/ "./services/blockServices.ts":
/*!***********************************!*\
  !*** ./services/blockServices.ts ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar config_1 = __webpack_require__(/*! ../config */ \"./config.ts\");\nvar data_access_1 = __webpack_require__(/*! ../data-access */ \"./data-access/index.ts\");\nvar models_1 = __webpack_require__(/*! ../models */ \"./models/index.ts\");\nexports.BlockServices = {\n    getAllBlocks: function () {\n        return data_access_1.DatabaseDataAccess.findAll(config_1.Config.database.collections.blocks).then(function (blocks) {\n            return blocks;\n        });\n    },\n    getOneBlock: function (hash) {\n        return data_access_1.DatabaseDataAccess.findOne(config_1.Config.database.collections.blocks, { hash: hash }).then(function (block) {\n            return block;\n        });\n    },\n    createOneBlock: function (data) {\n        return new Promise(function (resolve, reject) {\n            models_1.Block.createNonce().then(function (nonce) {\n                data.prevBlock = null;\n                data.nonce = nonce;\n            });\n            var block = new models_1.Block(data);\n            console.log(block);\n            data_access_1.DatabaseDataAccess.insertOne(config_1.Config.database.collections.blocks, block).then(function (result) {\n                resolve(result);\n            }, function (e) {\n                reject(e);\n            });\n        });\n    },\n    getLastBlock: function () {\n        return data_access_1.DatabaseDataAccess.findLastOne(config_1.Config.database.collections.blocks)\n            .then(function (block) {\n            console.log(block);\n        }, function (e) { return console.log(e); });\n    },\n    validateBlock: function (block) {\n        return new Promise(function (resolve, reject) {\n            resolve(true);\n        });\n    }\n};\n\n\n//# sourceURL=webpack:///./services/blockServices.ts?");

/***/ }),

/***/ "./services/chainServices.ts":
/*!***********************************!*\
  !*** ./services/chainServices.ts ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar config_1 = __webpack_require__(/*! ../config */ \"./config.ts\");\nvar data_access_1 = __webpack_require__(/*! ../data-access */ \"./data-access/index.ts\");\nvar models_1 = __webpack_require__(/*! ../models */ \"./models/index.ts\");\nexports.ChainServices = {\n    checkChain: function () {\n        return new Promise(function (resolve, reject) {\n            data_access_1.DatabaseDataAccess.findAll(config_1.Config.database.collections.blocks).then(function (blocks) {\n                var errors = [];\n                blocks.reverse().forEach(function (block, index) {\n                    if (index + 1 < blocks.length) {\n                        var isValid = models_1.Block.isValid(block, blocks[index + 1]);\n                        if (!isValid) {\n                            errors.push(block);\n                        }\n                    }\n                });\n                if (errors.length === 0) {\n                    resolve({ success: 'The chain isn\\'t corrupted' });\n                }\n                else {\n                    reject({ error: 'Corrupted block found: ' + errors.join(',') });\n                }\n            });\n        });\n    },\n    getDevices: function () {\n        return new Promise(function (resolve, reject) {\n            resolve({});\n        });\n    }\n};\n\n\n//# sourceURL=webpack:///./services/chainServices.ts?");

/***/ }),

/***/ "./services/deviceServices.ts":
/*!************************************!*\
  !*** ./services/deviceServices.ts ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar data_access_1 = __webpack_require__(/*! ../data-access */ \"./data-access/index.ts\");\nvar models_1 = __webpack_require__(/*! ../models */ \"./models/index.ts\");\nvar config_1 = __webpack_require__(/*! ../config */ \"./config.ts\");\nexports.DeviceServices = {\n    isConnected: function () {\n        return new Promise(function (resolve, reject) {\n            data_access_1.DatabaseDataAccess.isConnected().then(function (databaseResult) {\n                resolve({\n                    database: databaseResult\n                });\n            }, function (e) {\n                reject(e);\n            });\n        });\n    },\n    init: function (request) {\n        return new Promise(function (resolve, reject) {\n            var device = new models_1.Device();\n            data_access_1.DatabaseDataAccess\n                .insertOneIfNotExist(config_1.Config.database.collections.devices, { host: device.host }, device)\n                .then(function (result) {\n                resolve(result);\n            }, function (e) {\n                reject(e);\n            });\n        });\n    },\n    getDevice: function (request) {\n        return new Promise(function (resolve, reject) {\n            var host = request.connection.localAddress;\n            data_access_1.DatabaseDataAccess\n                .findOne(config_1.Config.database.collections.devices, { host: host })\n                .then(function (result) {\n                resolve(result);\n            }, function (e) {\n                reject(e);\n            });\n        });\n    }\n};\n\n\n//# sourceURL=webpack:///./services/deviceServices.ts?");

/***/ }),

/***/ "./services/encryptionServices.ts":
/*!****************************************!*\
  !*** ./services/encryptionServices.ts ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar crypto = __webpack_require__(/*! crypto */ \"crypto\");\nvar config_1 = __webpack_require__(/*! ../config */ \"./config.ts\");\nvar binary = config_1.Config.encryption.binary, algorithm = config_1.Config.encryption.algorithm, hash = config_1.Config.encryption.hash, iterations = config_1.Config.encryption.iterations;\nexports.EncryptionServices = {\n    randomSecret: function (length) {\n        var characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789', secret = '';\n        for (var i = 0; i < length; i++)\n            secret += characters.charAt(Math.floor(Math.random() * characters.length));\n        return secret;\n    },\n    hash: function (secret) {\n        var hash = secret;\n        for (var i = 0; i < iterations; i++)\n            hash = crypto.createHmac('sha512', hash)\n                .update('I love cupcakes')\n                .digest(binary);\n        return hash;\n    },\n    encrypt: function (content, password) {\n        var cipher = crypto.createCipher(algorithm, password), crypted = cipher.update(content, 'utf8', binary);\n        crypted += cipher.final(binary);\n        return crypted;\n    },\n    decrypt: function (content, password) {\n        var decipher = crypto.createDecipher(algorithm, password), dec = decipher.update(content, binary, 'utf8');\n        dec += decipher.final(binary);\n        return dec;\n    }\n};\n\n\n//# sourceURL=webpack:///./services/encryptionServices.ts?");

/***/ }),

/***/ "./services/index.ts":
/*!***************************!*\
  !*** ./services/index.ts ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__export(__webpack_require__(/*! ./encryptionServices */ \"./services/encryptionServices.ts\"));\n__export(__webpack_require__(/*! ./chainServices */ \"./services/chainServices.ts\"));\n__export(__webpack_require__(/*! ./blockServices */ \"./services/blockServices.ts\"));\n__export(__webpack_require__(/*! ./deviceServices */ \"./services/deviceServices.ts\"));\n\n\n//# sourceURL=webpack:///./services/index.ts?");

/***/ }),

/***/ 0:
/*!**************************!*\
  !*** multi ./bin/www.ts ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! /Users/tocausan/github/naive-chain/server/bin/www.ts */\"./bin/www.ts\");\n\n\n//# sourceURL=webpack:///multi_./bin/www.ts?");

/***/ }),

/***/ "base64-js":
/*!****************************!*\
  !*** external "base64-js" ***!
  \****************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = base64-js;\n\n//# sourceURL=webpack:///external_%22base64-js%22?");

/***/ }),

/***/ "body-parser":
/*!******************************!*\
  !*** external "body-parser" ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = body-parser;\n\n//# sourceURL=webpack:///external_%22body-parser%22?");

/***/ }),

/***/ "buffer":
/*!*************************!*\
  !*** external "buffer" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = buffer;\n\n//# sourceURL=webpack:///external_%22buffer%22?");

/***/ }),

/***/ "chalk":
/*!************************!*\
  !*** external "chalk" ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = chalk;\n\n//# sourceURL=webpack:///external_%22chalk%22?");

/***/ }),

/***/ "cookie-parser":
/*!********************************!*\
  !*** external "cookie-parser" ***!
  \********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = cookie-parser;\n\n//# sourceURL=webpack:///external_%22cookie-parser%22?");

/***/ }),

/***/ "crypto":
/*!*************************!*\
  !*** external "crypto" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = crypto;\n\n//# sourceURL=webpack:///external_%22crypto%22?");

/***/ }),

/***/ "debug":
/*!************************!*\
  !*** external "debug" ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = debug;\n\n//# sourceURL=webpack:///external_%22debug%22?");

/***/ }),

/***/ "dns":
/*!**********************!*\
  !*** external "dns" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = dns;\n\n//# sourceURL=webpack:///external_%22dns%22?");

/***/ }),

/***/ "events":
/*!*************************!*\
  !*** external "events" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = events;\n\n//# sourceURL=webpack:///external_%22events%22?");

/***/ }),

/***/ "express":
/*!**************************!*\
  !*** external "express" ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = express;\n\n//# sourceURL=webpack:///external_%22express%22?");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = fs;\n\n//# sourceURL=webpack:///external_%22fs%22?");

/***/ }),

/***/ "http":
/*!***********************!*\
  !*** external "http" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = http;\n\n//# sourceURL=webpack:///external_%22http%22?");

/***/ }),

/***/ "ieee754":
/*!**************************!*\
  !*** external "ieee754" ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = ieee754;\n\n//# sourceURL=webpack:///external_%22ieee754%22?");

/***/ }),

/***/ "isarray":
/*!**************************!*\
  !*** external "isarray" ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = isarray;\n\n//# sourceURL=webpack:///external_%22isarray%22?");

/***/ }),

/***/ "lodash":
/*!*************************!*\
  !*** external "lodash" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = lodash;\n\n//# sourceURL=webpack:///external_%22lodash%22?");

/***/ }),

/***/ "logger":
/*!*************************!*\
  !*** external "logger" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = logger;\n\n//# sourceURL=webpack:///external_%22logger%22?");

/***/ }),

/***/ "moment":
/*!*************************!*\
  !*** external "moment" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = moment;\n\n//# sourceURL=webpack:///external_%22moment%22?");

/***/ }),

/***/ "mongodb-core":
/*!*******************************!*\
  !*** external "mongodb-core" ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = mongodb-core;\n\n//# sourceURL=webpack:///external_%22mongodb-core%22?");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = os;\n\n//# sourceURL=webpack:///external_%22os%22?");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = path;\n\n//# sourceURL=webpack:///external_%22path%22?");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = stream;\n\n//# sourceURL=webpack:///external_%22stream%22?");

/***/ }),

/***/ "url":
/*!**********************!*\
  !*** external "url" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = url;\n\n//# sourceURL=webpack:///external_%22url%22?");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = util;\n\n//# sourceURL=webpack:///external_%22util%22?");

/***/ })

/******/ });